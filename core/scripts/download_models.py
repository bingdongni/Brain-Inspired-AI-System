#!/usr/bin/env python3
"""
é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½è„šæœ¬
Pretrained Models Download Script

è‡ªåŠ¨ä¸‹è½½å’Œç®¡ç†é¢„è®­ç»ƒæ¨¡å‹
"""

import os
import sys
import json
import requests
import hashlib
from pathlib import Path
from typing import Dict, List, Optional
import argparse

class ModelDownloader:
    """æ¨¡å‹ä¸‹è½½å™¨"""
    
    def __init__(self, models_dir: str = "data/models/pretrained"):
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        # é¢„å®šä¹‰æ¨¡å‹åˆ—è¡¨
        self.available_models = {
            'brain_inspired_v1.0': {
                'url': 'https://github.com/brain-ai/models/releases/download/v1.0/brain_inspired_v1.0.pth',
                'filename': 'brain_inspired_v1.0.pth',
                'description': 'å®Œæ•´è„‘å¯å‘æ¨¡å‹',
                'size_mb': 50,
                'expected_hash': 'sha256:abc123def456',
                'requirements': ['torch']
            },
            'hippocampus_v1.0': {
                'url': 'https://github.com/brain-ai/models/releases/download/v1.0/hippocampus_v1.0.pth',
                'filename': 'hippocampus_v1.0.pth',
                'description': 'æµ·é©¬ä½“ä¸“ç”¨æ¨¡å‹',
                'size_mb': 30,
                'expected_hash': 'sha256:def456ghi789',
                'requirements': ['torch']
            },
            'neocortex_v1.0': {
                'url': 'https://github.com/brain-ai/models/releases/download/v1.0/neocortex_v1.0.pth',
                'filename': 'neocortex_v1.0.pth',
                'description': 'æ–°çš®å±‚ä¸“ç”¨æ¨¡å‹',
                'size_mb': 40,
                'expected_hash': 'sha256:ghi789jkl012',
                'requirements': ['torch']
            },
            'demo_models_pack': {
                'url': 'https://github.com/brain-ai/models/releases/download/v1.0/demo_models_pack.zip',
                'filename': 'demo_models_pack.zip',
                'description': 'æ¼”ç¤ºæ¨¡å‹åŒ…',
                'size_mb': 100,
                'expected_hash': 'sha256:jkl012mno345',
                'requirements': []
            }
        }
        
    def list_available_models(self) -> Dict:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        print("ğŸ“‹ å¯ç”¨é¢„è®­ç»ƒæ¨¡å‹:")
        print("=" * 60)
        
        for model_id, info in self.available_models.items():
            print(f"ğŸ†” {model_id}")
            print(f"   æè¿°: {info['description']}")
            print(f"   å¤§å°: {info['size_mb']} MB")
            print(f"   æ–‡ä»¶: {info['filename']}")
            print(f"   è¦æ±‚: {', '.join(info['requirements']) if info['requirements'] else 'æ— '}")
            print()
            
        return self.available_models
        
    def download_model(self, model_id: str, force: bool = False) -> bool:
        """ä¸‹è½½æŒ‡å®šæ¨¡å‹"""
        if model_id not in self.available_models:
            print(f"âŒ æœªçŸ¥æ¨¡å‹: {model_id}")
            return False
            
        model_info = self.available_models[model_id]
        local_file = self.models_dir / model_info['filename']
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if local_file.exists() and not force:
            print(f"âœ… æ¨¡å‹å·²å­˜åœ¨: {local_file}")
            
            # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
            if self._verify_file(local_file, model_info.get('expected_hash')):
                print("âœ… æ–‡ä»¶éªŒè¯é€šè¿‡")
                return True
            else:
                print("âš ï¸ æ–‡ä»¶éªŒè¯å¤±è´¥ï¼Œå°†é‡æ–°ä¸‹è½½")
                
        # æ£€æŸ¥ä¾èµ–
        if not self._check_requirements(model_info.get('requirements', [])):
            print(f"âŒ ç¼ºå°‘ä¾èµ–ï¼Œæ— æ³•ä¸‹è½½ {model_id}")
            return False
            
        print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_id}")
        print(f"   URL: {model_info['url']}")
        print(f"   ç›®æ ‡æ–‡ä»¶: {local_file}")
        print(f"   é¢„æœŸå¤§å°: {model_info['size_mb']} MB")
        
        try:
            # ä¸‹è½½æ–‡ä»¶
            success = self._download_file(model_info['url'], local_file)
            
            if success:
                print(f"âœ… ä¸‹è½½å®Œæˆ: {model_id}")
                
                # éªŒè¯æ–‡ä»¶
                if self._verify_file(local_file, model_info.get('expected_hash')):
                    print("âœ… æ–‡ä»¶éªŒè¯é€šè¿‡")
                    return True
                else:
                    print("âš ï¸ æ–‡ä»¶éªŒè¯å¤±è´¥")
                    return False
            else:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {model_id}")
                return False
                
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¼‚å¸¸: {e}")
            return False
            
    def _check_requirements(self, requirements: List[str]) -> bool:
        """æ£€æŸ¥ä¾èµ–è¦æ±‚"""
        for req in requirements:
            try:
                if req == 'torch':
                    import torch
                    print(f"âœ… {req}: {torch.__version__}")
                elif req == 'tensorflow':
                    import tensorflow
                    print(f"âœ… {req}: {tensorflow.__version__}")
                else:
                    __import__(req)
                    print(f"âœ… {req}: å·²å®‰è£…")
            except ImportError:
                print(f"âŒ {req}: æœªå®‰è£…")
                return False
                
        return True
        
    def _download_file(self, url: str, local_file: Path) -> bool:
        """ä¸‹è½½æ–‡ä»¶"""
        try:
            response = requests.get(url, stream=True, timeout=30)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(local_file, 'wb') as f:
                downloaded = 0
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        
                        # æ˜¾ç¤ºè¿›åº¦
                        if total_size > 0:
                            percent = (downloaded / total_size) * 100
                            print(f"\r   è¿›åº¦: {percent:.1f}% ({downloaded//1024//1024}/{total_size//1024//1024} MB)", end='')
                            
            print()  # æ¢è¡Œ
            return True
            
        except requests.RequestException as e:
            print(f"\nâŒ ç½‘ç»œé”™è¯¯: {e}")
            return False
        except Exception as e:
            print(f"\nâŒ ä¸‹è½½é”™è¯¯: {e}")
            return False
            
    def _verify_file(self, file_path: Path, expected_hash: Optional[str]) -> bool:
        """éªŒè¯æ–‡ä»¶å®Œæ•´æ€§"""
        if not expected_hash or not file_path.exists():
            return True
            
        try:
            # ç®€åŒ–çš„å“ˆå¸ŒéªŒè¯
            if expected_hash.startswith('sha256:'):
                expected = expected_hash[7:]  # å»æ‰ 'sha256:' å‰ç¼€
                
                # è®¡ç®—å®é™…å“ˆå¸Œ
                sha256_hash = hashlib.sha256()
                with open(file_path, 'rb') as f:
                    for chunk in iter(lambda: f.read(4096), b""):
                        sha256_hash.update(chunk)
                        
                actual = sha256_hash.hexdigest()
                
                if actual == expected:
                    print(f"âœ… å“ˆå¸ŒéªŒè¯é€šè¿‡: {actual[:8]}...")
                    return True
                else:
                    print(f"âŒ å“ˆå¸ŒéªŒè¯å¤±è´¥: æœŸæœ› {expected[:8]}..., å®é™… {actual[:8]}...")
                    return False
            else:
                print("âš ï¸ ä¸æ”¯æŒçš„å“ˆå¸Œæ ¼å¼ï¼Œè·³è¿‡éªŒè¯")
                return True
                
        except Exception as e:
            print(f"âš ï¸ å“ˆå¸ŒéªŒè¯å¤±è´¥: {e}")
            return False
            
    def download_all(self, force: bool = False) -> Dict[str, bool]:
        """ä¸‹è½½æ‰€æœ‰æ¨¡å‹"""
        print("ğŸ“¦ ä¸‹è½½æ‰€æœ‰é¢„è®­ç»ƒæ¨¡å‹")
        print("=" * 50)
        
        results = {}
        for model_id in self.available_models.keys():
            print(f"\nå¤„ç†æ¨¡å‹: {model_id}")
            results[model_id] = self.download_model(model_id, force)
            
        # æ€»ç»“
        successful = sum(1 for success in results.values() if success)
        total = len(results)
        
        print(f"\nğŸ“Š ä¸‹è½½æ€»ç»“:")
        print(f"   æˆåŠŸ: {successful}/{total}")
        print(f"   æˆåŠŸç‡: {successful/total:.1%}")
        
        if successful == total:
            print("ğŸ‰ æ‰€æœ‰æ¨¡å‹ä¸‹è½½æˆåŠŸ!")
        elif successful > 0:
            print("ğŸ‘ éƒ¨åˆ†æ¨¡å‹ä¸‹è½½æˆåŠŸ")
        else:
            print("ğŸ˜ æ‰€æœ‰æ¨¡å‹ä¸‹è½½å¤±è´¥")
            
        return results
        
    def list_downloaded_models(self) -> Dict[str, Dict]:
        """åˆ—å‡ºå·²ä¸‹è½½çš„æ¨¡å‹"""
        print("ğŸ“‚ å·²ä¸‹è½½çš„æ¨¡å‹:")
        print("=" * 50)
        
        downloaded = {}
        
        for model_id, info in self.available_models.items():
            local_file = self.models_dir / info['filename']
            
            if local_file.exists():
                file_size = local_file.stat().st_size / 1024 / 1024  # MB
                download_time = local_file.stat().st_mtime
                
                downloaded[model_id] = {
                    'file_path': str(local_file),
                    'file_size_mb': round(file_size, 2),
                    'download_time': download_time,
                    'info': info
                }
                
                print(f"âœ… {model_id}")
                print(f"   æ–‡ä»¶: {local_file}")
                print(f"   å¤§å°: {file_size:.1f} MB")
                print(f"   æè¿°: {info['description']}")
                print()
            else:
                print(f"âŒ {model_id} (æœªä¸‹è½½)")
                print()
                
        return downloaded
        
    def delete_model(self, model_id: str) -> bool:
        """åˆ é™¤æ¨¡å‹"""
        if model_id not in self.available_models:
            print(f"âŒ æœªçŸ¥æ¨¡å‹: {model_id}")
            return False
            
        model_info = self.available_models[model_id]
        local_file = self.models_dir / model_info['filename']
        
        if local_file.exists():
            try:
                local_file.unlink()
                print(f"âœ… å·²åˆ é™¤æ¨¡å‹: {model_id}")
                return True
            except Exception as e:
                print(f"âŒ åˆ é™¤å¤±è´¥: {e}")
                return False
        else:
            print(f"âš ï¸ æ¨¡å‹ä¸å­˜åœ¨: {model_id}")
            return True
            
    def cleanup_downloads(self) -> int:
        """æ¸…ç†æŸåçš„ä¸‹è½½æ–‡ä»¶"""
        print("ğŸ§¹ æ¸…ç†ä¸‹è½½æ–‡ä»¶")
        print("=" * 30)
        
        cleaned = 0
        
        for model_id, info in self.available_models.items():
            local_file = self.models_dir / info['filename']
            
            if local_file.exists():
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æŸåï¼ˆå¤§å°ä¸º0æˆ–å¼‚å¸¸å°ï¼‰
                file_size = local_file.stat().st_size
                expected_size_mb = info['size_mb']
                expected_size = expected_size_mb * 1024 * 1024
                
                if file_size == 0 or file_size < expected_size * 0.1:  # å°äºé¢„æœŸçš„10%
                    try:
                        local_file.unlink()
                        print(f"   æ¸…ç†æŸåæ–‡ä»¶: {model_id}")
                        cleaned += 1
                    except Exception as e:
                        print(f"   æ¸…ç†å¤±è´¥ {model_id}: {e}")
                        
        print(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleaned} ä¸ªæ–‡ä»¶")
        return cleaned


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å·¥å…·')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹')
    parser.add_argument('--download', help='ä¸‹è½½æŒ‡å®šæ¨¡å‹')
    parser.add_argument('--download-all', action='store_true', help='ä¸‹è½½æ‰€æœ‰æ¨¡å‹')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶é‡æ–°ä¸‹è½½')
    parser.add_argument('--installed', action='store_true', help='åˆ—å‡ºå·²å®‰è£…çš„æ¨¡å‹')
    parser.add_argument('--delete', help='åˆ é™¤æŒ‡å®šæ¨¡å‹')
    parser.add_argument('--cleanup', action='store_true', help='æ¸…ç†æŸåçš„æ–‡ä»¶')
    parser.add_argument('--models-dir', default='data/models/pretrained', help='æ¨¡å‹å­˜å‚¨ç›®å½•')
    
    args = parser.parse_args()
    
    downloader = ModelDownloader(args.models_dir)
    
    if args.list:
        downloader.list_available_models()
        
    elif args.download:
        downloader.download_model(args.download, args.force)
        
    elif args.download_all:
        downloader.download_all(args.force)
        
    elif args.installed:
        downloader.list_downloaded_models()
        
    elif args.delete:
        downloader.delete_model(args.delete)
        
    elif args.cleanup:
        downloader.cleanup_downloads()
        
    else:
        print("ğŸ› ï¸ é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½å·¥å…·")
        print("ä½¿ç”¨ --help æŸ¥çœ‹å¯ç”¨é€‰é¡¹")
        print("\nå¸¸ç”¨å‘½ä»¤:")
        print("  python download_models.py --list                    # åˆ—å‡ºæ‰€æœ‰æ¨¡å‹")
        print("  python download_models.py --download brain_inspired_v1.0  # ä¸‹è½½æŒ‡å®šæ¨¡å‹")
        print("  python download_models.py --download-all           # ä¸‹è½½æ‰€æœ‰æ¨¡å‹")
        print("  python download_models.py --installed              # æŸ¥çœ‹å·²å®‰è£…æ¨¡å‹")


if __name__ == "__main__":
    main()