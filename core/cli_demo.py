#!/usr/bin/env python3
"""
è„‘å¯å‘AIæ¼”ç¤ºç³»ç»Ÿ - äº¤äº’å¼å‘½ä»¤è¡Œç•Œé¢
Brain-Inspired AI Demo System - Interactive Command Line Interface

æä¾›å®Œæ•´çš„ç³»ç»Ÿæ¼”ç¤ºåŠŸèƒ½ï¼š
- ç³»ç»Ÿåˆå§‹åŒ–å’Œé…ç½®
- æ•°æ®è¾“å…¥å’Œé¢„å¤„ç†
- è®­ç»ƒæ§åˆ¶å’Œç›‘æ§
- ç»“æœå±•ç¤ºå’Œåˆ†æ
"""

import os
import sys
import json
import time
import argparse
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("è­¦å‘Š: PyTorchæœªå®‰è£…ï¼Œéƒ¨åˆ†åŠŸèƒ½å°†ä¸å¯ç”¨")

class BrainInspiredAISystem:
    """è„‘å¯å‘AIæ¼”ç¤ºç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self):
        self.config = None
        self.models = {}
        self.data_loaders = {}
        self.results = {}
        self.initialized = False
        
    def initialize_system(self, config_path: str = "config.yaml"):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        print("ğŸ§  æ­£åœ¨åˆå§‹åŒ–è„‘å¯å‘AIç³»ç»Ÿ...")
        
        # æ£€æŸ¥ä¾èµ–
        self._check_dependencies()
        
        # åŠ è½½é…ç½®
        self.config = self._load_config(config_path)
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        self._create_directories()
        
        self.initialized = True
        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!")
        return True
        
    def _check_dependencies(self):
        """æ£€æŸ¥ç³»ç»Ÿä¾èµ–"""
        print("ğŸ“‹ æ£€æŸ¥ç³»ç»Ÿä¾èµ–...")
        
        dependencies = {
            'torch': TORCH_AVAILABLE,
            'numpy': True,
            'pathlib': True
        }
        
        missing = [name for name, available in dependencies.items() if not available]
        
        if missing:
            print(f"âŒ ç¼ºå°‘ä¾èµ–: {', '.join(missing)}")
            print("è¯·å®‰è£…ç¼ºå°‘çš„ä¾èµ–åé‡æ–°è¿è¡Œ")
            return False
        
        print("âœ… æ‰€æœ‰ä¾èµ–æ£€æŸ¥é€šè¿‡")
        return True
        
    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        default_config = {
            'model': {
                'name': 'BrainInspiredNet',
                'hidden_size': 256,
                'num_layers': 4,
                'dropout': 0.1
            },
            'training': {
                'batch_size': 32,
                'learning_rate': 0.001,
                'epochs': 100,
                'early_stopping': True,
                'patience': 10
            },
            'hippocampus': {
                'memory_capacity': 1000,
                'encoding_dim': 128,
                'retrieval_threshold': 0.7
            },
            'neocortex': {
                'layers': 6,
                'abstraction_levels': 3
            }
        }
        
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                print(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_path}")
                return {**default_config, **config}
            except Exception as e:
                print(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
        
        return default_config
        
    def _create_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„"""
        directories = [
            'data/datasets',
            'data/models',
            'data/results',
            'logs',
            'visualizations'
        ]
        
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
            
        print("ğŸ“ ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ")
        
    def generate_sample_data(self, dataset_name: str = "synthetic"):
        """ç”Ÿæˆç¤ºä¾‹æ•°æ®é›†"""
        print(f"ğŸ“Š ç”Ÿæˆç¤ºä¾‹æ•°æ®é›†: {dataset_name}")
        
        if dataset_name == "synthetic":
            return self._generate_synthetic_data()
        elif dataset_name == "mnist":
            return self._generate_mnist_like_data()
        elif dataset_name == "patterns":
            return self._generate_pattern_data()
        else:
            raise ValueError(f"æœªçŸ¥æ•°æ®é›†ç±»å‹: {dataset_name}")
            
    def _generate_synthetic_data(self):
        """ç”Ÿæˆåˆæˆæ•°æ®é›†"""
        np.random.seed(42)
        
        # ç”Ÿæˆè®­ç»ƒæ•°æ®
        train_size = 1000
        input_dim = 20
        output_dim = 5
        
        X_train = np.random.randn(train_size, input_dim).astype(np.float32)
        y_train = np.random.randint(0, output_dim, train_size)
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        test_size = 200
        X_test = np.random.randn(test_size, input_dim).astype(np.float32)
        y_test = np.random.randint(0, output_dim, test_size)
        
        data = {
            'X_train': X_train,
            'y_train': y_train,
            'X_test': X_test,
            'y_test': y_test,
            'input_dim': input_dim,
            'output_dim': output_dim
        }
        
        print(f"âœ… åˆæˆæ•°æ®ç”Ÿæˆå®Œæˆ - è®­ç»ƒæ ·æœ¬: {train_size}, æµ‹è¯•æ ·æœ¬: {test_size}")
        return data
        
    def _generate_mnist_like_data(self):
        """ç”ŸæˆMNISTé£æ ¼çš„æ•°æ®"""
        np.random.seed(42)
        
        train_size = 1000
        test_size = 200
        image_size = 28 * 28
        num_classes = 10
        
        X_train = np.random.randn(train_size, image_size).astype(np.float32)
        y_train = np.random.randint(0, num_classes, train_size)
        
        X_test = np.random.randn(test_size, image_size).astype(np.float32)
        y_test = np.random.randint(0, num_classes, test_size)
        
        data = {
            'X_train': X_train,
            'y_train': y_train,
            'X_test': X_test,
            'y_test': y_test,
            'input_dim': image_size,
            'output_dim': num_classes,
            'dataset_type': 'mnist_like'
        }
        
        print(f"âœ… MNISTé£æ ¼æ•°æ®ç”Ÿæˆå®Œæˆ")
        return data
        
    def _generate_pattern_data(self):
        """ç”Ÿæˆæ¨¡å¼è¯†åˆ«æ•°æ®"""
        np.random.seed(42)
        
        # ç”Ÿæˆå…·æœ‰æ˜ç¡®æ¨¡å¼çš„åˆ†ç±»æ•°æ®
        train_size = 800
        test_size = 200
        input_dim = 10
        num_classes = 4
        
        X_train = []
        y_train = []
        
        for i in range(train_size):
            class_id = i % num_classes
            pattern = np.zeros(input_dim)
            
            # ä¸ºæ¯ä¸ªç±»åˆ«åˆ›å»ºç‰¹å®šæ¨¡å¼
            if class_id == 0:
                pattern[:3] = np.random.normal(2, 0.5, 3)
            elif class_id == 1:
                pattern[3:6] = np.random.normal(2, 0.5, 3)
            elif class_id == 2:
                pattern[6:9] = np.random.normal(2, 0.5, 3)
            else:
                pattern[9] = np.random.normal(2, 0.5, 1)
                
            X_train.append(pattern)
            y_train.append(class_id)
            
        X_train = np.array(X_train).astype(np.float32)
        y_train = np.array(y_train).astype(np.int64)
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        X_test = []
        y_test = []
        
        for i in range(test_size):
            class_id = i % num_classes
            pattern = np.zeros(input_dim)
            
            if class_id == 0:
                pattern[:3] = np.random.normal(2, 0.5, 3)
            elif class_id == 1:
                pattern[3:6] = np.random.normal(2, 0.5, 3)
            elif class_id == 2:
                pattern[6:9] = np.random.normal(2, 0.5, 3)
            else:
                pattern[9] = np.random.normal(2, 0.5, 1)
                
            X_test.append(pattern)
            y_test.append(class_id)
            
        X_test = np.array(X_test).astype(np.float32)
        y_test = np.array(y_test).astype(np.int64)
        
        data = {
            'X_train': X_train,
            'y_train': y_train,
            'X_test': X_test,
            'y_test': y_test,
            'input_dim': input_dim,
            'output_dim': num_classes,
            'dataset_type': 'patterns'
        }
        
        print(f"âœ… æ¨¡å¼è¯†åˆ«æ•°æ®ç”Ÿæˆå®Œæˆ")
        return data
        
    def create_models(self, model_type: str = "brain_inspired"):
        """åˆ›å»ºæ¨¡å‹"""
        print(f"ğŸ—ï¸ åˆ›å»ºæ¨¡å‹: {model_type}")
        
        if not TORCH_AVAILABLE:
            print("âŒ PyTorchä¸å¯ç”¨ï¼Œæ— æ³•åˆ›å»ºæ·±åº¦å­¦ä¹ æ¨¡å‹")
            return {}
            
        if model_type == "brain_inspired":
            return self._create_brain_inspired_model()
        elif model_type == "hippocampus_only":
            return self._create_hippocampus_model()
        elif model_type == "neocortex_only":
            return self._create_neocortex_model()
        else:
            raise ValueError(f"æœªçŸ¥æ¨¡å‹ç±»å‹: {model_type}")
            
    def _create_brain_inspired_model(self):
        """åˆ›å»ºè„‘å¯å‘æ¨¡å‹"""
        class BrainInspiredNet(nn.Module):
            def __init__(self, input_dim, hidden_dim, output_dim, num_layers=4):
                super().__init__()
                self.input_dim = input_dim
                self.hidden_dim = hidden_dim
                self.output_dim = output_dim
                self.num_layers = num_layers
                
                # è¾“å…¥å±‚
                self.input_layer = nn.Linear(input_dim, hidden_dim)
                
                # éšè—å±‚
                self.hidden_layers = nn.ModuleList([
                    nn.Linear(hidden_dim, hidden_dim) for _ in range(num_layers - 2)
                ])
                
                # æµ·é©¬ä½“è®°å¿†å±‚ï¼ˆç®€åŒ–çš„æ³¨æ„åŠ›æœºåˆ¶ï¼‰
                self.hippocampus_layer = nn.MultiheadAttention(
                    hidden_dim, num_heads=8, batch_first=True
                )
                
                # æ–°çš®å±‚æŠ½è±¡å±‚
                self.neocortex_layers = nn.ModuleList([
                    nn.Linear(hidden_dim, hidden_dim // 2),
                    nn.Linear(hidden_dim // 2, hidden_dim // 4)
                ])
                
                # è¾“å‡ºå±‚
                self.output_layer = nn.Linear(hidden_dim // 4, output_dim)
                
                # æ¿€æ´»å‡½æ•°
                self.activation = nn.ReLU()
                self.dropout = nn.Dropout(0.1)
                
            def forward(self, x):
                # è¾“å…¥å±‚
                x = self.activation(self.input_layer(x))
                x = self.dropout(x)
                
                # éšè—å±‚
                for layer in self.hidden_layers:
                    x = self.activation(layer(x))
                    x = self.dropout(x)
                
                # æµ·é©¬ä½“å±‚ï¼ˆæ³¨æ„åŠ›æœºåˆ¶ï¼‰
                x = x.unsqueeze(1)  # æ·»åŠ åºåˆ—ç»´åº¦
                attended_x, _ = self.hippocampus_layer(x, x, x)
                x = attended_x.squeeze(1)
                
                # æ–°çš®å±‚æŠ½è±¡
                for layer in self.neocortex_layers:
                    x = self.activation(layer(x))
                    x = self.dropout(x)
                
                # è¾“å‡ºå±‚
                output = self.output_layer(x)
                return output
                
        # è·å–æ•°æ®ç»´åº¦
        if hasattr(self, 'current_data'):
            input_dim = self.current_data['input_dim']
            output_dim = self.current_data['output_dim']
        else:
            input_dim = 20
            output_dim = 5
            
        hidden_dim = self.config['model']['hidden_size']
        num_layers = self.config['model']['num_layers']
        
        model = BrainInspiredNet(input_dim, hidden_dim, output_dim, num_layers)
        
        print(f"âœ… è„‘å¯å‘æ¨¡å‹åˆ›å»ºå®Œæˆ")
        print(f"   - è¾“å…¥ç»´åº¦: {input_dim}")
        print(f"   - éšè—ç»´åº¦: {hidden_dim}")
        print(f"   - è¾“å‡ºç»´åº¦: {output_dim}")
        print(f"   - å±‚æ•°: {num_layers}")
        
        return {'brain_inspired': model}
        
    def _create_hippocampus_model(self):
        """åˆ›å»ºæµ·é©¬ä½“ä¸“ç”¨æ¨¡å‹"""
        class HippocampusModel(nn.Module):
            def __init__(self, input_dim, hidden_dim, output_dim):
                super().__init__()
                self.encoder = nn.Sequential(
                    nn.Linear(input_dim, hidden_dim),
                    nn.ReLU(),
                    nn.Dropout(0.1)
                )
                self.attention = nn.MultiheadAttention(hidden_dim, num_heads=4, batch_first=True)
                self.decoder = nn.Sequential(
                    nn.Linear(hidden_dim, hidden_dim // 2),
                    nn.ReLU(),
                    nn.Linear(hidden_dim // 2, output_dim)
                )
                
            def forward(self, x):
                x = self.encoder(x)
                x = x.unsqueeze(1)
                attended_x, _ = self.attention(x, x, x)
                x = attended_x.squeeze(1)
                output = self.decoder(x)
                return output
                
        input_dim = self.current_data['input_dim']
        output_dim = self.current_data['output_dim']
        hidden_dim = self.config['model']['hidden_size']
        
        model = HippocampusModel(input_dim, hidden_dim, output_dim)
        
        print(f"âœ… æµ·é©¬ä½“æ¨¡å‹åˆ›å»ºå®Œæˆ")
        return {'hippocampus': model}
        
    def _create_neocortex_model(self):
        """åˆ›å»ºæ–°çš®å±‚ä¸“ç”¨æ¨¡å‹"""
        class NeocortexModel(nn.Module):
            def __init__(self, input_dim, hidden_dim, output_dim):
                super().__init__()
                self.abstraction_layers = nn.ModuleList([
                    nn.Linear(hidden_dim, hidden_dim // (i + 2)) for i in range(3)
                ])
                self.classifier = nn.Linear(hidden_dim // 3, output_dim)
                self.activation = nn.ReLU()
                self.dropout = nn.Dropout(0.1)
                
                # é¢„ç¼–ç å™¨
                self.encoder = nn.Sequential(
                    nn.Linear(input_dim, hidden_dim),
                    nn.ReLU(),
                    nn.Dropout(0.1)
                )
                
            def forward(self, x):
                x = self.encoder(x)
                
                for layer in self.abstraction_layers:
                    x = self.activation(layer(x))
                    x = self.dropout(x)
                
                output = self.classifier(x)
                return output
                
        input_dim = self.current_data['input_dim']
        output_dim = self.current_data['output_dim']
        hidden_dim = self.config['model']['hidden_size']
        
        model = NeocortexModel(input_dim, hidden_dim, output_dim)
        
        print(f"âœ… æ–°çš®å±‚æ¨¡å‹åˆ›å»ºå®Œæˆ")
        return {'neocortex': model}
        
    def train_model(self, model_name: str, data: Dict, epochs: Optional[int] = None):
        """è®­ç»ƒæ¨¡å‹"""
        if not TORCH_AVAILABLE:
            print("âŒ PyTorchä¸å¯ç”¨ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
            return {}
            
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹: {model_name}")
        
        if model_name not in self.models:
            print(f"âŒ æ¨¡å‹ {model_name} ä¸å­˜åœ¨")
            return {}
            
        model = self.models[model_name]
        if not hasattr(model, 'train'):
            print(f"âŒ å¯¹è±¡ {model_name} ä¸æ˜¯PyTorchæ¨¡å‹")
            return {}
            
        # å‡†å¤‡æ•°æ®
        X_train = torch.FloatTensor(data['X_train'])
        y_train = torch.LongTensor(data['y_train'])
        X_test = torch.FloatTensor(data['X_test'])
        y_test = torch.LongTensor(data['y_test'])
        
        train_dataset = TensorDataset(X_train, y_train)
        train_loader = DataLoader(train_dataset, batch_size=self.config['training']['batch_size'], shuffle=True)
        
        # è®¾ç½®è®­ç»ƒå‚æ•°
        epochs = epochs or self.config['training']['epochs']
        learning_rate = self.config['training']['learning_rate']
        
        # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        
        # è®­ç»ƒå¾ªç¯
        model.train()
        train_losses = []
        test_accuracies = []
        
        print(f"ğŸ“ˆ è®­ç»ƒå‚æ•°: epochs={epochs}, batch_size={self.config['training']['batch_size']}, lr={learning_rate}")
        
        for epoch in range(epochs):
            epoch_loss = 0.0
            num_batches = 0
            
            for batch_X, batch_y in train_loader:
                optimizer.zero_grad()
                
                outputs = model(batch_X)
                loss = criterion(outputs, batch_y)
                
                loss.backward()
                optimizer.step()
                
                epoch_loss += loss.item()
                num_batches += 1
            
            avg_loss = epoch_loss / num_batches
            train_losses.append(avg_loss)
            
            # è¯„ä¼°
            model.eval()
            with torch.no_grad():
                test_outputs = model(X_test)
                _, predicted = torch.max(test_outputs.data, 1)
                accuracy = (predicted == y_test).float().mean().item()
                test_accuracies.append(accuracy)
            model.train()
            
            # æ‰“å°è¿›åº¦
            if (epoch + 1) % max(1, epochs // 10) == 0:
                print(f"   Epoch {epoch+1}/{epochs}: Loss={avg_loss:.4f}, Accuracy={accuracy:.4f}")
        
        # ä¿å­˜è®­ç»ƒç»“æœ
        results = {
            'model_name': model_name,
            'epochs': epochs,
            'final_loss': train_losses[-1],
            'final_accuracy': test_accuracies[-1],
            'train_losses': train_losses,
            'test_accuracies': test_accuracies,
            'training_time': time.time()
        }
        
        self.results[model_name] = results
        
        print(f"âœ… è®­ç»ƒå®Œæˆ!")
        print(f"   - æœ€ç»ˆæŸå¤±: {train_losses[-1]:.4f}")
        print(f"   - æœ€ç»ˆå‡†ç¡®ç‡: {test_accuracies[-1]:.4f}")
        
        return results
        
    def evaluate_model(self, model_name: str, data: Dict):
        """è¯„ä¼°æ¨¡å‹"""
        if not TORCH_AVAILABLE:
            print("âŒ PyTorchä¸å¯ç”¨ï¼Œæ— æ³•è¯„ä¼°æ¨¡å‹")
            return {}
            
        print(f"ğŸ“Š è¯„ä¼°æ¨¡å‹: {model_name}")
        
        if model_name not in self.models:
            print(f"âŒ æ¨¡å‹ {model_name} ä¸å­˜åœ¨")
            return {}
            
        model = self.models[model_name]
        
        X_test = torch.FloatTensor(data['X_test'])
        y_test = torch.LongTensor(data['y_test'])
        
        model.eval()
        with torch.no_grad():
            outputs = model(X_test)
            _, predicted = torch.max(outputs.data, 1)
            accuracy = (predicted == y_test).float().mean().item()
            
            # è®¡ç®—åˆ†ç±»æŠ¥å‘Š
            from sklearn.metrics import classification_report, confusion_matrix
            
            y_pred = predicted.numpy()
            y_true = y_test.numpy()
            
            report = classification_report(y_true, y_pred, output_dict=True)
            confusion = confusion_matrix(y_true, y_pred)
            
        evaluation_results = {
            'model_name': model_name,
            'accuracy': accuracy,
            'classification_report': report,
            'confusion_matrix': confusion.tolist(),
            'num_test_samples': len(y_test)
        }
        
        print(f"âœ… è¯„ä¼°å®Œæˆ!")
        print(f"   - å‡†ç¡®ç‡: {accuracy:.4f}")
        print(f"   - æµ‹è¯•æ ·æœ¬æ•°: {len(y_test)}")
        
        return evaluation_results
        
    def save_results(self, filename: str = None):
        """ä¿å­˜ç»“æœ"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"results/demo_results_{timestamp}.json"
            
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
            
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        
    def load_results(self, filename: str):
        """åŠ è½½ç»“æœ"""
        if os.path.exists(filename):
            with open(filename, 'r', encoding='utf-8') as f:
                self.results = json.load(f)
            print(f"ğŸ“‚ ç»“æœå·²ä» {filename} åŠ è½½")
            return True
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            return False
            
    def visualize_results(self, save_plots: bool = True):
        """å¯è§†åŒ–ç»“æœ"""
        try:
            import matplotlib.pyplot as plt
            
            print("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
            
            if not self.results:
                print("âŒ æ²¡æœ‰ç»“æœå¯ä»¥å¯è§†åŒ–")
                return
                
            # è®­ç»ƒæ›²çº¿
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('è„‘å¯å‘AIæ¼”ç¤ºç»“æœ', fontsize=16)
            
            for i, (model_name, result) in enumerate(self.results.items()):
                if 'train_losses' in result and 'test_accuracies' in result:
                    # æŸå¤±æ›²çº¿
                    axes[0, 0].plot(result['train_losses'], label=f'{model_name} Loss')
                    axes[0, 0].set_title('è®­ç»ƒæŸå¤±')
                    axes[0, 0].set_xlabel('Epoch')
                    axes[0, 0].set_ylabel('Loss')
                    axes[0, 0].legend()
                    axes[0, 0].grid(True)
                    
                    # å‡†ç¡®ç‡æ›²çº¿
                    axes[0, 1].plot(result['test_accuracies'], label=f'{model_name} Accuracy')
                    axes[0, 1].set_title('æµ‹è¯•å‡†ç¡®ç‡')
                    axes[0, 1].set_xlabel('Epoch')
                    axes[0, 1].set_ylabel('Accuracy')
                    axes[0, 1].legend()
                    axes[0, 1].grid(True)
            
            # æ€§èƒ½å¯¹æ¯”
            model_names = list(self.results.keys())
            accuracies = [self.results[name].get('final_accuracy', 0) for name in model_names]
            
            axes[1, 0].bar(model_names, accuracies)
            axes[1, 0].set_title('æ¨¡å‹æ€§èƒ½å¯¹æ¯”')
            axes[1, 0].set_ylabel('å‡†ç¡®ç‡')
            axes[1, 0].tick_params(axis='x', rotation=45)
            
            # æ¨¡å‹å‚æ•°ç»Ÿè®¡
            param_counts = []
            for model_name in model_names:
                if model_name in self.models:
                    model = self.models[model_name]
                    if hasattr(model, 'parameters'):
                        param_count = sum(p.numel() for p in model.parameters())
                        param_counts.append(param_count)
                    else:
                        param_counts.append(0)
                else:
                    param_counts.append(0)
            
            axes[1, 1].bar(model_names, param_counts)
            axes[1, 1].set_title('æ¨¡å‹å‚æ•°æ•°é‡')
            axes[1, 1].set_ylabel('å‚æ•°æ•°é‡')
            axes[1, 1].tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            
            if save_plots:
                os.makedirs('visualizations', exist_ok=True)
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                plot_filename = f"visualizations/demo_results_{timestamp}.png"
                plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
                print(f"ğŸ“ˆ å›¾è¡¨å·²ä¿å­˜åˆ°: {plot_filename}")
            
            plt.show()
            
        except ImportError:
            print("âš ï¸ matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")


def interactive_demo():
    """äº¤äº’å¼æ¼”ç¤ºæ¨¡å¼"""
    print("ğŸ§  è„‘å¯å‘AIæ¼”ç¤ºç³»ç»Ÿ")
    print("=" * 50)
    
    system = BrainInspiredAISystem()
    
    # ç³»ç»Ÿåˆå§‹åŒ–
    print("\n1ï¸âƒ£ ç³»ç»Ÿåˆå§‹åŒ–")
    if not system.initialize_system():
        return
        
    while True:
        print("\n" + "=" * 50)
        print("é€‰æ‹©æ¼”ç¤ºåŠŸèƒ½:")
        print("1. æ•°æ®ç”Ÿæˆ")
        print("2. æ¨¡å‹åˆ›å»º") 
        print("3. æ¨¡å‹è®­ç»ƒ")
        print("4. æ¨¡å‹è¯„ä¼°")
        print("5. ç»“æœå¯è§†åŒ–")
        print("6. ä¿å­˜/åŠ è½½ç»“æœ")
        print("7. è¿è¡Œå®Œæ•´æ¼”ç¤º")
        print("0. é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-7): ").strip()
        
        if choice == "0":
            print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨è„‘å¯å‘AIæ¼”ç¤ºç³»ç»Ÿ!")
            break
        elif choice == "1":
            print("\nğŸ“Š æ•°æ®ç”Ÿæˆé€‰é¡¹:")
            print("1. åˆæˆæ•°æ®")
            print("2. MNISTé£æ ¼æ•°æ®") 
            print("3. æ¨¡å¼è¯†åˆ«æ•°æ®")
            
            data_choice = input("é€‰æ‹©æ•°æ®ç±»å‹ (1-3): ").strip()
            
            if data_choice == "1":
                data = system.generate_sample_data("synthetic")
            elif data_choice == "2":
                data = system.generate_sample_data("mnist")
            elif data_choice == "3":
                data = system.generate_sample_data("patterns")
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")
                continue
                
            system.current_data = data
            print(f"âœ… æ•°æ®ç”Ÿæˆå®Œæˆ - è®­ç»ƒæ ·æœ¬: {len(data['X_train'])}, æµ‹è¯•æ ·æœ¬: {len(data['X_test'])}")
            
        elif choice == "2":
            print("\nğŸ—ï¸ æ¨¡å‹åˆ›å»ºé€‰é¡¹:")
            print("1. è„‘å¯å‘å®Œæ•´æ¨¡å‹")
            print("2. æµ·é©¬ä½“ä¸“ç”¨æ¨¡å‹")
            print("3. æ–°çš®å±‚ä¸“ç”¨æ¨¡å‹")
            
            model_choice = input("é€‰æ‹©æ¨¡å‹ç±»å‹ (1-3): ").strip()
            
            if model_choice == "1":
                models = system.create_models("brain_inspired")
            elif model_choice == "2":
                models = system.create_models("hippocampus_only")
            elif model_choice == "3":
                models = system.create_models("neocortex_only")
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")
                continue
                
            system.models.update(models)
            print(f"âœ… æ¨¡å‹åˆ›å»ºå®Œæˆ: {list(models.keys())}")
            
        elif choice == "3":
            if not system.models:
                print("âŒ è¯·å…ˆåˆ›å»ºæ¨¡å‹")
                continue
                
            print("\nè®­ç»ƒæ¨¡å‹é€‰æ‹©:")
            for i, model_name in enumerate(system.models.keys(), 1):
                print(f"{i}. {model_name}")
                
            train_choice = input(f"é€‰æ‹©è¦è®­ç»ƒçš„æ¨¡å‹ (1-{len(system.models)}): ").strip()
            
            try:
                model_idx = int(train_choice) - 1
                model_name = list(system.models.keys())[model_idx]
                
                epochs_input = input("è®­ç»ƒè½®æ•° (é»˜è®¤100): ").strip()
                epochs = int(epochs_input) if epochs_input else 100
                
                if not hasattr(system, 'current_data'):
                    print("âŒ è¯·å…ˆç”Ÿæˆæ•°æ®")
                    continue
                    
                result = system.train_model(model_name, system.current_data, epochs)
                print(f"âœ… {model_name} è®­ç»ƒå®Œæˆ")
                
            except (ValueError, IndexError):
                print("âŒ æ— æ•ˆé€‰æ‹©")
                
        elif choice == "4":
            if not system.models:
                print("âŒ è¯·å…ˆåˆ›å»ºæ¨¡å‹")
                continue
                
            print("\nè¯„ä¼°æ¨¡å‹é€‰æ‹©:")
            for i, model_name in enumerate(system.models.keys(), 1):
                print(f"{i}. {model_name}")
                
            eval_choice = input(f"é€‰æ‹©è¦è¯„ä¼°çš„æ¨¡å‹ (1-{len(system.models)}): ").strip()
            
            try:
                model_idx = int(eval_choice) - 1
                model_name = list(system.models.keys())[model_idx]
                
                if not hasattr(system, 'current_data'):
                    print("âŒ è¯·å…ˆç”Ÿæˆæ•°æ®")
                    continue
                    
                evaluation = system.evaluate_model(model_name, system.current_data)
                print(f"âœ… {model_name} è¯„ä¼°å®Œæˆ")
                
            except (ValueError, IndexError):
                print("âŒ æ— æ•ˆé€‰æ‹©")
                
        elif choice == "5":
            system.visualize_results()
            
        elif choice == "6":
            print("\nä¿å­˜/åŠ è½½é€‰é¡¹:")
            print("1. ä¿å­˜ç»“æœ")
            print("2. åŠ è½½ç»“æœ")
            
            save_choice = input("é€‰æ‹©æ“ä½œ (1-2): ").strip()
            
            if save_choice == "1":
                filename = input("ä¿å­˜æ–‡ä»¶å (å¯é€‰): ").strip()
                if not filename:
                    system.save_results()
                else:
                    system.save_results(filename)
            elif save_choice == "2":
                filename = input("åŠ è½½æ–‡ä»¶å: ").strip()
                system.load_results(filename)
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")
                
        elif choice == "7":
            print("\nğŸš€ è¿è¡Œå®Œæ•´æ¼”ç¤º...")
            
            # ç”Ÿæˆæ•°æ®
            print("1. ç”Ÿæˆåˆæˆæ•°æ®")
            data = system.generate_sample_data("synthetic")
            system.current_data = data
            
            # åˆ›å»ºæ¨¡å‹
            print("2. åˆ›å»ºè„‘å¯å‘æ¨¡å‹")
            models = system.create_models("brain_inspired")
            system.models.update(models)
            
            # è®­ç»ƒæ¨¡å‹
            print("3. è®­ç»ƒæ¨¡å‹")
            result = system.train_model("brain_inspired", data, epochs=50)
            
            # è¯„ä¼°æ¨¡å‹
            print("4. è¯„ä¼°æ¨¡å‹")
            evaluation = system.evaluate_model("brain_inspired", data)
            
            # å¯è§†åŒ–ç»“æœ
            print("5. ç”Ÿæˆå¯è§†åŒ–")
            system.visualize_results()
            
            # ä¿å­˜ç»“æœ
            print("6. ä¿å­˜ç»“æœ")
            system.save_results()
            
            print("ğŸ‰ å®Œæ•´æ¼”ç¤ºå®Œæˆ!")
            
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è„‘å¯å‘AIæ¼”ç¤ºç³»ç»Ÿ')
    parser.add_argument('--mode', choices=['interactive', 'demo', 'batch'], default='interactive',
                       help='è¿è¡Œæ¨¡å¼: interactive(äº¤äº’å¼), demo(è‡ªåŠ¨æ¼”ç¤º), batch(æ‰¹å¤„ç†)')
    parser.add_argument('--config', default='config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--dataset', default='synthetic', help='æ•°æ®é›†ç±»å‹')
    parser.add_argument('--model', default='brain_inspired', help='æ¨¡å‹ç±»å‹')
    parser.add_argument('--epochs', type=int, default=50, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--output', help='ç»“æœè¾“å‡ºæ–‡ä»¶')
    
    args = parser.parse_args()
    
    system = BrainInspiredAISystem()
    
    if args.mode == 'interactive':
        interactive_demo()
    elif args.mode == 'demo':
        # è‡ªåŠ¨æ¼”ç¤ºæ¨¡å¼
        print("ğŸ­ è‡ªåŠ¨æ¼”ç¤ºæ¨¡å¼")
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        system.initialize_system(args.config)
        
        # ç”Ÿæˆæ•°æ®
        data = system.generate_sample_data(args.dataset)
        system.current_data = data
        
        # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
        models = system.create_models(args.model)
        system.models.update(models)
        
        result = system.train_model(args.model, data, args.epochs)
        
        # è¯„ä¼°æ¨¡å‹
        evaluation = system.evaluate_model(args.model, data)
        
        # ä¿å­˜ç»“æœ
        if args.output:
            system.save_results(args.output)
        else:
            system.save_results()
            
        print("âœ… è‡ªåŠ¨æ¼”ç¤ºå®Œæˆ!")
        
    elif args.mode == 'batch':
        # æ‰¹å¤„ç†æ¨¡å¼ - è¿è¡Œå¤šä¸ªå®éªŒ
        print("ğŸ“¦ æ‰¹å¤„ç†æ¨¡å¼")
        
        system.initialize_system(args.config)
        datasets = ['synthetic', 'mnist', 'patterns']
        models = ['brain_inspired', 'hippocampus_only', 'neocortex_only']
        
        for dataset in datasets:
            print(f"\nğŸ”„ æ•°æ®é›†: {dataset}")
            data = system.generate_sample_data(dataset)
            system.current_data = data
            
            for model_name in models:
                print(f"   æ¨¡å‹: {model_name}")
                
                try:
                    # åˆ›å»ºæ¨¡å‹
                    models_dict = system.create_models(model_name)
                    system.models.update(models_dict)
                    
                    # è®­ç»ƒæ¨¡å‹
                    result = system.train_model(model_name, data, args.epochs)
                    
                    # è¯„ä¼°æ¨¡å‹
                    evaluation = system.evaluate_model(model_name, data)
                    
                    print(f"   âœ… {model_name} åœ¨ {dataset} ä¸Šå®Œæˆ")
                    
                except Exception as e:
                    print(f"   âŒ {model_name} åœ¨ {dataset} ä¸Šå¤±è´¥: {e}")
        
        # ä¿å­˜æ‰€æœ‰ç»“æœ
        system.save_results("results/batch_results.json")
        print("ğŸ“¦ æ‰¹å¤„ç†å®Œæˆ!")


if __name__ == "__main__":
    main()