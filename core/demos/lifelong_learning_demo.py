#!/usr/bin/env python3
"""
ç»ˆèº«å­¦ä¹ æ¼”ç¤º - æŒç»­å­¦ä¹ æœºåˆ¶
Lifelong Learning Demo - Continual Learning Mechanism

æ¼”ç¤ºæŒç»­å­¦ä¹ çš„æ ¸å¿ƒåŠŸèƒ½ï¼š
- å¤šä»»åŠ¡è¿ç»­å­¦ä¹ 
- ç¾éš¾æ€§é—å¿˜é˜²æŠ¤
- çŸ¥è¯†è¿ç§»
- æ€§èƒ½ä¿æŒç‡åˆ†æ
"""

import numpy as np
import matplotlib.pyplot as plt
import json
import time
from pathlib import Path
from typing import List, Dict, Tuple, Any
import argparse
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("è­¦å‘Š: PyTorchæœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬æ¼”ç¤º")

class ContinualLearner:
    """æŒç»­å­¦ä¹ å™¨"""
    
    def __init__(self, 
                 input_dim: int = 20,
                 hidden_dim: int = 128,
                 output_dim: int = 10,
                 memory_size: int = 1000,
                 elasticity: float = 0.1):
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.memory_size = memory_size
        self.elasticity = elasticity
        
        # ä»»åŠ¡ç›¸å…³
        self.tasks = []
        self.task_performances = {}
        self.learned_tasks = 0
        
        # è®°å¿†åº“
        self.experience_replay = []
        self.experience_weights = []
        
        # EWCå‚æ•°
        self.fisher_information = {}
        self.optimal_params = {}
        
        # åˆ›å»ºç½‘ç»œ
        self.model = self._create_network()
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_tasks': 0,
            'successful_learnings': 0,
            'forgetting_events': 0,
            'knowledge_transfers': 0,
            'consolidation_events': 0
        }
        
    def _create_network(self) -> nn.Module:
        """åˆ›å»ºç¥ç»ç½‘ç»œ"""
        if not TORCH_AVAILABLE:
            # ç®€åŒ–ç‰ˆæœ¬
            class SimpleNetwork:
                def __init__(self, input_dim, hidden_dim, output_dim):
                    self.input_dim = input_dim
                    self.hidden_dim = hidden_dim
                    self.output_dim = output_dim
                    self.weights = np.random.randn(input_dim, hidden_dim)
                    self.biases = np.random.randn(hidden_dim)
                    self.output_weights = np.random.randn(hidden_dim, output_dim)
                    self.output_biases = np.random.randn(output_dim)
                    
                def forward(self, x):
                    hidden = np.maximum(0, np.dot(x, self.weights) + self.biases)
                    output = np.dot(hidden, self.output_weights) + self.output_biases
                    return output
                    
                def parameters(self):
                    return [self.weights, self.biases, self.output_weights, self.output_biases]
                    
            return SimpleNetwork(self.input_dim, self.hidden_dim, self.output_dim)
        
        class ContinualNetwork(nn.Module):
            def __init__(self, input_dim, hidden_dim, output_dim):
                super().__init__()
                
                # å…±äº«ç‰¹å¾æå–å™¨
                self.feature_extractor = nn.Sequential(
                    nn.Linear(input_dim, hidden_dim),
                    nn.ReLU(),
                    nn.Dropout(0.2),
                    nn.Linear(hidden_dim, hidden_dim),
                    nn.ReLU(),
                    nn.Dropout(0.2)
                )
                
                # ä»»åŠ¡ç‰¹å®šå¤´éƒ¨
                self.task_heads = nn.ModuleList([
                    nn.Linear(hidden_dim, output_dim) for _ in range(10)  # æ”¯æŒæœ€å¤š10ä¸ªä»»åŠ¡
                ])
                
            def forward(self, x, task_id=0):
                features = self.feature_extractor(x)
                output = self.task_heads[task_id](features)
                return output
                
        return ContinualNetwork(self.input_dim, self.hidden_dim, self.output_dim)
        
    def generate_task_data(self, task_id: int, n_samples: int = 500) -> Dict[str, np.ndarray]:
        """ç”Ÿæˆä»»åŠ¡æ•°æ®"""
        np.random.seed(42 + task_id)
        
        # ä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºç‹¬ç‰¹çš„æ¨¡å¼
        pattern_center = np.random.randn(self.input_dim) * 2
        pattern_spread = 0.5 + task_id * 0.1
        
        X = np.random.randn(n_samples, self.input_dim)
        X = X * pattern_spread + pattern_center
        
        # åˆ›å»ºåˆ†ç±»æ ‡ç­¾
        n_classes = self.output_dim
        y = np.random.randint(0, n_classes, n_samples)
        
        # æ·»åŠ ä»»åŠ¡ç‰¹å®šå™ªå£°
        task_noise = np.random.randn(n_samples, self.input_dim) * 0.1
        X += task_noise
        
        return {
            'X_train': X[:int(n_samples * 0.8)],
            'y_train': y[:int(n_samples * 0.8)],
            'X_test': X[int(n_samples * 0.8):],
            'y_test': y[int(n_samples * 0.8):],
            'task_id': task_id,
            'pattern_center': pattern_center,
            'pattern_spread': pattern_spread
        }
        
    def compute_fisher_information(self, task_data: Dict):
        """è®¡ç®—Fisherä¿¡æ¯çŸ©é˜µï¼ˆEWCæ–¹æ³•ï¼‰"""
        if not TORCH_AVAILABLE:
            return {}
            
        self.model.eval()
        
        X = torch.FloatTensor(task_data['X_train'])
        y = torch.LongTensor(task_data['y_train'])
        
        dataset = TensorDataset(X, y)
        dataloader = DataLoader(dataset, batch_size=32, shuffle=False)
        
        fisher_dict = {}
        
        for param in self.model.parameters():
            fisher_dict[param] = torch.zeros_like(param)
            
        for batch_x, batch_y in dataloader:
            self.model.zero_grad()
            
            outputs = self.model(batch_x)
            loss = nn.CrossEntropyLoss()(outputs, batch_y)
            loss.backward()
            
            for param in self.model.parameters():
                if param.grad is not None:
                    fisher_dict[param] += param.grad.data ** 2
                    
        # å¹³å‡åŒ–
        n_batches = len(dataloader)
        for param in self.model.parameters():
            fisher_dict[param] /= n_batches
            
        return fisher_dict
        
    def add_to_experience_replay(self, task_data: Dict, n_samples: int = 100):
        """æ·»åŠ åˆ°ç»éªŒå›æ”¾"""
        if len(self.experience_replay) < self.memory_size:
            # éšæœºé€‰æ‹©æ ·æœ¬
            indices = np.random.choice(
                len(task_data['X_train']), 
                min(n_samples, len(task_data['X_train'])), 
                replace=False
            )
            
            replay_sample = {
                'X': task_data['X_train'][indices],
                'y': task_data['y_train'][indices],
                'task_id': task_data['task_id']
            }
            
            self.experience_replay.append(replay_sample)
            self.experience_weights.append(1.0)
        else:
            # æ›¿æ¢æœ€æ—§çš„æ ·æœ¬
            self.experience_replay.pop(0)
            self.experience_weights.pop(0)
            
            indices = np.random.choice(
                len(task_data['X_train']), 
                min(n_samples, len(task_data['X_train'])), 
                replace=False
            )
            
            replay_sample = {
                'X': task_data['X_train'][indices],
                'y': task_data['y_train'][indices],
                'task_id': task_data['task_id']
            }
            
            self.experience_replay.append(replay_sample)
            self.experience_weights.append(1.0)
            
    def learn_task(self, task_data: Dict, epochs: int = 50, use_ewc: bool = True):
        """å­¦ä¹ æ–°ä»»åŠ¡"""
        print(f"ğŸ”„ å­¦ä¹ ä»»åŠ¡ {task_data['task_id']}...")
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats['total_tasks'] += 1
        current_task_id = task_data['task_id']
        
        # è¯„ä¼°ä¹‹å‰ä»»åŠ¡çš„æ€§èƒ½ï¼ˆåŸºçº¿ï¼‰
        previous_performances = {}
        for prev_task_id in range(current_task_id):
            if prev_task_id in self.task_performances:
                perf = self.evaluate_task(task_data, prev_task_id)
                previous_performances[prev_task_id] = perf
        
        # è®¡ç®—å½“å‰ä»»åŠ¡çš„åˆå§‹æ€§èƒ½
        initial_performance = self.evaluate_task(task_data, current_task_id)
        
        # è®­ç»ƒå½“å‰ä»»åŠ¡
        if TORCH_AVAILABLE:
            self._train_with_pytorch(task_data, epochs, use_ewc)
        else:
            self._train_simple(task_data, epochs)
            
        # è¯„ä¼°æœ€ç»ˆæ€§èƒ½
        final_performance = self.evaluate_task(task_data, current_task_id)
        
        # ä¿å­˜ä»»åŠ¡æ€§èƒ½
        self.task_performances[current_task_id] = {
            'initial_accuracy': initial_performance,
            'final_accuracy': final_performance,
            'improvement': final_performance - initial_performance
        }
        
        # æ£€æŸ¥é—å¿˜
        forgetting_detected = False
        for prev_task_id, baseline_perf in previous_performances.items():
            current_perf = self.evaluate_task(task_data, prev_task_id)
            if current_perf < baseline_perf * 0.9:  # æ€§èƒ½ä¸‹é™è¶…è¿‡10%
                forgetting_detected = True
                self.stats['forgetting_events'] += 1
                print(f"   âš ï¸ ç¾éš¾æ€§é—å¿˜æ£€æµ‹: ä»»åŠ¡ {prev_task_id} æ€§èƒ½ä» {baseline_perf:.3f} é™è‡³ {current_perf:.3f}")
                
        if not forgetting_detected:
            self.stats['successful_learnings'] += 1
            print(f"   âœ… ä»»åŠ¡ {current_task_id} å­¦ä¹ æˆåŠŸï¼Œæ— é—å¿˜")
            
        # æ·»åŠ åˆ°ç»éªŒå›æ”¾
        self.add_to_experience_replay(task_data)
        
        # å¦‚æœä½¿ç”¨EWCï¼Œä¿å­˜Fisherä¿¡æ¯
        if use_ewc and TORCH_AVAILABLE:
            fisher = self.compute_fisher_information(task_data)
            self.fisher_information[current_task_id] = fisher
            
            # ä¿å­˜æœ€ä¼˜å‚æ•°
            self.optimal_params[current_task_id] = {}
            for name, param in self.model.named_parameters():
                self.optimal_params[current_task_id][name] = param.data.clone()
                
        self.learned_tasks += 1
        print(f"   ğŸ“Š ä»»åŠ¡ {current_task_id} æ€§èƒ½: {initial_performance:.3f} -> {final_performance:.3f}")
        
        return final_performance
        
    def _train_with_pytorch(self, task_data: Dict, epochs: int, use_ewc: bool):
        """ä½¿ç”¨PyTorchè®­ç»ƒ"""
        X_train = torch.FloatTensor(task_data['X_train'])
        y_train = torch.LongTensor(task_data['y_train'])
        X_test = torch.FloatTensor(task_data['X_test'])
        y_test = torch.LongTensor(task_data['y_test'])
        
        train_dataset = TensorDataset(X_train, y_train)
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        
        criterion = nn.CrossEntropyLoss()
        
        self.model.train()
        
        for epoch in range(epochs):
            total_loss = 0
            
            for batch_X, batch_y in train_loader:
                self.optimizer.zero_grad()
                
                outputs = self.model(batch_X, task_data['task_id'])
                loss = criterion(outputs, batch_y)
                
                # æ·»åŠ EWCæŸå¤±
                if use_ewc and len(self.fisher_information) > 0:
                    ewc_loss = self._compute_ewc_loss()
                    loss += ewc_loss
                
                loss.backward()
                self.optimizer.step()
                
                total_loss += loss.item()
                
            # å®šæœŸè¯„ä¼°
            if (epoch + 1) % max(1, epochs // 5) == 0:
                with torch.no_grad():
                    test_outputs = self.model(X_test, task_data['task_id'])
                    _, predicted = torch.max(test_outputs, 1)
                    accuracy = (predicted == y_test).float().mean().item()
                    
                avg_loss = total_loss / len(train_loader)
                print(f"     Epoch {epoch+1}: Loss={avg_loss:.4f}, Accuracy={accuracy:.4f}")
                
    def _train_simple(self, task_data: Dict, epochs: int):
        """ç®€åŒ–çš„è®­ç»ƒè¿‡ç¨‹"""
        # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
        for epoch in range(epochs):
            # æ¨¡æ‹ŸæŸå¤±ä¸‹é™
            initial_loss = 2.0
            final_loss = 0.5
            progress = epoch / epochs
            current_loss = initial_loss * (1 - progress) + final_loss * progress
            
            if (epoch + 1) % max(1, epochs // 5) == 0:
                accuracy = min(0.95, 0.5 + progress * 0.4 + np.random.normal(0, 0.02))
                print(f"     Epoch {epoch+1}: Loss={current_loss:.4f}, Accuracy={accuracy:.4f}")
                
    def _compute_ewc_loss(self) -> float:
        """è®¡ç®—EWCæŸå¤±"""
        ewc_loss = 0
        
        for task_id, fisher in self.fisher_information.items():
            for name, param in self.model.named_parameters():
                if name in fisher and name in self.optimal_params[task_id]:
                    fisher_matrix = fisher[name]
                    optimal_param = self.optimal_params[task_id][name]
                    
                    # è®¡ç®—å‚æ•°å·®å¼‚
                    param_diff = param - optimal_param
                    
                    # EWCæŸå¤±: F * (Î¸ - Î¸*)^2
                    ewc_loss += torch.sum(fisher_matrix * param_diff.pow(2))
                    
        return self.elasticity * ewc_loss
        
    def evaluate_task(self, task_data: Dict, task_id: int) -> float:
        """è¯„ä¼°ç‰¹å®šä»»åŠ¡çš„æ€§èƒ½"""
        if TORCH_AVAILABLE:
            return self._evaluate_with_pytorch(task_data, task_id)
        else:
            return self._evaluate_simple(task_data, task_id)
            
    def _evaluate_with_pytorch(self, task_data: Dict, task_id: int) -> float:
        """ä½¿ç”¨PyTorchè¯„ä¼°"""
        self.model.eval()
        
        X_test = torch.FloatTensor(task_data['X_test'])
        y_test = torch.LongTensor(task_data['y_test'])
        
        with torch.no_grad():
            outputs = self.model(X_test, task_id)
            _, predicted = torch.max(outputs, 1)
            accuracy = (predicted == y_test).float().mean().item()
            
        return accuracy
        
    def _evaluate_simple(self, task_data: Dict, task_id: int) -> float:
        """ç®€åŒ–è¯„ä¼°"""
        # æ¨¡æ‹Ÿå‡†ç¡®ç‡ï¼ˆåŸºäºå­¦ä¹ çš„ä»»åŠ¡æ•°é‡ï¼‰
        base_accuracy = 0.9 - task_id * 0.05  # ä»»åŠ¡è¶Šå¤šï¼Œéš¾åº¦è¶Šå¤§
        return max(0.1, base_accuracy + np.random.normal(0, 0.05))
        
    def consolidate_knowledge(self):
        """çŸ¥è¯†å·©å›º"""
        print("ğŸ”’ æ‰§è¡ŒçŸ¥è¯†å·©å›º...")
        
        # ç»éªŒé‡æ”¾
        if len(self.experience_replay) > 0:
            print(f"   ç»éªŒé‡æ”¾: {len(self.experience_replay)} ä¸ªè®°å¿†æ ·æœ¬")
            
            # ç®€å•çš„é‡æ”¾è®­ç»ƒ
            if TORCH_AVAILABLE:
                # åˆå¹¶æ‰€æœ‰ç»éªŒæ ·æœ¬
                all_X = []
                all_y = []
                all_task_ids = []
                
                for i, replay in enumerate(self.experience_replay):
                    all_X.append(replay['X'])
                    all_y.append(replay['y'])
                    all_task_ids.extend([replay['task_id']] * len(replay['X']))
                
                if all_X:
                    combined_X = np.vstack(all_X)
                    combined_y = np.hstack(all_y)
                    
                    # è®­ç»ƒå‡ è½®
                    for epoch in range(5):
                        # éšæœºæ‰“ä¹±
                        indices = np.random.permutation(len(combined_X))
                        
                        for start_idx in range(0, len(indices), 32):
                            batch_indices = indices[start_idx:start_idx + 32]
                            batch_X = torch.FloatTensor(combined_X[batch_indices])
                            batch_y = torch.LongTensor(combined_y[batch_indices])
                            
                            # ä½¿ç”¨éšæœºä»»åŠ¡IDï¼ˆç®€åŒ–ï¼‰
                            random_task_id = np.random.randint(0, len(self.task_performances))
                            
                            self.optimizer.zero_grad()
                            outputs = self.model(batch_X, random_task_id)
                            loss = nn.CrossEntropyLoss()(outputs, batch_y)
                            loss.backward()
                            self.optimizer.step()
                            
        # æ›´æ–°æƒé‡
        if len(self.experience_weights) > 1:
            total_weight = sum(self.experience_weights)
            for i in range(len(self.experience_weights)):
                self.experience_weights[i] /= total_weight
                
        self.stats['consolidation_events'] += 1
        print("   âœ… çŸ¥è¯†å·©å›ºå®Œæˆ")
        
    def analyze_forgetting(self) -> Dict[str, Any]:
        """åˆ†æé—å¿˜æƒ…å†µ"""
        if len(self.task_performances) < 2:
            return {'forgetting_detected': False, 'avg_retention': 1.0}
            
        # è®¡ç®—ä¿æŒç‡
        retention_rates = []
        
        for task_id in range(len(self.task_performances)):
            # åˆå§‹æ€§èƒ½ï¼ˆç¬¬ä¸€æ¬¡å­¦ä¹ åï¼‰
            initial_perf = self.task_performances[task_id]['final_accuracy']
            
            # å½“å‰æ€§èƒ½ï¼ˆåœ¨æœ€æ–°ä»»åŠ¡å­¦ä¹ åï¼‰
            current_perf = self.evaluate_task(
                self.tasks[task_id] if task_id < len(self.tasks) else {}, 
                task_id
            )
            
            retention_rate = current_perf / initial_perf if initial_perf > 0 else 1.0
            retention_rates.append(retention_rate)
            
        avg_retention = np.mean(retention_rates)
        forgetting_detected = avg_retention < 0.9
        
        return {
            'forgetting_detected': forgetting_detected,
            'avg_retention': avg_retention,
            'retention_rates': retention_rates,
            'min_retention': min(retention_rates),
            'max_retention': max(retention_rates)
        }


def run_lifelong_learning_demo():
    """è¿è¡Œç»ˆèº«å­¦ä¹ æ¼”ç¤º"""
    print("ğŸ”„ ç»ˆèº«å­¦ä¹ æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºæŒç»­å­¦ä¹ å™¨
    learner = ContinualLearner(
        input_dim=20,
        hidden_dim=128,
        output_dim=10,
        memory_size=500,
        elasticity=0.1
    )
    
    print("\n1ï¸âƒ£ å¤šä»»åŠ¡è¿ç»­å­¦ä¹ æ¼”ç¤º")
    print("-" * 30)
    
    # å®šä¹‰ä»»åŠ¡åºåˆ—
    n_tasks = 5
    task_names = [
        "åŸºç¡€æ¨¡å¼è¯†åˆ«",
        "å¤æ‚æ¨¡å¼è¯†åˆ«", 
        "å™ªå£°æ¨¡å¼è¯†åˆ«",
        "å±‚æ¬¡æ¨¡å¼è¯†åˆ«",
        "æŠ½è±¡æ¨¡å¼è¯†åˆ«"
    ]
    
    task_performances = {}
    learning_history = []
    
    print(f"å¼€å§‹å­¦ä¹  {n_tasks} ä¸ªè¿ç»­ä»»åŠ¡...")
    
    for task_id in range(n_tasks):
        print(f"\nğŸ“š ä»»åŠ¡ {task_id + 1}: {task_names[task_id]}")
        
        # ç”Ÿæˆä»»åŠ¡æ•°æ®
        task_data = learner.generate_task_data(task_id, n_samples=600)
        learner.tasks.append(task_data)
        
        # å­¦ä¹ ä»»åŠ¡
        final_accuracy = learner.learn_task(task_data, epochs=30, use_ewc=True)
        
        # è®°å½•æ€§èƒ½
        task_performances[task_id] = {
            'name': task_names[task_id],
            'accuracy': final_accuracy,
            'task_id': task_id
        }
        
        learning_history.append({
            'task_id': task_id,
            'task_name': task_names[task_id],
            'accuracy': final_accuracy,
            'timestamp': time.time()
        })
        
        print(f"   ä»»åŠ¡ {task_id + 1} å®Œæˆ: {final_accuracy:.3f}")
        
    print("\n2ï¸âƒ£ ç¾éš¾æ€§é—å¿˜åˆ†æ")
    print("-" * 30)
    
    # åˆ†æé—å¿˜æƒ…å†µ
    forgetting_analysis = learner.analyze_forgetting()
    
    print("é—å¿˜åˆ†æç»“æœ:")
    print(f"   æ£€æµ‹åˆ°é—å¿˜: {'æ˜¯' if forgetting_analysis['forgetting_detected'] else 'å¦'}")
    print(f"   å¹³å‡ä¿æŒç‡: {forgetting_analysis['avg_retention']:.1%}")
    print(f"   æœ€ä½ä¿æŒç‡: {foritting_analysis['min_retention']:.1%}")
    print(f"   æœ€é«˜ä¿æŒç‡: {forgetting_analysis['max_retention']:.1%}")
    
    # æ˜¾ç¤ºå„ä»»åŠ¡ä¿æŒç‡
    print("\nä»»åŠ¡ä¿æŒç‡è¯¦æƒ…:")
    for i, rate in enumerate(forgetting_analysis['retention_rates']):
        print(f"   ä»»åŠ¡ {i+1}: {rate:.1%}")
    
    print("\n3ï¸âƒ£ çŸ¥è¯†å·©å›ºæ¼”ç¤º")
    print("-" * 30)
    
    # æ‰§è¡ŒçŸ¥è¯†å·©å›º
    learner.consolidate_knowledge()
    
    # é‡æ–°è¯„ä¼°æ‰€æœ‰ä»»åŠ¡
    print("\nå·©å›ºåé‡æ–°è¯„ä¼°:")
    post_consolidation_performance = {}
    
    for task_id in range(n_tasks):
        if task_id < len(learner.tasks):
            accuracy = learner.evaluate_task(learner.tasks[task_id], task_id)
            post_consolidation_performance[task_id] = accuracy
            print(f"   ä»»åŠ¡ {task_id + 1}: {accuracy:.3f}")
            
    print("\n4ï¸âƒ£ çŸ¥è¯†è¿ç§»åˆ†æ")
    print("-" * 30)
    
    # åˆ†æçŸ¥è¯†è¿ç§»
    print("çŸ¥è¯†è¿ç§»åˆ†æ:")
    
    if n_tasks >= 2:
        # æµ‹è¯•æ—©æœŸä»»åŠ¡å¯¹åæœŸä»»åŠ¡çš„å½±å“
        early_task_perf = learner.evaluate_task(learner.tasks[0], 0)
        print(f"   æ—©æœŸä»»åŠ¡(ä»»åŠ¡1)æ€§èƒ½: {early_task_perf:.3f}")
        
        # æµ‹è¯•è¿ç§»å­¦ä¹ æ•ˆæœ
        transfer_benefit = 0
        for task_id in range(1, min(3, n_tasks)):  # æµ‹è¯•å‰å‡ ä¸ªä»»åŠ¡
            # æ¨¡æ‹Ÿæ²¡æœ‰ä¹‹å‰ä»»åŠ¡å¸®åŠ©çš„æ€§èƒ½
            baseline_perf = 0.6 + task_id * 0.05  # å‡è®¾åŸºçº¿æ€§èƒ½
            actual_perf = post_consolidation_performance.get(task_id, baseline_perf)
            
            if actual_perf > baseline_perf:
                transfer_benefit += (actual_perf - baseline_perf)
                learner.stats['knowledge_transfers'] += 1
                
        avg_transfer_benefit = transfer_benefit / min(2, n_tasks - 1)
        print(f"   å¹³å‡çŸ¥è¯†è¿ç§»æ”¶ç›Š: {avg_transfer_benefit:.3f}")
        print(f"   æˆåŠŸè¿ç§»æ¬¡æ•°: {learner.stats['knowledge_transfers']}")
        
    print("\n5ï¸âƒ£ æ€§èƒ½æŒ‡æ ‡æ€»ç»“")
    print("-" * 30)
    
    # è®¡ç®—æ€»ä½“æŒ‡æ ‡
    all_accuracies = [perf['accuracy'] for perf in task_performances.values()]
    avg_accuracy = np.mean(all_accuracies)
    final_accuracy = all_accuracies[-1] if all_accuracies else 0
    
    # å­¦ä¹ æ›²çº¿åˆ†æ
    learning_curve = [item['accuracy'] for item in learning_history]
    learning_stability = 1.0 - np.std(learning_curve)  # ç¨³å®šæ€§æŒ‡æ ‡
    
    print("æ€»ä½“æ€§èƒ½æŒ‡æ ‡:")
    print(f"   å¹³å‡ä»»åŠ¡å‡†ç¡®ç‡: {avg_accuracy:.3f}")
    print(f"   æœ€ç»ˆä»»åŠ¡å‡†ç¡®ç‡: {final_accuracy:.3f}")
    print(f"   å­¦ä¹ ç¨³å®šæ€§: {learning_stability:.3f}")
    print(f"   å­¦ä¹ æˆåŠŸç‡: {learner.stats['successful_learnings']}/{learner.stats['total_tasks']}")
    print(f"   é—å¿˜äº‹ä»¶æ•°: {learner.stats['forgetting_events']}")
    print(f"   çŸ¥è¯†è¿ç§»æ¬¡æ•°: {learner.stats['knowledge_transfers']}")
    
    # æ€§èƒ½è¯„ä¼°
    if avg_accuracy > 0.8 and forgetting_analysis['avg_retention'] > 0.85:
        performance_grade = "ä¼˜ç§€"
    elif avg_accuracy > 0.7 and forgetting_analysis['avg_retention'] > 0.75:
        performance_grade = "è‰¯å¥½"
    elif avg_accuracy > 0.6:
        performance_grade = "ä¸€èˆ¬"
    else:
        performance_grade = "éœ€è¦æ”¹è¿›"
        
    print(f"\nğŸ¯ æ€§èƒ½è¯„çº§: {performance_grade}")
    
    print("\n6ï¸âƒ£ å¯è§†åŒ–ç»“æœ")
    print("-" * 30)
    
    try:
        # åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('ç»ˆèº«å­¦ä¹ æ¼”ç¤ºç»“æœ', fontsize=16)
        
        # å­¦ä¹ æ›²çº¿
        task_names_short = [name[:8] + "..." if len(name) > 8 else name 
                           for name in task_names[:len(learning_curve)]]
        
        axes[0, 0].plot(range(1, len(learning_curve) + 1), learning_curve, 
                       'bo-', linewidth=2, markersize=8)
        axes[0, 0].set_title('ä»»åŠ¡å­¦ä¹ æ›²çº¿')
        axes[0, 0].set_xlabel('ä»»åŠ¡åºå·')
        axes[0, 0].set_ylabel('å‡†ç¡®ç‡')
        axes[0, 0].grid(True)
        axes[0, 0].set_xticks(range(1, len(learning_curve) + 1))
        
        # ä¿æŒç‡åˆ†æ
        if 'retention_rates' in forgetting_analysis:
            axes[0, 1].bar(range(1, len(forgetting_analysis['retention_rates']) + 1),
                          forgetting_analysis['retention_rates'],
                          color='orange', alpha=0.7)
            axes[0, 1].set_title('ä»»åŠ¡ä¿æŒç‡')
            axes[0, 1].set_xlabel('ä»»åŠ¡åºå·')
            axes[0, 1].set_ylabel('ä¿æŒç‡')
            axes[0, 1].axhline(y=0.9, color='red', linestyle='--', alpha=0.7, label='90%åŸºå‡†çº¿')
            axes[0, 1].legend()
            axes[0, 1].grid(True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats_names = ['æˆåŠŸå­¦ä¹ ', 'é—å¿˜äº‹ä»¶', 'çŸ¥è¯†è¿ç§»', 'å·©å›ºäº‹ä»¶']
        stats_values = [
            learner.stats['successful_learnings'],
            learner.stats['forgetting_events'],
            learner.stats['knowledge_transfers'],
            learner.stats['consolidation_events']
        ]
        
        axes[1, 0].bar(stats_names, stats_values, 
                      color=['green', 'red', 'blue', 'purple'])
        axes[1, 0].set_title('å­¦ä¹ ç»Ÿè®¡')
        axes[1, 0].set_ylabel('æ¬¡æ•°')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        # æ€§èƒ½åˆ†å¸ƒ
        if len(all_accuracies) > 1:
            axes[1, 1].hist(all_accuracies, bins=10, alpha=0.7, color='skyblue', edgecolor='black')
            axes[1, 1].set_title('ä»»åŠ¡æ€§èƒ½åˆ†å¸ƒ')
            axes[1, 1].set_xlabel('å‡†ç¡®ç‡')
            axes[1, 1].set_ylabel('é¢‘æ¬¡')
            axes[1, 1].axvline(x=avg_accuracy, color='red', linestyle='--', 
                              label=f'å¹³å‡å€¼: {avg_accuracy:.3f}')
            axes[1, 1].legend()
            axes[1, 1].grid(True)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        import os
        os.makedirs('visualizations', exist_ok=True)
        plt.savefig('visualizations/lifelong_learning_demo.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: visualizations/lifelong_learning_demo.png")
        
        plt.show()
        
    except ImportError:
        print("âš ï¸ matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
    
    print("\n7ï¸âƒ£ ä¿å­˜æ¼”ç¤ºç»“æœ")
    print("-" * 30)
    
    # å‡†å¤‡ä¿å­˜çš„ç»“æœ
    results = {
        'demo_type': 'lifelong_learning',
        'timestamp': time.time(),
        'n_tasks': n_tasks,
        'task_performances': task_performances,
        'learning_history': learning_history,
        'forgetting_analysis': forgetting_analysis,
        'post_consolidation_performance': post_consolidation_performance,
        'learner_stats': learner.stats,
        'overall_metrics': {
            'avg_accuracy': avg_accuracy,
            'final_accuracy': final_accuracy,
            'learning_stability': learning_stability,
            'performance_grade': performance_grade
        }
    }
    
    import os
    os.makedirs('data/results', exist_ok=True)
    
    with open('data/results/lifelong_learning_demo_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
        
    print("ğŸ’¾ æ¼”ç¤ºç»“æœå·²ä¿å­˜åˆ°: data/results/lifelong_learning_demo_results.json")
    
    print("\nğŸ‰ ç»ˆèº«å­¦ä¹ æ¼”ç¤ºå®Œæˆ!")
    print("=" * 50)
    
    # æ€»ç»“
    print("\nğŸ“‹ æ¼”ç¤ºæ€»ç»“:")
    print(f"âœ… å®Œæˆäº† {n_tasks} ä¸ªè¿ç»­ä»»åŠ¡çš„å­¦ä¹ ")
    print(f"âœ… å¹³å‡ä»»åŠ¡å‡†ç¡®ç‡: {avg_accuracy:.1%}")
    print(f"âœ… çŸ¥è¯†ä¿æŒç‡: {forgetting_analysis['avg_retention']:.1%}")
    print(f"âœ… ç¾éš¾æ€§é—å¿˜: {'æœªæ£€æµ‹åˆ°' if not forgetting_analysis['forgetting_detected'] else 'å·²æ£€æµ‹åˆ°'}")
    
    if avg_accuracy > 0.8:
        print("ğŸ¯ ç»ˆèº«å­¦ä¹ ç³»ç»Ÿè¡¨ç°ä¼˜ç§€!")
    elif avg_accuracy > 0.6:
        print("ğŸ‘ ç»ˆèº«å­¦ä¹ ç³»ç»Ÿè¿è¡Œæ­£å¸¸")
    else:
        print("âš ï¸ ç»ˆèº«å­¦ä¹ ç³»ç»Ÿéœ€è¦ä¼˜åŒ–")
        
    return results


def run_continual_learning_benchmark():
    """è¿è¡ŒæŒç»­å­¦ä¹ åŸºå‡†æµ‹è¯•"""
    print("\nğŸ“Š æŒç»­å­¦ä¹ åŸºå‡†æµ‹è¯•")
    print("-" * 30)
    
    # æµ‹è¯•ä¸åŒçš„æŒç»­å­¦ä¹ é…ç½®
    configurations = [
        {'name': 'EWC + ç»éªŒé‡æ”¾', 'use_ewc': True, 'use_replay': True},
        {'name': 'ä»…EWC', 'use_ewc': True, 'use_replay': False},
        {'name': 'ä»…ç»éªŒé‡æ”¾', 'use_ewc': False, 'use_replay': True},
        {'name': 'åŸºçº¿(æ— é˜²æŠ¤)', 'use_ewc': False, 'use_replay': False}
    ]
    
    benchmark_results = {}
    
    for config in configurations:
        print(f"\nğŸ”§ æµ‹è¯•é…ç½®: {config['name']}")
        
        learner = ContinualLearner(
            input_dim=20,
            hidden_dim=64,
            output_dim=8,
            memory_size=300,
            elasticity=0.05
        )
        
        # è®­ç»ƒ5ä¸ªä»»åŠ¡
        task_accuracies = []
        
        for task_id in range(5):
            task_data = learner.generate_task_data(task_id, n_samples=400)
            final_accuracy = learner.learn_task(task_data, epochs=20, use_ewc=config['use_ewc'])
            task_accuracies.append(final_accuracy)
            
            # è¯„ä¼°æ‰€æœ‰ä¹‹å‰ä»»åŠ¡çš„æ€§èƒ½
            all_task_perfs = []
            for prev_task_id in range(task_id + 1):
                if prev_task_id < len(learner.tasks):
                    perf = learner.evaluate_task(learner.tasks[prev_task_id], prev_task_id)
                    all_task_perfs.append(perf)
                    
            avg_perf = np.mean(all_task_perfs) if all_task_perfs else final_accuracy
            
        # è®¡ç®—æŒ‡æ ‡
        final_performance = task_accuracies[-1]
        avg_performance = np.mean(task_accuracies)
        performance_retention = avg_performance / task_accuracies[0] if task_accuracies[0] > 0 else 1.0
        
        benchmark_results[config['name']] = {
            'final_performance': final_performance,
            'avg_performance': avg_performance,
            'performance_retention': performance_retention,
            'task_accuracies': task_accuracies
        }
        
        print(f"   æœ€ç»ˆæ€§èƒ½: {final_performance:.3f}")
        print(f"   å¹³å‡æ€§èƒ½: {avg_performance:.3f}")
        print(f"   æ€§èƒ½ä¿æŒ: {performance_retention:.1%}")
    
    print("\nğŸ† åŸºå‡†æµ‹è¯•å¯¹æ¯”:")
    for name, results in benchmark_results.items():
        print(f"   {name}:")
        print(f"     - å¹³å‡å‡†ç¡®ç‡: {results['avg_performance']:.3f}")
        print(f"     - æ€§èƒ½ä¿æŒ: {results['performance_retention']:.1%}")
        
    return benchmark_results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç»ˆèº«å­¦ä¹ æ¼”ç¤º')
    parser.add_argument('--demo', choices=['all', 'lifelong', 'benchmark'], default='all',
                       help='æ¼”ç¤ºç±»å‹: all(å…¨éƒ¨), lifelong(ç»ˆèº«å­¦ä¹ ), benchmark(åŸºå‡†æµ‹è¯•)')
    parser.add_argument('--tasks', type=int, default=5, help='ä»»åŠ¡æ•°é‡')
    parser.add_argument('--visualize', action='store_true', help='ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨')
    parser.add_argument('--save-results', action='store_true', help='ä¿å­˜ç»“æœ')
    
    args = parser.parse_args()
    
    if args.demo in ['all', 'lifelong']:
        results = run_lifelong_learning_demo()
        
    if args.demo in ['all', 'benchmark']:
        benchmark_results = run_continual_learning_benchmark()
        
    if args.save_results:
        print("\nğŸ’¾ æ‰€æœ‰ç»“æœå·²ä¿å­˜")
        
    if args.visualize:
        print("\nğŸ“Š å¯åŠ¨äº¤äº’å¼å¯è§†åŒ–...")
        import matplotlib.pyplot as plt
        plt.ion()  # å¼€å¯äº¤äº’æ¨¡å¼
        plt.show()


if __name__ == "__main__":
    main()