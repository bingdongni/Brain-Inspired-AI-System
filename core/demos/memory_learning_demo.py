#!/usr/bin/env python3
"""
è®°å¿†å­¦ä¹ æ¼”ç¤º - æµ·é©¬ä½“è®°å¿†æœºåˆ¶
Memory Learning Demo - Hippocampus Memory Mechanism

æ¼”ç¤ºæµ·é©¬ä½“çš„æ ¸å¿ƒåŠŸèƒ½ï¼š
- åºåˆ—è®°å¿†å­¦ä¹ 
- æ¨¡å¼è¡¥å…¨
- è®°å¿†æ£€ç´¢
- é—å¿˜æ›²çº¿åˆ†æ
"""

import numpy as np
import matplotlib.pyplot as plt
import json
import time
from pathlib import Path
from typing import List, Dict, Tuple, Any
import argparse
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("è­¦å‘Š: PyTorchæœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬æ¼”ç¤º")

class HippocampusMemorySystem:
    """æµ·é©¬ä½“è®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self, memory_capacity: int = 1000, encoding_dim: int = 128):
        self.memory_capacity = memory_capacity
        self.encoding_dim = encoding_dim
        
        # è®°å¿†å­˜å‚¨
        self.memories = []
        self.memory_strengths = []
        self.memory_patterns = []
        
        # æ¨¡å¼åˆ†ç¦»å’Œè¡¥å…¨å‚æ•°
        self.pattern_separation_threshold = 0.3
        self.pattern_completion_threshold = 0.7
        self.forgetting_rate = 0.05
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_learned': 0,
            'successful_retrievals': 0,
            'pattern_completions': 0,
            'forgetting_events': 0
        }
        
    def encode_pattern(self, pattern: np.ndarray) -> np.ndarray:
        """ç¼–ç æ¨¡å¼åˆ°é«˜ç»´ç©ºé—´"""
        if not TORCH_AVAILABLE:
            # ç®€åŒ–çš„ç¼–ç æœºåˆ¶
            encoded = np.random.randn(self.encoding_dim)
            return encoded / np.linalg.norm(encoded)
            
        # ä½¿ç”¨ç¥ç»ç½‘ç»œç¼–ç 
        encoder = nn.Sequential(
            nn.Linear(len(pattern), 256),
            nn.ReLU(),
            nn.Linear(256, self.encoding_dim),
            nn.Tanh()
        )
        
        with torch.no_grad():
            pattern_tensor = torch.FloatTensor(pattern)
            encoded = encoder(pattern_tensor).numpy()
            
        return encoded / (np.linalg.norm(encoded) + 1e-8)
        
    def store_memory(self, pattern: np.ndarray, strength: float = 1.0):
        """å­˜å‚¨è®°å¿†"""
        # ç¼–ç æ¨¡å¼
        encoded_pattern = self.encode_pattern(pattern)
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸ä¼¼è®°å¿†
        similarity_threshold = 0.8
        for i, existing_pattern in enumerate(self.memory_patterns):
            similarity = np.dot(encoded_pattern, existing_pattern)
            if similarity > similarity_threshold:
                # åŠ å¼ºç°æœ‰è®°å¿†
                self.memory_strengths[i] += strength * 0.1
                self.stats['total_learned'] += 1
                return i
                
        # åˆ›å»ºæ–°è®°å¿†
        if len(self.memories) < self.memory_capacity:
            memory_id = len(self.memories)
            self.memories.append(pattern.copy())
            self.memory_patterns.append(encoded_pattern)
            self.memory_strengths.append(strength)
            self.stats['total_learned'] += 1
            return memory_id
        else:
            # æ›¿æ¢æœ€å¼±çš„è®°å¿†
            min_strength_idx = np.argmin(self.memory_strengths)
            self.memories[min_strength_idx] = pattern.copy()
            self.memory_patterns[min_strength_idx] = encoded_pattern
            self.memory_strengths[min_strength_idx] = strength
            self.stats['total_learned'] += 1
            return min_strength_idx
            
    def retrieve_memory(self, query_pattern: np.ndarray, 
                       partial_match: bool = False) -> Tuple[Any, float, List[int]]:
        """æ£€ç´¢è®°å¿†"""
        if not self.memory_patterns:
            return None, 0.0, []
            
        # ç¼–ç æŸ¥è¯¢æ¨¡å¼
        encoded_query = self.encode_pattern(query_pattern)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = []
        for pattern in self.memory_patterns:
            similarity = np.dot(encoded_query, pattern)
            similarities.append(similarity)
            
        similarities = np.array(similarities)
        
        # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„è®°å¿†
        best_match_idx = np.argmax(similarities)
        best_similarity = similarities[best_match_idx]
        
        # åˆ¤æ–­æ£€ç´¢æˆåŠŸ
        threshold = self.pattern_completion_threshold if partial_match else 0.8
        
        if best_similarity > threshold:
            self.stats['successful_retrievals'] += 1
            retrieved_memory = self.memories[best_match_idx]
            return retrieved_memory, best_similarity, [best_match_idx]
        else:
            return None, best_similarity, []
            
    def complete_pattern(self, partial_pattern: np.ndarray) -> Tuple[Any, float]:
        """æ¨¡å¼è¡¥å…¨"""
        # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„å®Œæ•´æ¨¡å¼
        retrieved, similarity, indices = self.retrieve_memory(partial_pattern, partial_match=True)
        
        if retrieved is not None and similarity > self.pattern_completion_threshold:
            self.stats['pattern_completions'] += 1
            
            # ä½¿ç”¨ç›¸ä¼¼åº¦åŠ æƒè¡¥å…¨
            if len(indices) > 1:
                # å¤šé‡è¡¥å…¨
                weighted_completion = np.zeros_like(retrieved)
                total_weight = 0
                
                for idx in indices:
                    weight = similarities[idx]
                    weighted_completion += weight * self.memories[idx]
                    total_weight += weight
                    
                completed_pattern = weighted_completion / (total_weight + 1e-8)
            else:
                completed_pattern = retrieved
                
            return completed_pattern, similarity
            
        return None, 0.0
        
    def simulate_forgetting(self, time_steps: int = 100):
        """æ¨¡æ‹Ÿé—å¿˜è¿‡ç¨‹"""
        forgetting_curve = []
        
        for step in range(time_steps):
            # éšæœºé—å¿˜ä¸€äº›è®°å¿†
            for i in range(len(self.memory_strengths)):
                if np.random.random() < self.forgetting_rate:
                    self.memory_strengths[i] *= 0.95
                    self.stats['forgetting_events'] += 1
                    
            # è®¡ç®—å¹³å‡è®°å¿†å¼ºåº¦
            avg_strength = np.mean(self.memory_strengths) if self.memory_strengths else 0
            forgetting_curve.append(avg_strength)
            
        return forgetting_curve
        
    def learn_sequence(self, sequence: List[np.ndarray]) -> Dict[str, Any]:
        """å­¦ä¹ åºåˆ—æ¨¡å¼"""
        print(f"ğŸ“š å­¦ä¹ åºåˆ—æ¨¡å¼ï¼Œé•¿åº¦: {len(sequence)}")
        
        sequence_results = {
            'learned_items': [],
            'retrieval_successes': 0,
            'completion_successes': 0,
            'processing_time': 0
        }
        
        start_time = time.time()
        
        for i, item in enumerate(sequence):
            # å­˜å‚¨å½“å‰é¡¹ç›®
            memory_id = self.store_memory(item, strength=1.0)
            sequence_results['learned_items'].append(memory_id)
            
            # æµ‹è¯•æ£€ç´¢ï¼ˆé™¤äº†æœ€åä¸€ä¸ªé¡¹ç›®ï¼‰
            if i < len(sequence) - 1:
                retrieved, similarity, indices = self.retrieve_memory(item)
                if retrieved is not None:
                    sequence_results['retrieval_successes'] += 1
                    
            # æµ‹è¯•æ¨¡å¼è¡¥å…¨
            if i > 0:
                # ä½¿ç”¨éƒ¨åˆ†æ¨¡å¼æµ‹è¯•è¡¥å…¨
                partial = item[:len(item)//2] if len(item) > 2 else item
                completed, similarity = self.complete_pattern(partial)
                if completed is not None:
                    sequence_results['completion_successes'] += 1
                    
            print(f"   æ­¥éª¤ {i+1}: è®°å¿†å¼ºåº¦ {self.memory_strengths[-1]:.3f}")
            
        sequence_results['processing_time'] = time.time() - start_time
        
        return sequence_results
        
    def analyze_memory_patterns(self) -> Dict[str, Any]:
        """åˆ†æè®°å¿†æ¨¡å¼ç»Ÿè®¡"""
        if not self.memory_patterns:
            return {}
            
        patterns_array = np.array(self.memory_patterns)
        
        analysis = {
            'num_memories': len(self.memories),
            'avg_strength': np.mean(self.memory_strengths),
            'strength_std': np.std(self.memory_strengths),
            'memory_diversity': np.mean([np.std(pattern) for pattern in self.memory_patterns]),
            'capacity_usage': len(self.memories) / self.memory_capacity,
            'retrieval_success_rate': self.stats['successful_retrievals'] / max(1, self.stats['total_learned']),
            'pattern_completion_rate': self.stats['pattern_completions'] / max(1, self.stats['total_learned']),
            'stats': self.stats.copy()
        }
        
        return analysis


def generate_sequence_data(sequence_type: str = "numbers", length: int = 10) -> List[np.ndarray]:
    """ç”Ÿæˆåºåˆ—æ•°æ®"""
    if sequence_type == "numbers":
        # æ•°å­—åºåˆ—
        sequence = []
        for i in range(length):
            num = i + 1
            # å°†æ•°å­—ç¼–ç ä¸ºå‘é‡
            pattern = np.zeros(20)
            pattern[:num] = 1.0  # è®¾ç½®å‰ num ä¸ªä½ç½®ä¸º 1
            sequence.append(pattern)
            
    elif sequence_type == "patterns":
        # å‡ ä½•æ¨¡å¼åºåˆ—
        sequence = []
        patterns = [
            np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]),  # å¯¹è§’çº¿
            np.array([1, 1, 1, 0, 0, 0, 0, 0, 0]),  # æ°´å¹³çº¿
            np.array([1, 0, 0, 1, 0, 0, 1, 0, 0]),  # å‚ç›´çº¿
            np.array([1, 1, 1, 1, 1, 1, 1, 1, 1])   # å…¨éƒ¨
        ]
        
        for i in range(length):
            pattern_idx = i % len(patterns)
            pattern = np.zeros(20)
            pattern[:len(patterns[pattern_idx])] = patterns[pattern_idx]
            sequence.append(pattern)
            
    elif sequence_type == "letters":
        # å­—æ¯åºåˆ—
        sequence = []
        letters = "HELLOWORLD"
        for i in range(length):
            letter = letters[i % len(letters)]
            # å°†å­—æ¯ç¼–ç ä¸ºå‘é‡
            pattern = np.zeros(26)
            pattern[ord(letter) - ord('A')] = 1.0
            sequence.append(pattern)
            
    else:
        raise ValueError(f"æœªçŸ¥åºåˆ—ç±»å‹: {sequence_type}")
        
    return sequence


def run_memory_learning_demo():
    """è¿è¡Œè®°å¿†å­¦ä¹ æ¼”ç¤º"""
    print("ğŸ§  æµ·é©¬ä½“è®°å¿†å­¦ä¹ æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºæµ·é©¬ä½“è®°å¿†ç³»ç»Ÿ
    hippocampus = HippocampusMemorySystem(
        memory_capacity=1000,
        encoding_dim=128
    )
    
    print("\n1ï¸âƒ£ åŸºç¡€è®°å¿†åŠŸèƒ½æ¼”ç¤º")
    print("-" * 30)
    
    # åŸºç¡€è®°å¿†æµ‹è¯•
    test_patterns = [
        np.array([1, 0, 0, 1, 0, 0, 1, 0]),
        np.array([0, 1, 0, 0, 1, 0, 0, 1]),
        np.array([1, 1, 0, 1, 1, 0, 1, 1])
    ]
    
    print("å­˜å‚¨æµ‹è¯•æ¨¡å¼...")
    for i, pattern in enumerate(test_patterns):
        memory_id = hippocampus.store_memory(pattern, strength=1.0)
        print(f"   æ¨¡å¼ {i+1}: å­˜å‚¨åˆ°è®°å¿†å•å…ƒ {memory_id}")
        
    print("\næ£€ç´¢æµ‹è¯•æ¨¡å¼...")
    for i, pattern in enumerate(test_patterns):
        retrieved, similarity, indices = hippocampus.retrieve_memory(pattern)
        if retrieved is not None:
            print(f"   æ¨¡å¼ {i+1}: æ£€ç´¢æˆåŠŸ (ç›¸ä¼¼åº¦: {similarity:.3f})")
        else:
            print(f"   æ¨¡å¼ {i+1}: æ£€ç´¢å¤±è´¥")
    
    print("\n2ï¸âƒ£ åºåˆ—å­¦ä¹ æ¼”ç¤º")
    print("-" * 30)
    
    # å­¦ä¹ æ•°å­—åºåˆ—
    number_sequence = generate_sequence_data("numbers", 8)
    print("å­¦ä¹ æ•°å­—åºåˆ—: [1, 2, 3, 4, 5, 6, 7, 8]")
    
    sequence_results = hippocampus.learn_sequence(number_sequence)
    
    print(f"\nåºåˆ—å­¦ä¹ ç»“æœ:")
    print(f"   å­¦ä¹ é¡¹ç›®æ•°: {len(sequence_results['learned_items'])}")
    print(f"   æ£€ç´¢æˆåŠŸç‡: {sequence_results['retrieval_successes']}/{len(number_sequence)-1}")
    print(f"   è¡¥å…¨æˆåŠŸç‡: {sequence_results['completion_successes']}/{len(number_sequence)-1}")
    print(f"   å¤„ç†æ—¶é—´: {sequence_results['processing_time']:.3f}ç§’")
    
    print("\n3ï¸âƒ£ æ¨¡å¼è¡¥å…¨æ¼”ç¤º")
    print("-" * 30)
    
    # æµ‹è¯•æ¨¡å¼è¡¥å…¨
    test_completion_patterns = [
        number_sequence[0][:4],  # éƒ¨åˆ†æ•°å­—1
        number_sequence[3][:3],  # éƒ¨åˆ†æ•°å­—4
        number_sequence[6][:5],  # éƒ¨åˆ†æ•°å­—7
    ]
    
    completion_results = []
    
    for i, partial_pattern in enumerate(test_completion_patterns):
        completed_pattern, similarity = hippocampus.complete_pattern(partial_pattern)
        
        if completed_pattern is not None:
            print(f"   æµ‹è¯• {i+1}: è¡¥å…¨æˆåŠŸ (ç›¸ä¼¼åº¦: {similarity:.3f})")
            # æ£€æŸ¥è¡¥å…¨å‡†ç¡®æ€§
            original_idx = i * 2  # å¯¹åº”çš„å®Œæ•´æ¨¡å¼ç´¢å¼•
            if original_idx < len(number_sequence):
                original = number_sequence[original_idx]
                accuracy = 1.0 - np.mean(np.abs(completed_pattern - original))
                print(f"         è¡¥å…¨å‡†ç¡®ç‡: {accuracy:.3f}")
                completion_results.append(similarity)
        else:
            print(f"   æµ‹è¯• {i+1}: è¡¥å…¨å¤±è´¥")
            
    print("\n4ï¸âƒ£ é—å¿˜æ›²çº¿æ¼”ç¤º")
    print("-" * 30)
    
    # ç”Ÿæˆé—å¿˜æ›²çº¿
    print("ç”Ÿæˆé—å¿˜æ›²çº¿ (100ä¸ªæ—¶é—´æ­¥)...")
    forgetting_curve = hippocampus.simulate_forgetting(100)
    
    print(f"é—å¿˜æ›²çº¿ç»Ÿè®¡:")
    print(f"   åˆå§‹å¹³å‡å¼ºåº¦: {forgetting_curve[0]:.3f}")
    print(f"   æœ€ç»ˆå¹³å‡å¼ºåº¦: {forgetting_curve[-1]:.3f}")
    print(f"   é—å¿˜ç‡: {(forgetting_curve[0] - forgetting_curve[-1]) / forgetting_curve[0] * 100:.1f}%")
    
    print("\n5ï¸âƒ£ è®°å¿†æ¨¡å¼åˆ†æ")
    print("-" * 30)
    
    # åˆ†æè®°å¿†æ¨¡å¼
    analysis = hippocampus.analyze_memory_patterns()
    
    print("è®°å¿†ç³»ç»Ÿåˆ†æ:")
    print(f"   è®°å¿†æ•°é‡: {analysis['num_memories']}")
    print(f"   å¹³å‡å¼ºåº¦: {analysis['avg_strength']:.3f}")
    print(f"   å¼ºåº¦æ ‡å‡†å·®: {analysis['strength_std']:.3f}")
    print(f"   è®°å¿†å¤šæ ·æ€§: {analysis['memory_diversity']:.3f}")
    print(f"   å®¹é‡ä½¿ç”¨ç‡: {analysis['capacity_usage']:.1%}")
    print(f"   æ£€ç´¢æˆåŠŸç‡: {analysis['retrieval_success_rate']:.1%}")
    print(f"   è¡¥å…¨æˆåŠŸç‡: {analysis['pattern_completion_rate']:.1%}")
    
    print("\n6ï¸âƒ£ å¯è§†åŒ–ç»“æœ")
    print("-" * 30)
    
    try:
        # åˆ›å»ºå¯è§†åŒ–å›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('æµ·é©¬ä½“è®°å¿†å­¦ä¹ æ¼”ç¤ºç»“æœ', fontsize=16)
        
        # é—å¿˜æ›²çº¿
        axes[0, 0].plot(forgetting_curve, 'b-', linewidth=2)
        axes[0, 0].set_title('é—å¿˜æ›²çº¿')
        axes[0, 0].set_xlabel('æ—¶é—´æ­¥')
        axes[0, 0].set_ylabel('å¹³å‡è®°å¿†å¼ºåº¦')
        axes[0, 0].grid(True)
        
        # è®°å¿†å¼ºåº¦åˆ†å¸ƒ
        if hippocampus.memory_strengths:
            axes[0, 1].hist(hippocampus.memory_strengths, bins=20, alpha=0.7, color='green')
            axes[0, 1].set_title('è®°å¿†å¼ºåº¦åˆ†å¸ƒ')
            axes[0, 1].set_xlabel('è®°å¿†å¼ºåº¦')
            axes[0, 1].set_ylabel('é¢‘æ¬¡')
            axes[0, 1].grid(True)
        
        # å­¦ä¹ æ€§èƒ½æŒ‡æ ‡
        metrics = ['æ£€ç´¢æˆåŠŸç‡', 'è¡¥å…¨æˆåŠŸç‡']
        values = [analysis['retrieval_success_rate'], analysis['pattern_completion_rate']]
        
        axes[1, 0].bar(metrics, values, color=['blue', 'orange'])
        axes[1, 0].set_title('å­¦ä¹ æ€§èƒ½æŒ‡æ ‡')
        axes[1, 0].set_ylabel('æˆåŠŸç‡')
        axes[1, 0].set_ylim(0, 1)
        
        # è¡¥å…¨ç›¸ä¼¼åº¦åˆ†å¸ƒ
        if completion_results:
            axes[1, 1].hist(completion_results, bins=10, alpha=0.7, color='red')
            axes[1, 1].set_title('æ¨¡å¼è¡¥å…¨ç›¸ä¼¼åº¦åˆ†å¸ƒ')
            axes[1, 1].set_xlabel('ç›¸ä¼¼åº¦')
            axes[1, 1].set_ylabel('é¢‘æ¬¡')
            axes[1, 1].grid(True)
        else:
            axes[1, 1].text(0.5, 0.5, 'æ— è¡¥å…¨æ•°æ®', ha='center', va='center', transform=axes[1, 1].transAxes)
            axes[1, 1].set_title('æ¨¡å¼è¡¥å…¨ç›¸ä¼¼åº¦åˆ†å¸ƒ')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        import os
        os.makedirs('visualizations', exist_ok=True)
        plt.savefig('visualizations/memory_learning_demo.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: visualizations/memory_learning_demo.png")
        
        plt.show()
        
    except ImportError:
        print("âš ï¸ matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
    
    print("\n7ï¸âƒ£ ä¿å­˜æ¼”ç¤ºç»“æœ")
    print("-" * 30)
    
    # ä¿å­˜ç»“æœ
    results = {
        'demo_type': 'memory_learning',
        'timestamp': time.time(),
        'sequence_results': sequence_results,
        'completion_results': completion_results,
        'forgetting_curve': forgetting_curve,
        'analysis': analysis,
        'hippocampus_stats': hippocampus.stats
    }
    
    import os
    os.makedirs('data/results', exist_ok=True)
    
    with open('data/results/memory_learning_demo_results.json', 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
        
    print("ğŸ’¾ æ¼”ç¤ºç»“æœå·²ä¿å­˜åˆ°: data/results/memory_learning_demo_results.json")
    
    print("\nğŸ‰ è®°å¿†å­¦ä¹ æ¼”ç¤ºå®Œæˆ!")
    print("=" * 50)
    
    # æ€»ç»“
    print("\nğŸ“‹ æ¼”ç¤ºæ€»ç»“:")
    print(f"âœ… æˆåŠŸå­˜å‚¨äº† {len(hippocampus.memories)} ä¸ªè®°å¿†")
    print(f"âœ… æ£€ç´¢æˆåŠŸç‡è¾¾åˆ° {analysis['retrieval_success_rate']:.1%}")
    print(f"âœ… æ¨¡å¼è¡¥å…¨æˆåŠŸç‡è¾¾åˆ° {analysis['pattern_completion_rate']:.1%}")
    print(f"âœ… è®°å¿†ç³»ç»Ÿå®¹é‡ä½¿ç”¨ç‡: {analysis['capacity_usage']:.1%}")
    
    if analysis['retrieval_success_rate'] > 0.8:
        print("ğŸ¯ æµ·é©¬ä½“è®°å¿†æœºåˆ¶å·¥ä½œæ­£å¸¸!")
    else:
        print("âš ï¸ è®°å¿†æœºåˆ¶å¯èƒ½éœ€è¦è°ƒä¼˜")
        
    return results


def run_pattern_separation_demo():
    """è¿è¡Œæ¨¡å¼åˆ†ç¦»æ¼”ç¤º"""
    print("\nğŸ§© æ¨¡å¼åˆ†ç¦»æ¼”ç¤º")
    print("=" * 50)
    
    hippocampus = HippocampusMemorySystem(memory_capacity=500, encoding_dim=64)
    
    # ç”Ÿæˆå®¹æ˜“æ··æ·†çš„æ¨¡å¼
    similar_patterns = []
    
    for i in range(10):
        base_pattern = np.random.randn(16)
        
        # åˆ›å»ºç›¸ä¼¼çš„æ¨¡å¼
        pattern1 = base_pattern + np.random.randn(16) * 0.1
        pattern2 = base_pattern + np.random.randn(16) * 0.1
        pattern3 = base_pattern + np.random.randn(16) * 0.5  # æ›´ä¸ç›¸ä¼¼
        
        similar_patterns.extend([pattern1, pattern2, pattern3])
    
    print("æµ‹è¯•æ¨¡å¼åˆ†ç¦»èƒ½åŠ›...")
    
    # å­˜å‚¨æ‰€æœ‰æ¨¡å¼
    for i, pattern in enumerate(similar_patterns):
        hippocampus.store_memory(pattern)
        
    # æµ‹è¯•ç›¸ä¼¼æ¨¡å¼çš„åˆ†ç¦»
    test_base = np.random.randn(16)
    test_similar1 = test_base + np.random.randn(16) * 0.05
    test_similar2 = test_base + np.random.randn(16) * 0.5
    
    retrieved1, sim1, _ = hippocampus.retrieve_memory(test_similar1)
    retrieved2, sim2, _ = hippocampus.retrieve_memory(test_similar2)
    
    print(f"æµ‹è¯•ç»“æœ:")
    print(f"   éå¸¸ç›¸ä¼¼æ¨¡å¼æ£€ç´¢ç›¸ä¼¼åº¦: {sim1:.3f}")
    print(f"   ä¸­ç­‰ç›¸ä¼¼æ¨¡å¼æ£€ç´¢ç›¸ä¼¼åº¦: {sim2:.3f}")
    print(f"   åˆ†ç¦»æ•ˆæœ: {abs(sim1 - sim2):.3f}")
    
    return {
        'high_similarity': sim1,
        'medium_similarity': sim2,
        'separation_effectiveness': abs(sim1 - sim2)
    }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æµ·é©¬ä½“è®°å¿†å­¦ä¹ æ¼”ç¤º')
    parser.add_argument('--demo', choices=['all', 'memory', 'separation'], default='all',
                       help='æ¼”ç¤ºç±»å‹: all(å…¨éƒ¨), memory(è®°å¿†å­¦ä¹ ), separation(æ¨¡å¼åˆ†ç¦»)')
    parser.add_argument('--visualize', action='store_true', help='ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨')
    parser.add_argument('--save-results', action='store_true', help='ä¿å­˜ç»“æœ')
    
    args = parser.parse_args()
    
    if args.demo in ['all', 'memory']:
        results = run_memory_learning_demo()
        
    if args.demo in ['all', 'separation']:
        separation_results = run_pattern_separation_demo()
        
    if args.save_results:
        print("\nğŸ’¾ æ‰€æœ‰ç»“æœå·²ä¿å­˜")
        
    if args.visualize:
        print("\nğŸ“Š å¯åŠ¨äº¤äº’å¼å¯è§†åŒ–...")
        import matplotlib.pyplot as plt
        plt.ion()  # å¼€å¯äº¤äº’æ¨¡å¼
        plt.show()


if __name__ == "__main__":
    main()