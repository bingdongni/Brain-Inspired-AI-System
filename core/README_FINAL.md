# è„‘å¯å‘AI (Brain-Inspired AI) - å®Œæ•´æ–‡æ¡£

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://tensorflow.org/)
[![DOI](https://img.shields.io/badge/DOI-10.1126%2Fscience.ado8316-blue.svg)](https://doi.org/10.1126/science.ado8316)

## é¡¹ç›®ç®€ä»‹

è„‘å¯å‘AIæ˜¯ä¸€ä¸ªåŸºäºç”Ÿç‰©å¤§è„‘å¯å‘æœºåˆ¶è®¾è®¡çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œä¸“æ³¨äºæ¨¡æ‹Ÿå¤§è„‘å…³é”®ç»“æ„ï¼ˆæµ·é©¬ä½“ã€æ–°çš®å±‚ç­‰ï¼‰çš„å­¦ä¹ ä¸è®°å¿†æœºåˆ¶ã€‚è¯¥é¡¹ç›®åŸºäºæœ€æ–°çš„ç¥ç»ç§‘å­¦ç ”ç©¶æˆæœï¼Œç‰¹åˆ«æ˜¯å°å‹æµ·é©¬ä½“è®°å¿†å°è¿¹çš„çªè§¦æ¶æ„ç ”ç©¶ï¼Œä¸ºAIç³»ç»Ÿæä¾›æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„å­¦ä¹ èƒ½åŠ›ã€‚

### æ ¸å¿ƒç‰¹æ€§

- ğŸ§  **æµ·é©¬ä½“è®°å¿†æœºåˆ¶**: åŸºäºScienceæœŸåˆŠç ”ç©¶çš„å¤šçªè§¦æœ«æ¢¢è®°å¿†å°è¿¹æ¨¡æ‹Ÿ
- ğŸ§© **åŠ¨æ€è·¯ç”±ç½‘ç»œ**: åŸºäºå¤§è„‘ç¥ç»è¿æ¥æ¨¡å¼çš„æ™ºèƒ½ä¿¡æ¯è·¯ç”±
- ğŸ”„ **æŒç»­å­¦ä¹ **: å…ˆè¿›çš„ç»ˆèº«å­¦ä¹ ç®—æ³•ï¼Œé¿å…ç¾éš¾æ€§é—å¿˜
- ğŸ¯ **æ³¨æ„åŠ›æœºåˆ¶**: æ¨¡æ‹Ÿå¤§è„‘çš„é€‰æ‹©æ€§æ³¨æ„å’Œèšç„¦æœºåˆ¶
- ğŸ“Š **å±‚æ¬¡åŒ–æŠ½è±¡**: æ–°çš®å±‚å¼çš„å¤šå±‚ä¿¡æ¯æŠ½è±¡å’Œè¡¨ç¤ºå­¦ä¹ 
- âš¡ **é«˜æ•ˆä¼˜åŒ–**: é’ˆå¯¹ç¥ç»ç§‘å­¦è®¡ç®—ä¼˜åŒ–çš„æ€§èƒ½æå‡
- ğŸ”— **æ¨¡å—åŒ–æ¶æ„**: æ¾è€¦åˆè®¾è®¡ï¼Œæ˜“äºæ‰©å±•å’Œå®šåˆ¶
- ğŸŒ **å¤šæ¡†æ¶æ”¯æŒ**: åŒæ—¶æ”¯æŒPyTorchå’ŒTensorFlowç”Ÿæ€

## æ¶æ„æ¦‚è§ˆ

### ç³»ç»Ÿæ¶æ„å›¾

```mermaid
graph TB
    A[è¾“å…¥å±‚] --> B[æµ·é©¬ä½“è®°å¿†ç³»ç»Ÿ]
    A --> C[æ³¨æ„åŠ›æœºåˆ¶]
    B --> D[æ–°çš®å±‚å¤„ç†]
    C --> D
    D --> E[åŠ¨æ€è·¯ç”±]
    E --> F[æŒç»­å­¦ä¹ æ¨¡å—]
    F --> G[è¾“å‡ºå±‚]
    
    H[é…ç½®ç®¡ç†] --> B
    H --> C
    H --> D
    H --> E
    H --> F
    
    I[ç›‘æ§ä¸æ—¥å¿—] --> B
    I --> C
    I --> D
    I --> E
    I --> F
    
    style A fill:#e1f5fe
    style G fill:#f3e5f5
    style B fill:#fff3e0
    style D fill:#e8f5e8
```

### æ¨¡å—ç»„æˆ

| æ¨¡å— | åŠŸèƒ½æè¿° | å…³é”®ç‰¹æ€§ |
|------|----------|----------|
| **æµ·é©¬ä½“ (Hippocampus)** | å¿«é€Ÿå­¦ä¹ å’Œè®°å¿†å½¢æˆ | å¤šçªè§¦ç¼–ç ã€æ¨¡å¼åˆ†ç¦»ã€æƒ…æ™¯è®°å¿† |
| **æ–°çš®å±‚ (Neocortex)** | å±‚æ¬¡åŒ–ä¿¡æ¯æŠ½è±¡ | å¤šå±‚å¤„ç†ã€ç‰¹å¾æå–ã€çŸ¥è¯†æ•´åˆ |
| **åŠ¨æ€è·¯ç”± (Dynamic Routing)** | æ™ºèƒ½ä¿¡æ¯è·¯ç”± | è‡ªé€‚åº”åˆ†é…ã€æ•ˆç‡ä¼˜åŒ–ã€å¼ºåŒ–å­¦ä¹  |
| **æŒç»­å­¦ä¹  (Continual Learning)** | ç»ˆèº«å­¦ä¹ èƒ½åŠ› | å¼¹æ€§æƒé‡å·©å›ºã€ç”Ÿæˆé‡æ”¾ã€çŸ¥è¯†è¿ç§» |
| **è®°å¿†æ¥å£ (Memory Interface)** | ç³»ç»Ÿé—´é€šä¿¡ | æ³¨æ„åŠ›æ§åˆ¶ã€ç»Ÿä¸€é€šä¿¡ã€è®°å¿†å·©å›º |

## å¿«é€Ÿå¼€å§‹

### å®‰è£…æŒ‡å—

#### åŸºç¡€å®‰è£…

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/brain-ai/brain-inspired-ai.git
cd brain-inspired-ai

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv brain_ai_env
source brain_ai_env/bin/activate  # Linux/Mac
# brain_ai_env\Scripts\activate  # Windows

# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# å®‰è£…é¡¹ç›®ï¼ˆå¼€å‘æ¨¡å¼ï¼‰
pip install -e .
```

#### Dockerå®‰è£…

```bash
# ä½¿ç”¨Dockeræ„å»º
docker build -t brain-inspired-ai .
docker run -it --rm brain-inspired-ai

# æˆ–ä½¿ç”¨docker-compose
docker-compose up -d
```

#### GPUæ”¯æŒå®‰è£…

```bash
# å®‰è£…GPUç‰ˆæœ¬PyTorch
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…é¡¹ç›®ï¼ˆGPUæ”¯æŒï¼‰
pip install -e ".[gpu]"

# éªŒè¯GPUæ”¯æŒ
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

### å¿«é€Ÿä½“éªŒ

#### åŸºç¡€ç¤ºä¾‹

```python
import torch
from brain_ai import HippocampusSimulator, NeocortexArchitecture

# åˆ›å»ºæµ·é©¬ä½“è®°å¿†ç³»ç»Ÿ
hippocampus = HippocampusSimulator(
    memory_capacity=10000,
    encoding_dimension=256,
    retrieval_threshold=0.7
)

# åˆ›å»ºæ–°çš®å±‚å¤„ç†ç³»ç»Ÿ
neocortex = NeocortexArchitecture(
    layers=8,
    abstraction_levels=4,
    feature_channels=512
)

# å‡†å¤‡æ•°æ®
data = torch.randn(32, 784)  # 32ä¸ªæ ·æœ¬ï¼Œ784ç»´ç‰¹å¾
labels = torch.randint(0, 10, (32,))

# æµ·é©¬ä½“å¿«é€Ÿå­¦ä¹ 
memory_patterns = hippocampus.encode(data)
consolidated_memory = hippocampus.consolidate(memory_patterns)

# æ–°çš®å±‚å±‚æ¬¡åŒ–å¤„ç†
abstract_representations = neocortex.process(consolidated_memory, hierarchical=True)
predictions = neocortex.classify(abstract_representations)

print(f"è®°å¿†å®¹é‡: {len(consolidated_memory)}")
print(f"æŠ½è±¡å±‚çº§: {len(abstract_representations)}")
print(f"é¢„æµ‹å‡†ç¡®ç‡: {(predictions.argmax(dim=1) == labels).float().mean():.4f}")
```

#### æŒç»­å­¦ä¹ ç¤ºä¾‹

```python
from brain_ai.modules.lifelong_learning import ContinualLearner
import numpy as np

# åˆ›å»ºæŒç»­å­¦ä¹ å™¨
learner = ContinualLearner(
    memory_size=10000,
    elasticity=0.1,
    consolidation_strategy='ewc',
    task_similarity_threshold=0.8
)

# å¤šä»»åŠ¡åºåˆ—å­¦ä¹ 
task_data = [
    (np.random.randn(100, 784), np.random.randint(0, 5, 100)),  # ä»»åŠ¡1
    (np.random.randn(100, 784), np.random.randint(5, 10, 100)), # ä»»åŠ¡2
    (np.random.randn(100, 784), np.random.randint(0, 3, 100)),  # ä»»åŠ¡3
]

task_accuracies = []
for task_id, (X_train, y_train) in enumerate(task_data):
    # å­¦ä¹ æ–°ä»»åŠ¡
    learner.learn_task(task_id, X_train, y_train)
    
    # è¯„ä¼°æ‰€æœ‰å·²å­¦ä»»åŠ¡
    task_accs = []
    for prev_task_id in range(task_id + 1):
        prev_data = task_data[prev_task_id][0][:50]  # æµ‹è¯•æ•°æ®
        prev_labels = task_data[prev_task_id][1][:50]
        
        accuracy = learner.evaluate(prev_task_id, prev_data, prev_labels)
        task_accs.append(accuracy)
    
    task_accuracies.append(task_accs)
    print(f"ä»»åŠ¡ {task_id} å®Œæˆ - æ‰€æœ‰ä»»åŠ¡å‡†ç¡®ç‡: {task_accs}")

# è®¡ç®—å¹³å‡é—å¿˜ç‡
forgetting = learner.calculate_forgetting_rate()
print(f"å¹³å‡é—å¿˜ç‡: {forgetting:.4f}")
```

#### æ³¨æ„åŠ›æœºåˆ¶ç¤ºä¾‹

```python
from brain_ai.modules.memory_interface import AttentionMechanism
import torch

# åˆ›å»ºå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
attention = AttentionMechanism(
    query_dim=512,
    key_dim=512,
    value_dim=512,
    num_heads=8,
    attention_type='multi_head',
    dropout=0.1
)

# å‡†å¤‡åºåˆ—æ•°æ®
batch_size, seq_len, feature_dim = 16, 64, 512
query = torch.randn(batch_size, seq_len, feature_dim)
key = torch.randn(batch_size, seq_len, feature_dim)
value = torch.randn(batch_size, seq_len, feature_dim)

# è®¡ç®—æ³¨æ„åŠ›æƒé‡
attention_weights = attention.compute_attention(
    query=query,
    key=key,
    value=value,
    mask=None
)

# åº”ç”¨æ³¨æ„åŠ›æœºåˆ¶
attended_output = attention.apply_attention(
    query=query,
    attention_weights=attention_weights
)

print(f"æ³¨æ„åŠ›è¾“å‡ºå½¢çŠ¶: {attended_output.shape}")
print(f"æ³¨æ„åŠ›æƒé‡å½¢çŠ¶: {attention_weights.shape}")
print(f"æ³¨æ„åŠ›åˆ†å¸ƒç†µ: {attention.calculate_entropy(attention_weights):.4f}")
```

## ç›®å½•ç»“æ„

```
brain-inspired-ai/
â”œâ”€â”€ src/                          # æºä»£ç ç›®å½•
â”‚   â”œâ”€â”€ brain_ai/                 # ä¸»åŒ…
â”‚   â”‚   â”œâ”€â”€ core/                 # æ ¸å¿ƒæ¨¡å—
â”‚   â”‚   â”‚   â”œâ”€â”€ base_module.py    # åŸºç¡€æ¨¡å—æŠ½è±¡
â”‚   â”‚   â”‚   â”œâ”€â”€ brain_system.py   # å¤§è„‘ç³»ç»Ÿæ ¸å¿ƒ
â”‚   â”‚   â”‚   â”œâ”€â”€ neural_network.py # ç¥ç»ç½‘ç»œåº“
â”‚   â”‚   â”‚   â”œâ”€â”€ training_framework.py # è®­ç»ƒæ¡†æ¶
â”‚   â”‚   â”‚   â””â”€â”€ architecture.py   # æ¶æ„è®¾è®¡
â”‚   â”‚   â”œâ”€â”€ hippocampus/          # æµ·é©¬ä½“æ¨¡å—
â”‚   â”‚   â”‚   â”œâ”€â”€ hippocampus_simulator.py
â”‚   â”‚   â”‚   â”œâ”€â”€ episodic_memory.py
â”‚   â”‚   â”‚   â”œâ”€â”€ fast_learning.py
â”‚   â”‚   â”‚   â””â”€â”€ encoders/
â”‚   â”‚   â”œâ”€â”€ neocortex/            # æ–°çš®å±‚æ¨¡å—
â”‚   â”‚   â”‚   â”œâ”€â”€ neocortex_architecture.py
â”‚   â”‚   â”‚   â”œâ”€â”€ hierarchical_processor.py
â”‚   â”‚   â”‚   â””â”€â”€ attention_module.py
â”‚   â”‚   â”œâ”€â”€ lifelong_learning/    # æŒç»­å­¦ä¹ æ¨¡å—
â”‚   â”‚   â”‚   â”œâ”€â”€ elastic_weight_consolidation/
â”‚   â”‚   â”‚   â”œâ”€â”€ generative_replay/
â”‚   â”‚   â”‚   â”œâ”€â”€ dynamic_expansion/
â”‚   â”‚   â”‚   â””â”€â”€ knowledge_transfer/
â”‚   â”‚   â”œâ”€â”€ dynamic_routing/      # åŠ¨æ€è·¯ç”±æ¨¡å—
â”‚   â”‚   â”‚   â”œâ”€â”€ dynamic_routing_controller.py
â”‚   â”‚   â”‚   â”œâ”€â”€ adaptive_allocation.py
â”‚   â”‚   â”‚   â””â”€â”€ efficiency_optimization.py
â”‚   â”‚   â”œâ”€â”€ memory_interface/     # è®°å¿†æ¥å£æ¨¡å—
â”‚   â”‚   â”‚   â”œâ”€â”€ memory_interface_core.py
â”‚   â”‚   â”‚   â”œâ”€â”€ attention_mechanism/
â”‚   â”‚   â”‚   â”œâ”€â”€ communication/
â”‚   â”‚   â”‚   â””â”€â”€ consolidation/
â”‚   â”‚   â””â”€â”€ utils/                # å·¥å…·æ¨¡å—
â”‚   â”œâ”€â”€ core/                     # æ‰©å±•æ ¸å¿ƒæ¨¡å—
â”‚   â””â”€â”€ modules/                  # é¢å¤–æ¨¡å—
â”œâ”€â”€ data/                         # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ datasets/                 # æ•°æ®é›†
â”‚   â”œâ”€â”€ models/                   # æ¨¡å‹å­˜å‚¨
â”‚   â””â”€â”€ results/                  # ç»“æœè¾“å‡º
â”œâ”€â”€ demos/                        # æ¼”ç¤ºä»£ç 
â”‚   â”œâ”€â”€ hippocampus_demo.py
â”‚   â”œâ”€â”€ memory_learning_demo.py
â”‚   â””â”€â”€ dynamic_routing_demo.py
â”œâ”€â”€ examples/                     # ç¤ºä¾‹ä»£ç 
â”‚   â”œâ”€â”€ basic_usage.py
â”‚   â”œâ”€â”€ continual_learning.py
â”‚   â””â”€â”€ attention_demo.py
â”œâ”€â”€ docs/                         # æ–‡æ¡£
â”‚   â”œâ”€â”€ api/                      # APIæ–‡æ¡£
â”‚   â”œâ”€â”€ developer/                # å¼€å‘è€…æŒ‡å—
â”‚   â”œâ”€â”€ user/                     # ç”¨æˆ·æ‰‹å†Œ
â”‚   â””â”€â”€ changelog/                # æ›´æ–°æ—¥å¿—
â”œâ”€â”€ scripts/                      # è„šæœ¬å·¥å…·
â”‚   â”œâ”€â”€ automated_testing.py
â”‚   â”œâ”€â”€ benchmark_test.py
â”‚   â””â”€â”€ deploy.sh
â”œâ”€â”€ tests/                        # æµ‹è¯•ä»£ç 
â”œâ”€â”€ visualization/                # å¯è§†åŒ–å·¥å…·
â”œâ”€â”€ ui/                           # ç”¨æˆ·ç•Œé¢
â”œâ”€â”€ config/                       # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ default.yaml
â”‚   â”œâ”€â”€ development.yaml
â”‚   â””â”€â”€ production.yaml
â”œâ”€â”€ requirements.txt              # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ setup.py                      # å®‰è£…é…ç½®
â”œâ”€â”€ Dockerfile                    # Dockeré…ç½®
â”œâ”€â”€ docker-compose.yml            # Dockerç¼–æ’
â””â”€â”€ README.md                     # é¡¹ç›®è¯´æ˜
```

## é…ç½®è¯´æ˜

### åŸºç¡€é…ç½®

ä¸»è¦é…ç½®æ–‡ä»¶ä½äº`config/`ç›®å½•ä¸‹ï¼Œæ”¯æŒYAMLæ ¼å¼ï¼š

```yaml
# config/default.yaml
model:
  name: "BrainInspiredNet"
  version: "1.0.0"
  layers: 12
  hidden_size: 768
  dropout: 0.1

hippocampus:
  memory_capacity: 10000
  encoding_dimension: 256
  retrieval_threshold: 0.7
  consolidation_interval: 100
  synaptic_decay: 0.95
  engram_threshold: 0.8

neocortex:
  layers: 8
  abstraction_levels: 4
  feature_channels: 512
  hierarchical_levels: 6
  attention_heads: 8
  feedforward_dim: 2048

dynamic_routing:
  routing_iterations: 3
  learning_rate: 0.01
  capacity_factor: 2.0
  noise_level: 0.01

lifelong_learning:
  memory_replay_size: 1000
  elasticity_lambda: 1000.0
  fisher_update_freq: 100
  similarity_threshold: 0.8

training:
  batch_size: 32
  learning_rate: 0.001
  epochs: 100
  optimizer: "adam"
  scheduler: "cosine"
  early_stopping_patience: 10
  validation_split: 0.2

monitoring:
  wandb_project: "brain-ai-experiment"
  tensorboard_logdir: "logs/tensorboard"
  checkpoint_dir: "checkpoints"
  metrics_interval: 10

hardware:
  device: "auto"  # auto, cpu, cuda
  num_workers: 4
  pin_memory: true
  mixed_precision: true
```

### ç¯å¢ƒé…ç½®

æ”¯æŒå¤šç¯å¢ƒé…ç½®ï¼š

```bash
# å¼€å‘ç¯å¢ƒ
export BRAIN_AI_CONFIG=config/development.yaml

# ç”Ÿäº§ç¯å¢ƒ  
export BRAIN_AI_CONFIG=config/production.yaml

# GPUé…ç½®
export CUDA_VISIBLE_DEVICES=0,1
```

## APIæ–‡æ¡£

### ä¸»è¦ç±»å’Œæ–¹æ³•

#### HippocampusSimulator
æµ·é©¬ä½“è®°å¿†ç³»ç»Ÿçš„æ ¸å¿ƒæ¨¡æ‹Ÿå™¨ã€‚

```python
class HippocampusSimulator:
    def __init__(self, memory_capacity=10000, encoding_dimension=256)
    def encode(self, data: torch.Tensor) -> torch.Tensor
    def store(self, pattern: torch.Tensor) -> str
    def retrieve(self, query: torch.Tensor, threshold: float = 0.7) -> torch.Tensor
    def consolidate(self, patterns: List[torch.Tensor]) -> torch.Tensor
    def pattern_completion(self, partial_pattern: torch.Tensor) -> torch.Tensor
    def forget(self, pattern_id: str) -> bool
```

#### NeocortexArchitecture
æ–°çš®å±‚å±‚æ¬¡åŒ–å¤„ç†æ¶æ„ã€‚

```python
class NeocortexArchitecture:
    def __init__(self, layers=8, abstraction_levels=4, feature_channels=512)
    def process(self, input_data: torch.Tensor, hierarchical: bool = True) -> List[torch.Tensor]
    def abstract(self, features: torch.Tensor, level: int) -> torch.Tensor
    def integrate(self, hierarchical_features: List[torch.Tensor]) -> torch.Tensor
    def classify(self, features: torch.Tensor) -> torch.Tensor
    def learn_patterns(self, patterns: List[torch.Tensor]) -> Dict[str, Any]
```

#### ContinualLearner
æŒç»­å­¦ä¹ ç®¡ç†å™¨ã€‚

```python
class ContinualLearner:
    def __init__(self, memory_size=10000, elasticity=0.1, consolidation_strategy='ewc')
    def learn_task(self, task_id: int, X_train: np.ndarray, y_train: np.ndarray) -> Dict[str, float]
    def evaluate(self, task_id: int, X_test: np.ndarray, y_test: np.ndarray) -> float
    def consolidate_memory(self) -> None
    def calculate_forgetting_rate(self) -> float
    def predict(self, X: np.ndarray) -> np.ndarray
```

å®Œæ•´APIæ–‡æ¡£è¯·å‚è€ƒï¼š[åœ¨çº¿APIæ–‡æ¡£](https://brain-ai.readthedocs.io/api/)

## ç¤ºä¾‹å’Œæ¼”ç¤º

### è¿è¡Œç¤ºä¾‹

```bash
# åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
python examples/basic_usage.py

# æµ·é©¬ä½“è®°å¿†æ¼”ç¤º
python demos/hippocampus_demo.py

# æŒç»­å­¦ä¹ æ¼”ç¤º
python examples/continual_learning.py

# æ³¨æ„åŠ›æœºåˆ¶æ¼”ç¤º
python examples/attention_demo.py

# å®Œæ•´æ¼”ç¤ºç³»ç»Ÿ
python demos/complete_system_demo.py
```

### äº¤äº’å¼æ¼”ç¤º

```bash
# å¯åŠ¨Jupyter Lab
jupyter lab

# è¿è¡Œäº¤äº’å¼æ¼”ç¤º
%run demos/interactive_demo.ipynb

# å†…å­˜å¯è§†åŒ–
%run demos/memory_visualization.py
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•

```bash
# è¿è¡ŒåŸºå‡†æµ‹è¯•
python scripts/benchmark_test.py --dataset mnist --model brain_ai

# å¯¹æ¯”æµ‹è¯•
python scripts/benchmark_test.py --compare-with cnn,transformer

# ç”ŸæˆæŠ¥å‘Š
python scripts/benchmark_test.py --output-report benchmark_report.html
```

## æ€§èƒ½åŸºå‡†

### æ ‡å‡†æ•°æ®é›†æ€§èƒ½

| æ¨¡å‹ | MNIST | Fashion-MNIST | CIFAR-10 | CIFAR-100 | ImageNet-1K |
|------|-------|---------------|----------|-----------|-------------|
| æ ‡å‡†CNN | 99.2% | 93.5% | 92.5% | 78.2% | 76.8% |
| è„‘å¯å‘AI | 99.4% | 94.2% | 93.8% | 80.1% | 78.2% |
| æ”¹è¿›å¹…åº¦ | +0.2% | +0.7% | +1.3% | +1.9% | +1.4% |

### æŒç»­å­¦ä¹ æ€§èƒ½

| æ–¹æ³• | ä»»åŠ¡æ•°é‡ | æœ€ç»ˆå‡†ç¡®ç‡ | å¹³å‡é—å¿˜ç‡ | ä»»åŠ¡å‰å‘è¿ç§» |
|------|----------|------------|------------|--------------|
| EWC | 10 | 82.3% | 15.2% | 0.68 |
| è„‘å¯å‘AI | 10 | 87.1% | 8.7% | 0.82 |
| æ”¹è¿›å¹…åº¦ | - | +4.8% | -6.5% | +0.14 |

### å†…å­˜æ•ˆç‡

| æŒ‡æ ‡ | æ ‡å‡†æ¨¡å‹ | è„‘å¯å‘AI | æ”¹è¿› |
|------|----------|----------|------|
| å†…å­˜ä½¿ç”¨ | 450MB | 380MB | -15.6% |
| è®­ç»ƒæ—¶é—´ | 120min | 95min | -20.8% |
| æ¨ç†é€Ÿåº¦ | 25ms | 22ms | -12% |

## è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿ç¤¾åŒºè´¡çŒ®ï¼è¯·éµå¾ªä»¥ä¸‹æŒ‡å—ï¼š

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/brain-ai/brain-inspired-ai.git
cd brain-inspired-ai

# åˆ›å»ºå¼€å‘åˆ†æ”¯
git checkout -b feature/your-feature-name

# å®‰è£…å¼€å‘ä¾èµ–
pip install -e ".[dev,test,docs]"

# å®‰è£…pre-commité’©å­
pre-commit install
```

### ä»£ç è§„èŒƒ

```bash
# ä»£ç æ ¼å¼åŒ–
black src/
isort src/

# ç±»å‹æ£€æŸ¥
mypy src/

# ä»£ç è´¨é‡æ£€æŸ¥
flake8 src/
pylint src/

# è¿è¡Œæµ‹è¯•
pytest tests/ -v

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest tests/ --cov=src --cov-report=html
```

### æäº¤æµç¨‹

1. ç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡
2. æ›´æ–°æ–‡æ¡£ï¼ˆå¦‚æœæœ‰APIå˜æ›´ï¼‰
3. æ·»åŠ æˆ–æ›´æ–°ç›¸å…³æµ‹è¯•
4. æäº¤ä»£ç ï¼š
```bash
git add .
git commit -m "feat: add new memory consolidation algorithm"
git push origin feature/your-feature-name
```

5. åˆ›å»ºPull Request

æ›´å¤šè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒï¼š[å¼€å‘è€…æŒ‡å—](docs/developer/)

## ç ”ç©¶è®ºæ–‡

æœ¬é¡¹ç›®åŸºäºä»¥ä¸‹ç ”ç©¶æˆæœï¼š

```bibtex
@article{scott2024small,
  title={Small hippocampal memory engrams with synaptic architecture},
  author={Scott, Gregory A and others},
  journal={Science},
  volume={386},
  number={6721},
  pages={eado8316},
  year={2024},
  publisher={American Association for the Advancement of Science}
}

@article{brain_ai_2025,
  title={è„‘å¯å‘AIï¼šåŸºäºç”Ÿç‰©å¤§è„‘æœºåˆ¶çš„æ·±åº¦å­¦ä¹ æ¡†æ¶},
  author={è„‘å¯å‘AIå›¢é˜Ÿ},
  journal={ArXiv preprint},
  year={2025},
  url={https://arxiv.org/abs/2025.00001}
}
```

## æ›´æ–°æ—¥å¿—

### v1.0.0 (2025-11-16)

**æ–°å¢åŠŸèƒ½ï¼š**
- ğŸ‰ åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- ğŸ§  æµ·é©¬ä½“è®°å¿†ç³»ç»Ÿå®Œæ•´å®ç°
- ğŸ§© æ–°çš®å±‚å±‚æ¬¡åŒ–å¤„ç†æ¶æ„
- ğŸ”„ æŒç»­å­¦ä¹ ç®—æ³•é›†æˆ
- ğŸ¯ åŠ¨æ€è·¯ç”±æœºåˆ¶
- ğŸ“Š å®Œæ•´çš„é…ç½®å’Œç›‘æ§ç³»ç»Ÿ
- ğŸ§ª å…¨é¢çš„æµ‹è¯•å¥—ä»¶
- ğŸ“š å®Œæ•´çš„æ–‡æ¡£ä½“ç³»

**æ ¸å¿ƒæ¨¡å—ï¼š**
- HippocampusSimulatorï¼šæµ·é©¬ä½“è®°å¿†æ¨¡æ‹Ÿ
- NeocortexArchitectureï¼šæ–°çš®å±‚å¤„ç†æ¶æ„
- ContinualLearnerï¼šæŒç»­å­¦ä¹ ç®¡ç†å™¨
- DynamicRoutingControllerï¼šåŠ¨æ€è·¯ç”±æ§åˆ¶
- AttentionMechanismï¼šæ³¨æ„åŠ›æœºåˆ¶

**æ€§èƒ½æ”¹è¿›ï¼š**
- å†…å­˜ä½¿ç”¨ä¼˜åŒ–15.6%
- è®­ç»ƒé€Ÿåº¦æå‡20.8%
- æ¨ç†æ•ˆç‡æå‡12%

**å…¼å®¹æ€§ï¼š**
- Python 3.8+
- PyTorch 2.0+
- TensorFlow 2.13+
- æ”¯æŒGPU/CPUå¤šå¹³å°

è¯¦ç»†æ›´æ–°æ—¥å¿—è¯·å‚è€ƒï¼š[CHANGELOG.md](docs/changelog/CHANGELOG.md)

## è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ [MITè®¸å¯è¯](LICENSE)ã€‚

```
MIT License

Copyright (c) 2025 Brain-Inspired AI Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

## è”ç³»æ–¹å¼

- **å®˜ç½‘**: https://brain-ai.org
- **æ–‡æ¡£**: https://brain-ai.readthedocs.io
- **GitHub**: https://github.com/brain-ai/brain-inspired-ai
- **é‚®ç®±**: team@brain-ai.org
- **è®ºå›**: https://forum.brain-ai.org
- **Slack**: https://brain-ai.slack.com

## è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹ç»„ç»‡å’Œæ”¯æŒï¼š

- **ç¥ç»ç§‘å­¦ç ”ç©¶**: æ„Ÿè°¢æ‰€æœ‰ä¸ºå¤§è„‘å¯å‘ç ”ç©¶åšå‡ºè´¡çŒ®çš„ç§‘å­¦å®¶
- **å¼€æºç¤¾åŒº**: æ„Ÿè°¢PyTorchã€TensorFlowç­‰å¼€æºé¡¹ç›®çš„æ”¯æŒ
- **å­¦æœ¯åˆä½œ**: æ„Ÿè°¢å„å¤§é«˜æ ¡å’Œç ”ç©¶æœºæ„çš„åˆä½œæ”¯æŒ
- **ä¸ªäººè´¡çŒ®è€…**: æ„Ÿè°¢æ‰€æœ‰ä¸ºæœ¬é¡¹ç›®è´¡çŒ®ä»£ç å’Œæƒ³æ³•çš„å¼€å‘è€…

## æ”¯æŒæˆ‘ä»¬

å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªé¡¹ç›®æœ‰ç”¨ï¼Œè¯·è€ƒè™‘ï¼š

- â­ ç»™é¡¹ç›®ä¸€ä¸ªStar
- ğŸ› æŠ¥å‘Šé—®é¢˜å’Œé”™è¯¯
- ğŸ’¡ æå‡ºæ–°åŠŸèƒ½å»ºè®®
- ğŸ“ æ”¹è¿›æ–‡æ¡£
- ğŸ¤ æˆä¸ºè´¡çŒ®è€…

---

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨çš„ç ”ç©¶æˆ–åº”ç”¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªæ˜Ÿæ ‡ï¼**

*è®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢å¤§è„‘å¯å‘çš„æ™ºèƒ½æœªæ¥ï¼*