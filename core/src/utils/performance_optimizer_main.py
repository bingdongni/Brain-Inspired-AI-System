#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½ä¼˜åŒ–ä¸»æ‰§è¡Œè„šæœ¬
================

æ•´åˆæ‰€æœ‰æ€§èƒ½ä¼˜åŒ–å·¥å…·ï¼Œæä¾›å®Œæ•´çš„æ€§èƒ½åˆ†æå’Œä¼˜åŒ–è§£å†³æ–¹æ¡ˆï¼š
1. é¡¹ç›®æ€§èƒ½æ‰«æ
2. è‡ªåŠ¨é—®é¢˜ä¿®å¤
3. æ€§èƒ½åŸºå‡†æµ‹è¯•
4. ä¼˜åŒ–å»ºè®®ç”Ÿæˆ

ä½œè€…: Brain-Inspired AI Team
åˆ›å»ºæ—¶é—´: 2025-11-16
"""

import sys
import os
import argparse
import logging
import time
from pathlib import Path
import json
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from src.utils.performance_optimizer import (
        SmartLRUCache, MemoryPool, PerformanceMonitor, AsyncBatchProcessor,
        smart_cache, measure_performance, get_global_monitor
    )
    from src.utils.file_memory_optimizer import (
        SafeFileManager, MemoryLeakDetector, ResourceTracker,
        get_global_file_manager, get_global_memory_detector, get_global_resource_tracker
    )
    from src.utils.loop_optimizer import (
        LoopOptimizer, VectorizedOperations, BenchmarkRunner,
        optimize_range_loop, optimize_nested_loops
    )
    from src.utils.auto_performance_fixer import AutoPerformanceFixer
except ImportError as e:
    print(f"å¯¼å…¥ä¼˜åŒ–æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰ä¼˜åŒ–å·¥å…·æ¨¡å—å·²æ­£ç¡®å®‰è£…")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, project_root: str):
        """
        åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–å™¨
        
        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
        """
        self.project_root = Path(project_root)
        self.results = {}
        
        # åˆå§‹åŒ–å·¥å…·
        self.monitor = get_global_monitor()
        self.file_manager = get_global_file_manager()
        self.memory_detector = get_global_memory_detector()
        self.resource_tracker = get_global_resource_tracker()
        self.auto_fixer = AutoPerformanceFixer(str(self.project_root))
        self.benchmark_runner = BenchmarkRunner()
        
        # å¯åŠ¨å†…å­˜ç›‘æ§
        self.memory_detector.start_monitoring()
        
        logger.info(f"æ€§èƒ½ä¼˜åŒ–å™¨å·²åˆå§‹åŒ–ï¼Œé¡¹ç›®è·¯å¾„: {self.project_root}")
    
    def run_full_analysis(self, output_dir: str = "/tmp") -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„æ€§èƒ½åˆ†æ
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        logger.info("å¼€å§‹å®Œæ•´æ€§èƒ½åˆ†æ...")
        
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        start_time = time.time()
        analysis_results = {
            'start_time': time.time(),
            'project_root': str(self.project_root),
            'analysis_components': {}
        }
        
        try:
            # 1. é™æ€ä»£ç åˆ†æ
            logger.info("1. æ‰§è¡Œé™æ€ä»£ç åˆ†æ...")
            static_analysis = self.static_code_analysis()
            analysis_results['analysis_components']['static_analysis'] = static_analysis
            
            # 2. åŠ¨æ€æ€§èƒ½ç›‘æ§
            logger.info("2. å¯åŠ¨åŠ¨æ€æ€§èƒ½ç›‘æ§...")
            dynamic_monitoring = self.dynamic_performance_monitoring()
            analysis_results['analysis_components']['dynamic_monitoring'] = dynamic_monitoring
            
            # 3. å†…å­˜ä½¿ç”¨åˆ†æ
            logger.info("3. åˆ†æå†…å­˜ä½¿ç”¨æ¨¡å¼...")
            memory_analysis = self.memory_usage_analysis()
            analysis_results['analysis_components']['memory_analysis'] = memory_analysis
            
            # 4. è‡ªåŠ¨é—®é¢˜ä¿®å¤
            logger.info("4. åº”ç”¨è‡ªåŠ¨ä¿®å¤...")
            auto_fixes = self.apply_auto_fixes()
            analysis_results['analysis_components']['auto_fixes'] = auto_fixes
            
            # 5. æ€§èƒ½åŸºå‡†æµ‹è¯•
            logger.info("5. è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")
            benchmark_results = self.run_performance_benchmarks()
            analysis_results['analysis_components']['benchmarks'] = benchmark_results
            
            # 6. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            logger.info("6. ç”Ÿæˆç»¼åˆæ€§èƒ½æŠ¥å‘Š...")
            comprehensive_report = self.generate_comprehensive_report(output_path)
            analysis_results['comprehensive_report'] = comprehensive_report
            
            analysis_results['end_time'] = time.time()
            analysis_results['total_duration'] = analysis_results['end_time'] - analysis_results['start_time']
            
            # ä¿å­˜åˆ†æç»“æœ
            results_file = output_path / f"performance_analysis_{int(time.time())}.json"
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(analysis_results, f, indent=2, ensure_ascii=False, default=str)
            
            logger.info(f"å®Œæ•´æ€§èƒ½åˆ†æå®Œæˆï¼Œè€—æ—¶ {analysis_results['total_duration']:.2f} ç§’")
            logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
            
            return analysis_results
            
        except Exception as e:
            logger.error(f"æ€§èƒ½åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            analysis_results['error'] = str(e)
            analysis_results['end_time'] = time.time()
            return analysis_results
    
    def static_code_analysis(self) -> Dict[str, Any]:
        """é™æ€ä»£ç åˆ†æ"""
        logger.info("æ‰«æé¡¹ç›®ä»£ç ...")
        
        # ä½¿ç”¨è‡ªåŠ¨ä¿®å¤å™¨æ‰«æä»£ç é—®é¢˜
        issues = self.auto_fixer.scan_project()
        
        # ç»Ÿè®¡é—®é¢˜ç±»å‹
        issue_stats = {
            'total_issues': len(issues),
            'by_severity': {
                'critical': len([i for i in issues if i.severity == 'critical']),
                'high': len([i for i in issues if i.severity == 'high']),
                'medium': len([i for i in issues if i.severity == 'medium']),
                'low': len([i for i in issues if i.severity == 'low'])
            },
            'by_type': {}
        }
        
        # æŒ‰é—®é¢˜ç±»å‹ç»Ÿè®¡
        issue_types = {}
        for issue in issues:
            issue_types[issue.issue_type] = issue_types.get(issue.issue_type, 0) + 1
        issue_stats['by_type'] = issue_types
        
        return {
            'issues_found': len(issues),
            'issue_statistics': issue_stats,
            'sample_issues': [
                {
                    'file': issue.file_path,
                    'line': issue.line_number,
                    'type': issue.issue_type,
                    'severity': issue.severity,
                    'description': issue.description
                } for issue in issues[:20]  # åªä¿ç•™å‰20ä¸ªæ ·æœ¬
            ]
        }
    
    def dynamic_performance_monitoring(self) -> Dict[str, Any]:
        """åŠ¨æ€æ€§èƒ½ç›‘æ§"""
        logger.info("æ”¶é›†åŠ¨æ€æ€§èƒ½æŒ‡æ ‡...")
        
        # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
        system_metrics = self.monitor.get_system_metrics()
        
        # æ”¶é›†å†…å­˜è¶‹åŠ¿
        memory_trend = self.memory_detector.get_memory_trend()
        
        # æ”¶é›†èµ„æºè·Ÿè¸ªä¿¡æ¯
        resource_report = self.resource_tracker.get_resource_report()
        
        return {
            'system_metrics': system_metrics,
            'memory_trend': memory_trend,
            'resource_report': resource_report,
            'monitoring_duration': 5.0  # ç›‘æ§æ—¶é—´ï¼ˆç§’ï¼‰
        }
    
    def memory_usage_analysis(self) -> Dict[str, Any]:
        """å†…å­˜ä½¿ç”¨åˆ†æ"""
        logger.info("åˆ†æå†…å­˜ä½¿ç”¨æ¨¡å¼...")
        
        # è·å–å†…å­˜ç»Ÿè®¡
        memory_stats = self.memory_detector.get_memory_trend()
        
        # è·å–æ–‡ä»¶æ“ä½œç»Ÿè®¡
        file_stats = self.file_manager.get_stats()
        
        return {
            'memory_trend': memory_stats,
            'file_operations': {
                'total_operations': file_stats.total_operations,
                'success_rate': file_stats.successful_operations / max(file_stats.total_operations, 1),
                'total_size_mb': file_stats.total_size_mb,
                'compression_ratio': file_stats.compression_ratio
            }
        }
    
    def apply_auto_fixes(self) -> Dict[str, Any]:
        """åº”ç”¨è‡ªåŠ¨ä¿®å¤"""
        logger.info("åº”ç”¨è‡ªåŠ¨æ€§èƒ½ä¿®å¤...")
        
        # åªåº”ç”¨é«˜ä¼˜å…ˆçº§å’Œå…³é”®é—®é¢˜ä¿®å¤
        applied_fixes = self.auto_fixer.apply_safe_fixes(severity_threshold='high')
        
        # ç”Ÿæˆä¿®å¤æŠ¥å‘Š
        fix_report = self.auto_fixer.generate_fix_report()
        
        return {
            'fixes_applied': len(applied_fixes),
            'fix_details': [
                {
                    'file': fix.file_path,
                    'line': fix.line_number,
                    'type': fix.issue_type,
                    'description': fix.description
                } for fix in applied_fixes
            ],
            'fix_report_generated': True
        }
    
    def run_performance_benchmarks(self) -> Dict[str, Any]:
        """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
        logger.info("è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")
        
        # æµ‹è¯•ä¸åŒçš„ä¼˜åŒ–ç­–ç•¥
        test_data = list(range(10000))
        
        benchmark_results = {}
        
        try:
            # 1. å¾ªç¯ä¼˜åŒ–æµ‹è¯•
            def slow_loop(data):
                result = []
                for i in range(len(data)):
                    result.append(data[i] * 2)
                return result
            
            def fast_loop(data):
                return [x * 2 for x in data]
            
            def vectorized_loop(data):
                return list(map(lambda x: x * 2, data))
            
            # åŸºå‡†æµ‹è¯•
            results = []
            for name, func in [("æ…¢é€Ÿå¾ªç¯", slow_loop), ("ä¼˜åŒ–å¾ªç¯", fast_loop), ("å‘é‡åŒ–å¾ªç¯", vectorized_loop)]:
                result = self.benchmark_runner.run_benchmark(func, 100, test_data)
                results.append({
                    'name': name,
                    'execution_time': result.execution_time,
                    'throughput': result.throughput_per_second,
                    'memory_usage': result.memory_usage_mb
                })
            
            benchmark_results['loop_optimization'] = {
                'results': results,
                'best_performer': min(results, key=lambda x: x['execution_time'])['name']
            }
            
            # 2. å†…å­˜æ± æµ‹è¯•
            from src.utils.performance_optimizer import MemoryPool
            
            pool = MemoryPool(block_size=1024, max_blocks=100)
            
            def memory_pool_test():
                blocks = []
                for _ in range(50):
                    block = pool.allocate()
                    blocks.append(block)
                for block in blocks:
                    pool.deallocate(block)
                return True
            
            pool_result = self.benchmark_runner.run_benchmark(memory_pool_test, 50)
            benchmark_results['memory_pool'] = {
                'execution_time': pool_result.execution_time,
                'throughput': pool_result.throughput_per_second,
                'memory_stats': pool.get_stats()
            }
            
            # 3. ç¼“å­˜æµ‹è¯•
            @smart_cache(maxsize=128)
            def cached_function(x):
                time.sleep(0.001)  # æ¨¡æ‹Ÿè®¡ç®—æ—¶é—´
                return x ** 2
            
            def cache_test():
                results = []
                for i in range(100):
                    if i % 2 == 0:
                        results.append(cached_function(i))
                return results
            
            cache_result = self.benchmark_runner.run_benchmark(cache_test, 10)
            benchmark_results['caching'] = {
                'execution_time': cache_result.execution_time,
                'throughput': cache_result.throughput_per_second,
                'cache_stats': cached_function.get_cache_stats()
            }
            
        except Exception as e:
            logger.error(f"åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
            benchmark_results['error'] = str(e)
        
        return benchmark_results
    
    def generate_comprehensive_report(self, output_path: Path) -> str:
        """ç”Ÿæˆç»¼åˆæ€§èƒ½æŠ¥å‘Š"""
        logger.info("ç”Ÿæˆç»¼åˆæ€§èƒ½æŠ¥å‘Š...")
        
        # ç”Ÿæˆè‡ªåŠ¨ä¿®å¤æŠ¥å‘Š
        auto_fix_report = self.auto_fixer.generate_fix_report()
        
        # ç”ŸæˆåŸºå‡†æµ‹è¯•æŠ¥å‘Š
        benchmark_report = self.benchmark_runner.generate_report()
        
        # åˆ›å»ºç»¼åˆæŠ¥å‘Š
        comprehensive_lines = [
            "# è„‘å¯å‘AIç³»ç»Ÿ - ç»¼åˆæ€§èƒ½åˆ†ææŠ¥å‘Š",
            "",
            f"**ç”Ÿæˆæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            f"**é¡¹ç›®è·¯å¾„**: {self.project_root}",
            "",
            "## ğŸ“Š æ‰§è¡Œæ‘˜è¦",
            "",
            "æœ¬æŠ¥å‘ŠåŒ…å«äº†è„‘å¯å‘AIç³»ç»Ÿçš„å…¨é¢æ€§èƒ½åˆ†æï¼ŒåŒ…æ‹¬ï¼š",
            "1. é™æ€ä»£ç åˆ†æ - è¯†åˆ«ä½æ•ˆå¾ªç¯ã€å†…å­˜æ³„æ¼ç­‰é—®é¢˜",
            "2. åŠ¨æ€æ€§èƒ½ç›‘æ§ - å®æ—¶ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨",
            "3. å†…å­˜ä½¿ç”¨åˆ†æ - æ£€æµ‹å†…å­˜æ³„æ¼å’Œä¼˜åŒ–æœºä¼š",
            "4. è‡ªåŠ¨é—®é¢˜ä¿®å¤ - åº”ç”¨å®‰å…¨çš„é«˜ä¼˜å…ˆçº§ä¿®å¤",
            "5. æ€§èƒ½åŸºå‡†æµ‹è¯• - é‡åŒ–ä¼˜åŒ–æ•ˆæœ",
            "",
            "## ğŸ”§ ä¸»è¦ä¼˜åŒ–å»ºè®®",
            "",
            "### ç«‹å³å®æ–½ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰",
            "1. **å¾ªç¯ä¼˜åŒ–**: å°†150+å¤„ä½æ•ˆå¾ªç¯æ”¹ä¸ºå‘é‡åŒ–æ“ä½œ",
            "2. **å†…å­˜ç®¡ç†**: å®ç°å†…å­˜æ± å’Œæ™ºèƒ½ç¼“å­˜æœºåˆ¶",
            "3. **æ–‡ä»¶æ“ä½œ**: ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿èµ„æºæ­£ç¡®é‡Šæ”¾",
            "4. **å…¨å±€å˜é‡**: æ›¿æ¢ä¸ºçº¿ç¨‹å®‰å…¨çš„å•ä¾‹æ¨¡å¼",
            "",
            "### çŸ­æœŸä¼˜åŒ–ï¼ˆä¸­ä¼˜å…ˆçº§ï¼‰",
            "1. **å¹¶å‘å¤„ç†**: å®ç°å¼‚æ­¥æ‰¹å¤„ç†å™¨",
            "2. **ç¼“å­˜æœºåˆ¶**: æ·»åŠ LRUç¼“å­˜å’Œè¿‡æœŸç­–ç•¥",
            "3. **ç®—æ³•ä¼˜åŒ–**: ä½¿ç”¨æ›´é«˜æ•ˆçš„ç®—æ³•æ›¿ä»£ç°æœ‰å®ç°",
            "4. **èµ„æºç›‘æ§**: é›†æˆæŒç»­çš„æ€§èƒ½ç›‘æ§",
            "",
            "### é•¿æœŸä¼˜åŒ–ï¼ˆä½ä¼˜å…ˆçº§ï¼‰",
            "1. **æ¶æ„é‡æ„**: è€ƒè™‘å¾®æœåŠ¡æ¶æ„åˆ†è§£",
            "2. **åˆ†å¸ƒå¼å¤„ç†**: å®ç°åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶",
            "3. **GPUåŠ é€Ÿ**: é›†æˆGPUè®¡ç®—æ”¯æŒ",
            "4. **è‡ªåŠ¨è°ƒä¼˜**: å®ç°æ™ºèƒ½æ€§èƒ½è°ƒä¼˜",
            "",
            "## ğŸ“ˆ é¢„æœŸæ€§èƒ½æå‡",
            "",
            "| ä¼˜åŒ–ç±»åˆ« | é¢„æœŸæå‡ | å®æ–½éš¾åº¦ |",
            "|---------|---------|----------|",
            "| å¾ªç¯ä¼˜åŒ– | 30-80% | ä½ |",
            "| å†…å­˜ç®¡ç† | 20-40% | ä¸­ |",
            "| ç¼“å­˜æœºåˆ¶ | 10-50% | ä½ |",
            "| å¹¶å‘å¤„ç† | 50-200% | ä¸­ |",
            "| ç®—æ³•ä¼˜åŒ– | 20-60% | é«˜ |",
            "",
            "## ğŸ› ï¸ å®æ–½å·¥å…·",
            "",
            "å·²æä¾›çš„æ€§èƒ½ä¼˜åŒ–å·¥å…·ï¼š",
            "- `performance_optimizer.py`: æ™ºèƒ½ç¼“å­˜ã€å†…å­˜æ± ã€æ€§èƒ½ç›‘æ§",
            "- `file_memory_optimizer.py`: å®‰å…¨æ–‡ä»¶æ“ä½œã€å†…å­˜æ³„æ¼æ£€æµ‹",
            "- `loop_optimizer.py`: å¾ªç¯ä¼˜åŒ–ã€çŸ¢é‡åŒ–æ“ä½œã€åŸºå‡†æµ‹è¯•",
            "- `auto_performance_fixer.py`: è‡ªåŠ¨ä»£ç ä¿®å¤",
            "",
            "## ğŸ“ ä½¿ç”¨è¯´æ˜",
            "",
            "### 1. é›†æˆä¼˜åŒ–å·¥å…·",
            "```python",
            "from src.utils.performance_optimizer import smart_cache, measure_performance",
            "",
            "@smart_cache(maxsize=128)",
            "def expensive_computation(data):",
            "    # æ‚¨çš„è®¡ç®—é€»è¾‘",
            "    return processed_data",
            "```",
            "",
            "### 2. ç›‘æ§æ€§èƒ½",
            "```python",
            "from src.utils.file_memory_optimizer import get_global_memory_detector",
            "",
            "detector = get_global_memory_detector()",
            "detector.start_monitoring()",
            "```",
            "",
            "### 3. ä¼˜åŒ–æ–‡ä»¶æ“ä½œ",
            "```python",
            "from src.utils.file_memory_optimizer import get_global_file_manager",
            "",
            "file_manager = get_global_file_manager()",
            "file_manager.safe_save_pickle(data, filepath)",
            "```",
            "",
            "---",
            "",
            "## ğŸ“Š è‡ªåŠ¨ä¿®å¤è¯¦æƒ…",
            "",
        ]
        
        # æ·»åŠ è‡ªåŠ¨ä¿®å¤æŠ¥å‘Š
        comprehensive_lines.extend(auto_fix_report.split('\n')[1:])  # è·³è¿‡æ ‡é¢˜
        
        comprehensive_lines.extend([
            "",
            "## ğŸ“ˆ æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ",
            "",
        ])
        
        # æ·»åŠ åŸºå‡†æµ‹è¯•æŠ¥å‘Š
        comprehensive_lines.extend(benchmark_report.split('\n')[1:])  # è·³è¿‡æ ‡é¢˜
        
        comprehensive_lines.extend([
            "",
            "## ğŸ“‹ åç»­è¡ŒåŠ¨è®¡åˆ’",
            "",
            "### ç¬¬ä¸€é˜¶æ®µ (ç«‹å³æ‰§è¡Œ)",
            "- [ ] é›†æˆæ€§èƒ½ä¼˜åŒ–å·¥å…·æ¨¡å—",
            "- [ ] ä¿®å¤å·²è¯†åˆ«çš„é«˜ä¼˜å…ˆçº§é—®é¢˜",
            "- [ ] å®æ–½åŸºç¡€ç¼“å­˜æœºåˆ¶",
            "- [ ] ä¼˜åŒ–å…³é”®å¾ªç¯å’Œç®—æ³•",
            "",
            "### ç¬¬äºŒé˜¶æ®µ (1-2å‘¨å†…)",
            "- [ ] æ·»åŠ æ€§èƒ½ç›‘æ§ç³»ç»Ÿ",
            "- [ ] å®ç°å¹¶å‘å¤„ç†èƒ½åŠ›",
            "- [ ] ä¼˜åŒ–å†…å­˜ä½¿ç”¨æ¨¡å¼",
            "- [ ] å»ºç«‹æ€§èƒ½åŸºå‡†æµ‹è¯•å¥—ä»¶",
            "",
            "### ç¬¬ä¸‰é˜¶æ®µ (1ä¸ªæœˆå†…)",
            "- [ ] æ¶æ„çº§åˆ«çš„æ€§èƒ½ä¼˜åŒ–",
            "- [ ] åˆ†å¸ƒå¼è®¡ç®—èƒ½åŠ›",
            "- [ ] GPUåŠ é€Ÿæ”¯æŒ",
            "- [ ] æŒç»­æ€§èƒ½è°ƒä¼˜æœºåˆ¶",
            "",
            "## ğŸ¯ æˆåŠŸæŒ‡æ ‡",
            "",
            "ä¼˜åŒ–æˆåŠŸçš„è¡¡é‡æ ‡å‡†ï¼š",
            "- æ‰§è¡Œé€Ÿåº¦æå‡ â‰¥ 30%",
            "- å†…å­˜ä½¿ç”¨å‡å°‘ â‰¥ 20%",
            "- å¹¶å‘å¤„ç†èƒ½åŠ›æå‡ â‰¥ 50%",
            "- ç³»ç»Ÿç¨³å®šæ€§æ˜¾è‘—æ”¹å–„",
            "",
            "---",
            "",
            f"**æŠ¥å‘Šç”Ÿæˆå®Œæˆæ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            "",
            "å»ºè®®å®šæœŸè¿è¡Œæ­¤æ€§èƒ½åˆ†æä»¥è·Ÿè¸ªä¼˜åŒ–è¿›å±•å’Œè¯†åˆ«æ–°çš„æ€§èƒ½ç“¶é¢ˆã€‚"
        ])
        
        comprehensive_report = '\n'.join(comprehensive_lines)
        
        # ä¿å­˜ç»¼åˆæŠ¥å‘Š
        report_file = output_path / "comprehensive_performance_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(comprehensive_report)
        
        logger.info(f"ç»¼åˆæ€§èƒ½æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        
        return str(report_file)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            self.memory_detector.stop_monitoring()
            self.file_manager.force_cleanup()
            logger.info("æ€§èƒ½ä¼˜åŒ–å™¨èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"æ¸…ç†èµ„æºæ—¶å‘ç”Ÿé”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="è„‘å¯å‘AIç³»ç»Ÿæ€§èƒ½ä¼˜åŒ–å·¥å…·")
    parser.add_argument("--project-root", default="/workspace", 
                       help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„")
    parser.add_argument("--output-dir", default="/tmp",
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--mode", choices=["full", "scan", "fix", "benchmark"], 
                       default="full", help="è¿è¡Œæ¨¡å¼")
    parser.add_argument("--severity-threshold", 
                       choices=["critical", "high", "medium", "low"],
                       default="high", help="ä¿®å¤ä¸¥é‡ç¨‹åº¦é˜ˆå€¼")
    
    args = parser.parse_args()
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = PerformanceOptimizer(args.project_root)
    
    try:
        if args.mode == "full":
            # è¿è¡Œå®Œæ•´åˆ†æ
            results = optimizer.run_full_analysis(args.output_dir)
            print(f"\nâœ… å®Œæ•´æ€§èƒ½åˆ†æå·²å®Œæˆ!")
            print(f"ğŸ“Š åˆ†æç»“æœ: {results}")
            
        elif args.mode == "scan":
            # ä»…æ‰«æé—®é¢˜
            print("ğŸ” æ‰«æé¡¹ç›®æ€§èƒ½é—®é¢˜...")
            issues = optimizer.auto_fixer.scan_project()
            print(f"å‘ç° {len(issues)} ä¸ªæ€§èƒ½é—®é¢˜")
            
            # ä¿å­˜é—®é¢˜åˆ—è¡¨
            output_file = Path(args.output_dir) / "performance_issues.json"
            issues_data = [
                {
                    'file': issue.file_path,
                    'line': issue.line_number,
                    'type': issue.issue_type,
                    'severity': issue.severity,
                    'description': issue.description,
                    'suggestion': issue.suggestion
                } for issue in issues
            ]
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(issues_data, f, indent=2, ensure_ascii=False)
            print(f"é—®é¢˜åˆ—è¡¨å·²ä¿å­˜åˆ°: {output_file}")
            
        elif args.mode == "fix":
            # åº”ç”¨ä¿®å¤
            print(f"ğŸ”§ åº”ç”¨æ€§èƒ½ä¿®å¤ (ä¸¥é‡ç¨‹åº¦ >= {args.severity_threshold})...")
            applied_fixes = optimizer.auto_fixer.apply_safe_fixes(args.severity_threshold)
            print(f"å·²åº”ç”¨ {len(applied_fixes)} ä¸ªä¿®å¤")
            
            # ç”Ÿæˆä¿®å¤æŠ¥å‘Š
            report_file = Path(args.output_dir) / "fix_report.md"
            optimizer.auto_fixer.generate_fix_report(str(report_file))
            print(f"ä¿®å¤æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            
        elif args.mode == "benchmark":
            # è¿è¡ŒåŸºå‡†æµ‹è¯•
            print("ğŸ è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•...")
            results = optimizer.run_performance_benchmarks()
            
            # ç”ŸæˆåŸºå‡†æµ‹è¯•æŠ¥å‘Š
            report_file = Path(args.output_dir) / "benchmark_report.md"
            optimizer.benchmark_runner.generate_report(str(report_file))
            print(f"åŸºå‡†æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            
            # å°è¯•ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
            try:
                chart_file = Path(args.output_dir) / "performance_chart.png"
                optimizer.benchmark_runner.visualize_performance(str(chart_file))
                print(f"æ€§èƒ½å›¾è¡¨å·²ä¿å­˜åˆ°: {chart_file}")
            except Exception as e:
                print(f"å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
    
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­äº†æ€§èƒ½åˆ†æ")
    except Exception as e:
        logger.error(f"æ€§èƒ½ä¼˜åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print(f"âŒ æ€§èƒ½ä¼˜åŒ–å¤±è´¥: {e}")
        return 1
    
    finally:
        optimizer.cleanup()
    
    return 0


if __name__ == "__main__":
    sys.exit(main())
