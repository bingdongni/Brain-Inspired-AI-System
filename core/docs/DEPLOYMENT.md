# Brain-Inspired AI éƒ¨ç½²æŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜å¦‚ä½•åœ¨å„ç§ç¯å¢ƒä¸­éƒ¨ç½²å’Œé…ç½®Brain-Inspired AI Frameworkã€‚

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [æœ¬åœ°å¼€å‘éƒ¨ç½²](#æœ¬åœ°å¼€å‘éƒ¨ç½²)
- [ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²](#ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²)
- [Dockeréƒ¨ç½²](#dockeréƒ¨ç½²)
- [äº‘å¹³å°éƒ¨ç½²](#äº‘å¹³å°éƒ¨ç½²)
- [ç›‘æ§å’Œç»´æŠ¤](#ç›‘æ§å’Œç»´æŠ¤)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## ç¯å¢ƒå‡†å¤‡

### ç³»ç»Ÿè¦æ±‚

#### æœ€ä½è¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Linux (Ubuntu 20.04+), macOS 10.15+, Windows 10+
- **Python**: 3.8+
- **å†…å­˜**: 8GB RAM
- **å­˜å‚¨**: 10GB å¯ç”¨ç©ºé—´
- **CPU**: 4æ ¸å¤„ç†å™¨

#### æ¨èé…ç½®
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 22.04 LTS
- **Python**: 3.10+
- **å†…å­˜**: 16GB+ RAM
- **å­˜å‚¨**: 50GB+ SSD
- **CPU**: 8æ ¸+ å¤„ç†å™¨
- **GPU**: NVIDIA RTX 3080+ (å¯é€‰ï¼Œç”¨äºåŠ é€Ÿ)

#### ç”Ÿäº§ç¯å¢ƒé…ç½®
- **å†…å­˜**: 32GB+ RAM
- **å­˜å‚¨**: 100GB+ NVMe SSD
- **CPU**: 16æ ¸+ å¤„ç†å™¨
- **GPU**: NVIDIA A100/V100 (æ¨è)
- **ç½‘ç»œ**: 1Gbps+

### ä¾èµ–è½¯ä»¶

#### å¿…éœ€ä¾èµ–
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install -y python3.10 python3.10-venv python3-pip python3-dev
sudo apt install -y build-essential cmake git curl wget
sudo apt install -y libpq-dev libssl-dev libffi-dev

# macOS (ä½¿ç”¨Homebrew)
brew install python@3.10 cmake git curl wget postgresql

# Windows (ä½¿ç”¨Chocolatey)
choco install python310 cmake git curl wget postgresql
```

#### GPUæ”¯æŒ (å¯é€‰)
```bash
# å®‰è£…CUDA Toolkit 11.8+
# ä¸‹è½½åœ°å€: https://developer.nvidia.com/cuda-downloads

# éªŒè¯å®‰è£…
nvidia-smi
nvcc --version
```

## æœ¬åœ°å¼€å‘éƒ¨ç½²

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨Pythonè™šæ‹Ÿç¯å¢ƒ

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/brain-ai/brain-inspired-ai.git
cd brain-inspired-ai

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv_dev
source venv_dev/bin/activate  # Linux/Mac
# venv_dev\Scripts\activate  # Windows

# 3. å®‰è£…ä¾èµ–
pip install --upgrade pip
pip install -r requirements.txt
pip install -e .

# 4. éªŒè¯å®‰è£…
python -c "from brain_ai import HippocampusSimulator; print('å®‰è£…æˆåŠŸ!')"

# 5. è¿è¡Œå¼€å‘æœåŠ¡å™¨
make serve
# æˆ–è€…
brain-ai serve --config config/development.yaml
```

### æ–¹æ³•äºŒï¼šä½¿ç”¨Makefile

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/brain-ai/brain-inspired-ai.git
cd brain-inspired-ai

# è‡ªåŠ¨è®¾ç½®å¼€å‘ç¯å¢ƒ
make dev-setup

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv_dev/bin/activate

# è¿è¡Œæµ‹è¯•
make dev-test

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
make serve
```

### å¼€å‘ç¯å¢ƒé…ç½®

#### é…ç½®æ–‡ä»¶ (config/development.yaml)
```yaml
# å¼€å‘ç¯å¢ƒç‰¹å®šé…ç½®
system:
  device: "auto"
  num_workers: 2
  batch_size: 16

logging:
  level: "DEBUG"
  file: "logs/brain_ai_dev.log"

server:
  http:
    host: "127.0.0.1"
    port: 8000
    workers: 1

security:
  authentication:
    enabled: false
```

#### ç¯å¢ƒå˜é‡è®¾ç½®
```bash
# åˆ›å»º .env æ–‡ä»¶
cat > .env << EOF
ENVIRONMENT=development
DEBUG=true
LOG_LEVEL=DEBUG
DATABASE_URL=sqlite:///brain_ai_dev.db
REDIS_URL=redis://localhost:6379/0
SECRET_KEY=dev-secret-key-change-in-production
EOF

# åŠ è½½ç¯å¢ƒå˜é‡
source .env
```

### IDEé…ç½®

#### VS Code
```json
// .vscode/settings.json
{
    "python.defaultInterpreterPath": "./venv_dev/bin/python",
    "python.linting.enabled": true,
    "python.linting.flake8Enabled": true,
    "python.formatting.provider": "black",
    "python.testing.pytestEnabled": true,
    "python.testing.pytestArgs": ["tests/"],
    "files.associations": {
        "*.yaml": "yaml",
        "*.yml": "yaml"
    }
}
```

#### PyCharm
1. è®¾ç½®Pythonè§£é‡Šå™¨ä¸º `venv_dev/bin/python`
2. å¯ç”¨ä»£ç æ£€æŸ¥å’Œæ ¼å¼åŒ–
3. é…ç½®æµ‹è¯•è¿è¡Œå™¨ä¸ºpytest

## ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### éƒ¨ç½²æ¶æ„

```
                    [Load Balancer]
                           |
                   [Nginx Reverse Proxy]
                           |
                [Brain-AI API Servers]
                           |
    [Database] [Redis Cache] [Message Queue] [Storage]
```

### å‰ç½®æ¡ä»¶

#### ç³»ç»Ÿä¼˜åŒ–
```bash
# å¢åŠ æ–‡ä»¶æè¿°ç¬¦é™åˆ¶
echo "* soft nofile 65536" >> /etc/security/limits.conf
echo "* hard nofile 65536" >> /etc/security/limits.conf

# ä¼˜åŒ–ç½‘ç»œå‚æ•°
echo "net.core.somaxconn = 65536" >> /etc/sysctl.conf
echo "net.ipv4.tcp_max_syn_backlog = 65536" >> /etc/sysctl.conf
sysctl -p

# è®¾ç½®æ—¶åŒº
timedatectl set-timezone Asia/Shanghai
```

#### ç”¨æˆ·å’Œæƒé™
```bash
# åˆ›å»ºä¸“ç”¨ç”¨æˆ·
sudo useradd -r -s /bin/bash brain-ai
sudo usermod -aG sudo brain-ai

# åˆ›å»ºåº”ç”¨ç›®å½•
sudo mkdir -p /opt/brain-ai
sudo chown brain-ai:brain-ai /opt/brain-ai
```

### éƒ¨ç½²æ­¥éª¤

#### 1. å®‰è£…åº”ç”¨
```bash
# åˆ‡æ¢åˆ°brain-aiç”¨æˆ·
sudo su - brain-ai

# å…‹éš†é¡¹ç›®
cd /opt/brain-ai
git clone https://github.com/brain-ai/brain-inspired-ai.git .
git checkout v1.0.0  # ä½¿ç”¨ç¨³å®šç‰ˆæœ¬

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# å®‰è£…ä¾èµ–
pip install --upgrade pip
pip install -r requirements.txt
pip install -e .

# è®¾ç½®æƒé™
chmod +x scripts/*.sh
```

#### 2. é…ç½®ç¯å¢ƒ
```bash
# åˆ›å»ºç”Ÿäº§ç¯å¢ƒé…ç½®
cp config/production.yaml config/production-local.yaml

# ç¼–è¾‘é…ç½®æ–‡ä»¶
vim config/production-local.yaml
```

```yaml
# ç”Ÿäº§ç¯å¢ƒé…ç½®ç¤ºä¾‹
system:
  device: "cuda"
  num_workers: 8
  batch_size: 64

database:
  primary:
    type: "postgresql"
    host: "localhost"
    port: 5432
    database: "brain_ai_prod"
    username: "brain_ai"
    password: "secure_password_123"
    pool_size: 20
    max_overflow: 30

redis:
  host: "localhost"
  port: 6379
  db: 0
  password: "redis_password_123"

logging:
  level: "INFO"
  file: "/var/log/brain-ai/brain_ai.log"
  max_size: "100MB"
  backup_count: 10

server:
  http:
    host: "0.0.0.0"
    port: 8080
    workers: 4
    worker_class: "uvicorn.workers.UvicornWorker"
    max_requests: 10000
    timeout: 30

security:
  authentication:
    enabled: true
    secret_key: "your-production-secret-key"
    access_token_expire_minutes: 30
```

#### 3. åˆå§‹åŒ–æ•°æ®åº“
```bash
# åˆ›å»ºPostgreSQLæ•°æ®åº“
sudo -u postgres psql << EOF
CREATE DATABASE brain_ai_prod;
CREATE USER brain_ai WITH PASSWORD 'secure_password_123';
GRANT ALL PRIVILEGES ON DATABASE brain_ai_prod TO brain_ai;
ALTER USER brain_ai CREATEDB;
EOF

# åˆå§‹åŒ–æ•°æ®åº“è¡¨
python -m brain_ai.scripts.init_db --config config/production-local.yaml
```

#### 4. åˆ›å»ºç³»ç»ŸæœåŠ¡
```bash
# åˆ›å»ºsystemdæœåŠ¡æ–‡ä»¶
sudo tee /etc/systemd/system/brain-ai.service > /dev/null << EOF
[Unit]
Description=Brain-Inspired AI Service
After=network.target postgresql.service redis.service
Wants=postgresql.service redis.service

[Service]
Type=exec
User=brain-ai
Group=brain-ai
WorkingDirectory=/opt/brain-ai
Environment=PATH=/opt/brain-ai/venv/bin
EnvironmentFile=/opt/brain-ai/.env
ExecStart=/opt/brain-ai/venv/bin/python -m brain_ai.scripts.serve --config config/production-local.yaml
ExecReload=/bin/kill -HUP \$MAINPID
Restart=always
RestartSec=5

# å®‰å…¨è®¾ç½®
NoNewPrivileges=yes
PrivateTmp=yes
ProtectSystem=strict
ProtectHome=yes
ReadWritePaths=/opt/brain-ai/logs /opt/brain-ai/data /opt/brain-ai/models

[Install]
WantedBy=multi-user.target
EOF

# é‡æ–°åŠ è½½systemdå¹¶å¯ç”¨æœåŠ¡
sudo systemctl daemon-reload
sudo systemctl enable brain-ai
```

#### 5. è®¾ç½®Nginxåå‘ä»£ç†
```bash
# å®‰è£…Nginx
sudo apt install nginx

# åˆ›å»ºNginxé…ç½®
sudo tee /etc/nginx/sites-available/brain-ai > /dev/null << EOF
server {
    listen 80;
    server_name your-domain.com;

    # é‡å®šå‘åˆ°HTTPS
    return 301 https://\$server_name\$request_uri;
}

server {
    listen 443 ssl http2;
    server_name your-domain.com;

    # SSLé…ç½®
    ssl_certificate /etc/ssl/certs/brain-ai.crt;
    ssl_certificate_key /etc/ssl/private/brain-ai.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers on;

    # å®‰å…¨å¤´
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

    # é™åˆ¶è¯·æ±‚å¤§å°
    client_max_body_size 100M;

    # ä»£ç†åˆ°Brain-AIåº”ç”¨
    location / {
        proxy_pass http://127.0.0.1:8080;
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto \$scheme;
        
        # WebSocketæ”¯æŒ
        proxy_http_version 1.1;
        proxy_set_header Upgrade \$http_upgrade;
        proxy_set_header Connection "upgrade";
        
        # è¶…æ—¶è®¾ç½®
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    # é™æ€æ–‡ä»¶ç¼“å­˜
    location /static/ {
        alias /opt/brain-ai/static/;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }

    # å¥åº·æ£€æŸ¥
    location /health {
        proxy_pass http://127.0.0.1:8080/health;
        access_log off;
    }
}
EOF

# å¯ç”¨ç«™ç‚¹
sudo ln -s /etc/nginx/sites-available/brain-ai /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl reload nginx
```

#### 6. å¯åŠ¨æœåŠ¡
```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
sudo systemctl start brain-ai
sudo systemctl start postgresql
sudo systemctl start redis

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
sudo systemctl status brain-ai
sudo systemctl status postgresql
sudo systemctl status redis

# æŸ¥çœ‹æ—¥å¿—
sudo journalctl -u brain-ai -f
```

### ä½¿ç”¨éƒ¨ç½²è„šæœ¬

é¡¹ç›®æä¾›äº†è‡ªåŠ¨åŒ–çš„éƒ¨ç½²è„šæœ¬ï¼š

```bash
# éƒ¨ç½²åˆ°å¼€å‘ç¯å¢ƒ
./scripts/deploy.sh deploy development

# éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
./scripts/deploy.sh deploy production

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
./scripts/deploy.sh start-dev

# æ¸…ç†ç¯å¢ƒ
./scripts/deploy.sh cleanup all
```

## Dockeréƒ¨ç½²

### å•å®¹å™¨éƒ¨ç½²

```bash
# æ„å»ºé•œåƒ
docker build -t brain-ai:latest .

# è¿è¡Œå®¹å™¨
docker run -d \
  --name brain-ai \
  -p 8080:8080 \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/logs:/app/logs \
  --gpus all \
  brain-ai:latest
```

### Docker Composeéƒ¨ç½²

#### åŸºç¡€æœåŠ¡
```bash
# å¯åŠ¨æ ¸å¿ƒæœåŠ¡
docker-compose up brain-ai redis postgres -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f brain-ai
```

#### å®Œæ•´æœåŠ¡æ ˆ
```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼ˆåŒ…æ‹¬ç›‘æ§ï¼‰
docker-compose --profile monitoring up -d

# ä»…å¯åŠ¨ç‰¹å®šæœåŠ¡
docker-compose up brain-ai influxdb grafana -d
```

#### ç”Ÿäº§ç¯å¢ƒDocker Compose
```bash
# ä½¿ç”¨ç”Ÿäº§é…ç½®
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

# æ‰©å±•æœåŠ¡
docker-compose up --scale brain-ai=3 -d
```

### Kuberneteséƒ¨ç½²

#### éƒ¨ç½²æ¸…å•
```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: brain-ai

---
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: brain-ai-config
  namespace: brain-ai
data:
  production.yaml: |
    # ç”Ÿäº§é…ç½®å†…å®¹

---
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: brain-ai
  namespace: brain-ai
spec:
  replicas: 3
  selector:
    matchLabels:
      app: brain-ai
  template:
    metadata:
      labels:
        app: brain-ai
    spec:
      containers:
      - name: brain-ai
        image: brain-ai:latest
        ports:
        - containerPort: 8080
        env:
        - name: CONFIG_FILE
          value: "/app/config/production.yaml"
        volumeMounts:
        - name: config
          mountPath: /app/config
        - name: data
          mountPath: /app/data
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
      volumes:
      - name: config
        configMap:
          name: brain-ai-config
      - name: data
        persistentVolumeClaim:
          claimName: brain-ai-data

---
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: brain-ai-service
  namespace: brain-ai
spec:
  selector:
    app: brain-ai
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
  type: ClusterIP

---
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: brain-ai-ingress
  namespace: brain-ai
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - api.brain-ai.org
    secretName: brain-ai-tls
  rules:
  - host: api.brain-ai.org
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: brain-ai-service
            port:
              number: 80
```

#### éƒ¨ç½²åˆ°Kubernetes
```bash
# åˆ›å»ºå‘½åç©ºé—´
kubectl apply -f k8s/namespace.yaml

# éƒ¨ç½²åº”ç”¨
kubectl apply -f k8s/

# æ£€æŸ¥éƒ¨ç½²çŠ¶æ€
kubectl get pods -n brain-ai
kubectl get services -n brain-ai
kubectl get ingress -n brain-ai

# æŸ¥çœ‹æ—¥å¿—
kubectl logs -f deployment/brain-ai -n brain-ai
```

## äº‘å¹³å°éƒ¨ç½²

### AWSéƒ¨ç½²

#### ä½¿ç”¨ECS
```bash
# æ„å»ºå¹¶æ¨é€Dockeré•œåƒåˆ°ECR
aws ecr create-repository --repository-name brain-ai
$(aws ecr get-login --no-include-email --region us-west-2)
docker build -t brain-ai .
docker tag brain-ai:latest 123456789.dkr.ecr.us-west-2.amazonaws.com/brain-ai:latest
docker push 123456789.dkr.ecr.us-west-2.amazonaws.com/brain-ai:latest

# åˆ›å»ºECSä»»åŠ¡å®šä¹‰
aws ecs register-task-definition --cli-input-json file://aws/task-definition.json

# åˆ›å»ºECSæœåŠ¡
aws ecs create-service \
  --cluster brain-ai-cluster \
  --service-name brain-ai-service \
  --task-definition brain-ai:1 \
  --desired-count 3
```

#### ä½¿ç”¨Lambda (é€‚ç”¨äºæ— æœåŠ¡å™¨)
```python
# lambda_function.py
import json
import boto3
from brain_ai import HippocampusSimulator

def lambda_handler(event, context):
    # åˆå§‹åŒ–æµ·é©¬ä½“æ¨¡æ‹Ÿå™¨
    hippocampus = HippocampusSimulator()
    
    # å¤„ç†è¯·æ±‚
    input_data = event.get('input_data')
    result = hippocampus.process(input_data)
    
    return {
        'statusCode': 200,
        'body': json.dumps({
            'result': result
        })
    }
```

### GCPéƒ¨ç½²

#### ä½¿ç”¨Cloud Run
```bash
# æ„å»ºå¹¶éƒ¨ç½²åˆ°Cloud Run
gcloud builds submit --tag gcr.io/PROJECT-ID/brain-ai
gcloud run deploy brain-ai \
  --image gcr.io/PROJECT-ID/brain-ai \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --memory 2Gi \
  --cpu 2
```

### Azureéƒ¨ç½²

#### ä½¿ç”¨Container Instances
```bash
# åˆ›å»ºèµ„æºç»„
az group create --name brain-ai-rg --location eastus

# åˆ›å»ºå®¹å™¨å®ä¾‹
az container create \
  --resource-group brain-ai-rg \
  --name brain-ai \
  --image brain-ai:latest \
  --dns-name-label brain-ai \
  --ports 8080 \
  --memory 2 \
  --cpu 2
```

## ç›‘æ§å’Œç»´æŠ¤

### å¥åº·æ£€æŸ¥

#### ç«¯ç‚¹æ£€æŸ¥
```bash
# åŸºç¡€å¥åº·æ£€æŸ¥
curl -f http://localhost:8080/health

# è¯¦ç»†çŠ¶æ€æ£€æŸ¥
curl -f http://localhost:8080/status

# APIå¯ç”¨æ€§æµ‹è¯•
curl -X POST http://localhost:8080/predict \
  -H "Content-Type: application/json" \
  -d '{"input": "æµ‹è¯•æ•°æ®"}'
```

#### ç³»ç»Ÿç›‘æ§è„šæœ¬
```bash
#!/bin/bash
# monitor.sh

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
check_service() {
    if ! systemctl is-active --quiet brain-ai; then
        echo "é”™è¯¯: Brain-AIæœåŠ¡æœªè¿è¡Œ"
        return 1
    fi
    
    # æ£€æŸ¥ç«¯å£
    if ! netstat -ln | grep -q ":8080 "; then
        echo "é”™è¯¯: ç«¯å£8080æœªç›‘å¬"
        return 1
    fi
    
    # æ£€æŸ¥å¥åº·ç«¯ç‚¹
    if ! curl -f http://localhost:8080/health > /dev/null 2>&1; then
        echo "é”™è¯¯: å¥åº·æ£€æŸ¥å¤±è´¥"
        return 1
    fi
    
    echo "æœåŠ¡çŠ¶æ€æ­£å¸¸"
    return 0
}

# æ£€æŸ¥èµ„æºä½¿ç”¨
check_resources() {
    # CPUä½¿ç”¨ç‡
    cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')
    echo "CPUä½¿ç”¨ç‡: ${cpu_usage}%"
    
    # å†…å­˜ä½¿ç”¨
    memory_info=$(free -m | awk 'NR==2{printf "%.1f%%", $3*100/$2}')
    echo "å†…å­˜ä½¿ç”¨: ${memory_info}"
    
    # ç£ç›˜ä½¿ç”¨
    disk_usage=$(df -h / | awk 'NR==2{print $5}')
    echo "ç£ç›˜ä½¿ç”¨: ${disk_usage}"
}

# å‘é€å‘Šè­¦
send_alert() {
    local message="$1"
    # è¿™é‡Œå¯ä»¥é›†æˆé‚®ä»¶ã€Slackç­‰å‘Šè­¦æ–¹å¼
    echo "$(date): $message" >> /var/log/brain-ai/alerts.log
}

# ä¸»æ£€æŸ¥é€»è¾‘
main() {
    echo "å¼€å§‹ç³»ç»Ÿç›‘æ§æ£€æŸ¥..."
    
    if ! check_service; then
        send_alert "æœåŠ¡æ£€æŸ¥å¤±è´¥"
        exit 1
    fi
    
    check_resources
    echo "ç›‘æ§æ£€æŸ¥å®Œæˆ"
}

main "$@"
```

### æ—¥å¿—ç®¡ç†

#### æ—¥å¿—è½®è½¬é…ç½®
```bash
# /etc/logrotate.d/brain-ai
/var/log/brain-ai/*.log {
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    sharedscripts
    postrotate
        systemctl reload brain-ai
    endscript
}
```

#### é›†ä¸­åŒ–æ—¥å¿—
```yaml
# ä½¿ç”¨ELK Stack
version: '3.8'
services:
  elasticsearch:
    image: elasticsearch:7.15.0
    environment:
      - discovery.type=single-node
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
  
  logstash:
    image: logstash:7.15.0
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    depends_on:
      - elasticsearch
  
  kibana:
    image: kibana:7.15.0
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
```

### å¤‡ä»½ç­–ç•¥

#### æ•°æ®åº“å¤‡ä»½
```bash
#!/bin/bash
# backup_db.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/opt/backups"
DB_NAME="brain_ai_prod"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# PostgreSQLå¤‡ä»½
pg_dump -h localhost -U brain-ai -d $DB_NAME \
  --format=custom --verbose --file="$BACKUP_DIR/brain_ai_$DATE.backup"

# å‹ç¼©å¤‡ä»½
gzip "$BACKUP_DIR/brain_ai_$DATE.backup"

# æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™7å¤©ï¼‰
find $BACKUP_DIR -name "brain_ai_*.backup.gz" -mtime +7 -delete

echo "æ•°æ®åº“å¤‡ä»½å®Œæˆ: brain_ai_$DATE.backup.gz"
```

#### æ–‡ä»¶ç³»ç»Ÿå¤‡ä»½
```bash
#!/bin/bash
# backup_fs.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/opt/backups/files"
SOURCE_DIR="/opt/brain-ai"

# åˆ›å»ºå¤‡ä»½
tar -czf "$BACKUP_DIR/brain_ai_files_$DATE.tar.gz" \
  -C "$SOURCE_DIR" \
  --exclude='venv' \
  --exclude='.git' \
  --exclude='logs' \
  --exclude='__pycache__' \
  data/ models/ config/

echo "æ–‡ä»¶å¤‡ä»½å®Œæˆ: brain_ai_files_$DATE.tar.gz"
```

### æ€§èƒ½ä¼˜åŒ–

#### ç³»ç»Ÿä¼˜åŒ–
```bash
# /etc/sysctl.conf ä¼˜åŒ–
# ç½‘ç»œä¼˜åŒ–
net.core.rmem_max = 134217728
net.core.wmem_max = 134217728
net.ipv4.tcp_rmem = 4096 65536 134217728
net.ipv4.tcp_wmem = 4096 65536 134217728
net.core.netdev_max_backlog = 5000

# æ–‡ä»¶ç³»ç»Ÿä¼˜åŒ–
fs.file-max = 2097152
vm.swappiness = 10

# åº”ç”¨ä¼˜åŒ–
kernel.sched_migration_cost_ns = 5000000
kernel.sched_autogroup_enabled = 0
```

#### åº”ç”¨ä¼˜åŒ–
```yaml
# ç”Ÿäº§é…ç½®ä¼˜åŒ–
training:
  batch_size: 64
  num_workers: 8
  pin_memory: true
  mixed_precision:
    enabled: true

server:
  http:
    workers: 4
    worker_class: "uvicorn.workers.UvicornWorker"
    max_requests: 10000
    max_requests_jitter: 1000
    timeout: 30
    keepalive: 5
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. æœåŠ¡å¯åŠ¨å¤±è´¥
```bash
# æ£€æŸ¥æ—¥å¿—
sudo journalctl -u brain-ai -n 50

# æ£€æŸ¥é…ç½®æ–‡ä»¶
python -m brain_ai.scripts.config validate --config config/production.yaml

# æ£€æŸ¥ä¾èµ–
pip check

# æƒé™æ£€æŸ¥
ls -la /opt/brain-ai/
```

#### 2. å†…å­˜ä¸è¶³
```bash
# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h
ps aux --sort=-%mem | head

# è°ƒæ•´æ‰¹æ¬¡å¤§å°
export BRAIN_AI_BATCH_SIZE=16

# å¯ç”¨å†…å­˜ä¼˜åŒ–
export BRAIN_AI_MEMORY_OPTIMIZATION=true
```

#### 3. GPUä¸å¯ç”¨
```bash
# æ£€æŸ¥CUDAå®‰è£…
nvcc --version
nvidia-smi

# æ£€æŸ¥PyTorch GPUæ”¯æŒ
python -c "import torch; print(torch.cuda.is_available())"

# å¼ºåˆ¶ä½¿ç”¨CPU
export BRAIN_AI_DEVICE=cpu
```

#### 4. æ•°æ®åº“è¿æ¥å¤±è´¥
```bash
# æ£€æŸ¥PostgreSQLçŠ¶æ€
sudo systemctl status postgresql

# æµ‹è¯•è¿æ¥
psql -h localhost -U brain-ai -d brain_ai_prod

# æ£€æŸ¥é…ç½®
grep DATABASE_URL config/production.yaml
```

### è°ƒè¯•æ¨¡å¼

#### å¯ç”¨è°ƒè¯•
```bash
# è®¾ç½®è°ƒè¯•ç¯å¢ƒå˜é‡
export BRAIN_AI_DEBUG=true
export BRAIN_AI_LOG_LEVEL=DEBUG

# ä»¥è°ƒè¯•æ¨¡å¼å¯åŠ¨
python -m brain_ai.scripts.serve --debug --config config/development.yaml
```

#### æ€§èƒ½åˆ†æ
```bash
# CPUåˆ†æ
python -m cProfile -o profile.stats -m brain_ai.scripts.serve

# å†…å­˜åˆ†æ
python -m memory_profiler -m brain_ai.scripts.serve

# ä½¿ç”¨Py-Spy
py-spy top --pid $(pgrep -f brain_ai)
```

### æ¢å¤æ“ä½œ

#### æœåŠ¡æ¢å¤
```bash
# é‡å¯æœåŠ¡
sudo systemctl restart brain-ai

# å›æ»šåˆ°ä¸Šä¸€ä¸ªç‰ˆæœ¬
cd /opt/brain-ai
git checkout HEAD~1
sudo systemctl restart brain-ai

# ä»å¤‡ä»½æ¢å¤
# æ¢å¤æ•°æ®åº“
pg_restore -h localhost -U brain-ai -d brain_ai_prod /opt/backups/brain_ai_latest.backup

# æ¢å¤æ–‡ä»¶
tar -xzf /opt/backups/brain_ai_files_latest.tar.gz -C /opt/brain-ai/
```

## æ€»ç»“

æœ¬éƒ¨ç½²æŒ‡å—æ¶µç›–äº†Brain-Inspired AI Frameworkåœ¨å„ç§ç¯å¢ƒä¸‹çš„éƒ¨ç½²æ–¹æ³•ã€‚å»ºè®®ï¼š

1. **å¼€å‘ç¯å¢ƒ**: ä½¿ç”¨æœ¬åœ°Pythonç¯å¢ƒæˆ–Docker
2. **æµ‹è¯•ç¯å¢ƒ**: ä½¿ç”¨Docker Compose
3. **ç”Ÿäº§ç¯å¢ƒ**: ä½¿ç”¨systemd + Nginxæˆ–Kubernetes
4. **äº‘å¹³å°**: ä½¿ç”¨æ‰˜ç®¡æœåŠ¡å¦‚AWS ECSã€GCP Cloud Runç­‰

é€‰æ‹©æœ€é€‚åˆæ‚¨éœ€æ±‚å’ŒåŸºç¡€è®¾æ–½çš„éƒ¨ç½²æ–¹æ¡ˆï¼Œå¹¶ç¡®ä¿å®æ–½é€‚å½“çš„ç›‘æ§ã€å¤‡ä»½å’Œå®‰å…¨æªæ–½ã€‚

å¦‚æœ‰é—®é¢˜ï¼Œè¯·å‚è€ƒé¡¹ç›®çš„[GitHub Issues](https://github.com/brain-ai/brain-inspired-ai/issues)æˆ–è”ç³»å¼€å‘å›¢é˜Ÿã€‚