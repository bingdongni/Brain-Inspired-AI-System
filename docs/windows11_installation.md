# Windows 11 å®Œæ•´å®‰è£…æŒ‡å—

## ğŸ“‹ ç›®å½•
- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [å®‰è£…å‰å‡†å¤‡](#å®‰è£…å‰å‡†å¤‡)
- [Pythonç¯å¢ƒå®‰è£…](#pythonç¯å¢ƒå®‰è£…)
- [ä¾èµ–åŒ…å®‰è£…](#ä¾èµ–åŒ…å®‰è£…)
- [Node.jså’ŒWebç•Œé¢è®¾ç½®](#nodejså’Œwebç•Œé¢è®¾ç½®)
- [Jupyterç¯å¢ƒé…ç½®](#jupyterç¯å¢ƒé…ç½®)
- [GPUæ”¯æŒé…ç½®](#gpuæ”¯æŒé…ç½®)
- [CLIå·¥å…·ä½¿ç”¨æŒ‡å—](#cliå·¥å…·ä½¿ç”¨æŒ‡å—)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
- [ç¯å¢ƒéªŒè¯](#ç¯å¢ƒéªŒè¯)

## ğŸ¯ ç³»ç»Ÿè¦æ±‚

### æœ€ä½é…ç½®
- **æ“ä½œç³»ç»Ÿ**: Windows 11 (21H2æˆ–æ›´é«˜ç‰ˆæœ¬)
- **å†…å­˜**: 8GB RAM (æ¨è16GB+)
- **å­˜å‚¨**: è‡³å°‘20GBå¯ç”¨ç©ºé—´ (æ¨è50GB+)
- **Python**: 3.8+ (æ¨èPython 3.11æˆ–3.12)
- **ç½‘ç»œ**: å®½å¸¦è¿æ¥ (ç”¨äºä¸‹è½½ä¾èµ–åŒ…)

### æ¨èé…ç½®
- **å¤„ç†å™¨**: Intel i5/AMD Ryzen 5æˆ–æ›´é«˜
- **å†…å­˜**: 32GB RAM
- **GPU**: NVIDIA RTX 3060æˆ–æ›´é«˜ (æ”¯æŒCUDA)
- **å­˜å‚¨**: SSD 100GB+

## ğŸ› ï¸ å®‰è£…å‰å‡†å¤‡

### 1. å¯ç”¨WindowsåŠŸèƒ½

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä»¥ä¸‹WindowsåŠŸèƒ½å·²å¯ç”¨ï¼š

```powershell
# ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡ŒPowerShellï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š
Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All
Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V-Management-PowerShell -All
```

### 2. è®¾ç½®Windows Terminalï¼ˆæ¨èï¼‰

```powershell
# å®‰è£…Windows Terminal (é€šè¿‡Microsoft Store)
# æˆ–è€…é€šè¿‡winget
winget install Microsoft.WindowsTerminal
```

### 3. é…ç½®Windowså­ç³»ç»ŸLinux (WSL2) - å¯é€‰

å¦‚æœæ‚¨æƒ³è¦Linuxç¯å¢ƒä½“éªŒï¼š

```powershell
# å¯ç”¨WSL2
wsl --install

# é‡å¯ç”µè„‘åï¼Œè®¾ç½®Ubuntuä½œä¸ºé»˜è®¤å‘è¡Œç‰ˆ
wsl --setdefault Ubuntu-22.04
```

## ğŸ Pythonç¯å¢ƒå®‰è£…

### æ–¹æ¡ˆä¸€ï¼šå®˜æ–¹Pythonå®‰è£…ï¼ˆæ¨èï¼‰

#### 1. ä¸‹è½½Python

è®¿é—® [python.org](https://www.python.org/downloads/) ä¸‹è½½Python 3.11æˆ–3.12ç‰ˆæœ¬ã€‚

#### 2. å®‰è£…Python

```bash
# ä¸‹è½½å®Œæˆåï¼Œè¿è¡Œå®‰è£…ç¨‹åº
# é‡è¦ï¼šå‹¾é€‰ "Add Python to PATH"
# é€‰æ‹© "Customize Installation"
# åœ¨ "Optional Features" é¡µé¢å‹¾é€‰ï¼š
# - pip
# - tcl/tk and IDLE
# - Python test suite
# - py launcher
# - for all users

# åœ¨ "Advanced Options" é¡µé¢å‹¾é€‰ï¼š
# - Install for all users
# - Add Python to environment variables
```

#### 3. éªŒè¯å®‰è£…

```bash
# æ‰“å¼€æ–°çš„CMDæˆ–PowerShellçª—å£
python --version
pip --version

# å¦‚æœæ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯ï¼Œè¯´æ˜å®‰è£…æˆåŠŸ
```

### æ–¹æ¡ˆäºŒï¼šAnaconda/Minicondaå®‰è£…

#### 1. ä¸‹è½½Anaconda

è®¿é—® [anaconda.com](https://www.anaconda.com/products/distribution) ä¸‹è½½æœ€æ–°ç‰ˆæœ¬ã€‚

#### 2. å®‰è£…Anaconda

```bash
# è¿è¡Œå®‰è£…ç¨‹åº
# å»ºè®®é€‰æ‹© "Just Me" å®‰è£…
# å‹¾é€‰ "Add Anaconda to PATH"
# å‹¾é€‰ "Register Anaconda as my default Python"
```

#### 3. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# åˆ›å»ºä¸“é—¨çš„è™šæ‹Ÿç¯å¢ƒ
conda create -n brain_ai python=3.11
conda activate brain_ai

# éªŒè¯ç¯å¢ƒ
python --version
```

### æ–¹æ¡ˆä¸‰ï¼šMicrosoft Storeå®‰è£…

1. æ‰“å¼€Microsoft Store
2. æœç´¢ "Python 3.11"
3. ç‚¹å‡»"å®‰è£…"
4. ç­‰å¾…å®‰è£…å®Œæˆ

## ğŸ“¦ ä¾èµ–åŒ…å®‰è£…

### 1. åŸºç¡€ä¾èµ–å®‰è£…

#### ä½¿ç”¨pipå®‰è£…

```bash
# åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir brain-inspired-ai
cd brain-inspired-ai

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (å¦‚æœæœªä½¿ç”¨conda)
python -m venv brain_ai_env
brain_ai_env\Scripts\activate  # CMD
# æˆ–
.\brain_ai_env\Scripts\Activate.ps1  # PowerShell

# å‡çº§pip
python -m pip install --upgrade pip

# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install tensorflow keras
pip install numpy scipy pandas scikit-learn
pip install matplotlib seaborn pillow opencv-python
pip install jupyter jupyterlab ipywidgets
```

#### ä½¿ç”¨condaå®‰è£… (æ¨èé€Ÿåº¦æ›´å¿«)

```bash
# å¦‚æœä½¿ç”¨Anaconda
conda create -n brain_ai python=3.11
conda activate brain_ai

# å®‰è£…æ·±åº¦å­¦ä¹ æ¡†æ¶
conda install pytorch torchvision torchaudio cpuonly -c pytorch
conda install tensorflow
conda install numpy scipy pandas scikit-learn
conda install matplotlib seaborn pillow opencv
conda install jupyter jupyterlab ipywidgets

# å®‰è£…é¢å¤–ä¾èµ–
conda install -c conda-forge nixio pyefd
conda install wandb tensorboard rich
```

### 2. å®Œæ•´ä¾èµ–å®‰è£…

```bash
# å¦‚æœæ‚¨å·²è·å¾—å®Œæ•´é¡¹ç›®åŒ…ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…æ‰€æœ‰ä¾èµ–ï¼š
pip install -r requirements.txt
pip install -e .

# æˆ–è€…ä½¿ç”¨conda
conda env create -f environment.yml
```

### 3. éªŒè¯PyTorchå®‰è£…

```python
# åˆ›å»ºæµ‹è¯•æ–‡ä»¶ test_pytorch.py
import torch
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAæ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}")
print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
print(f"GPUæ•°é‡: {torch.cuda.device_count()}")

if torch.cuda.is_available():
    print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
```

```bash
# è¿è¡Œæµ‹è¯•
python test_pytorch.py
```

## ğŸŒ Node.jså’ŒWebç•Œé¢è®¾ç½®

### 1. å®‰è£…Node.js

#### æ–¹æ¡ˆä¸€ï¼šå®˜æ–¹å®‰è£…åŒ…

```bash
# è®¿é—® nodejs.org ä¸‹è½½LTSç‰ˆæœ¬
# å®‰è£…æ—¶å‹¾é€‰ "Add to PATH"
# éªŒè¯å®‰è£…
node --version
npm --version
```

#### æ–¹æ¡ˆäºŒï¼šwingetå®‰è£…

```powershell
winget install OpenJS.NodeJS
```

#### æ–¹æ¡ˆä¸‰ï¼šChocolateyå®‰è£…

```powershell
choco install nodejs
```

### 2. å®‰è£…pnpmï¼ˆæ¨èï¼‰

```bash
# å®‰è£…pnpmï¼ˆæ¯”npmæ›´å¿«ï¼‰
npm install -g pnpm

# éªŒè¯å®‰è£…
pnpm --version
```

### 3. é…ç½®Webç•Œé¢

```bash
# è¿›å…¥Webç•Œé¢ç›®å½•
cd ui/brain-ai-ui

# å®‰è£…ä¾èµ–
pnpm install

# æˆ–è€…ä½¿ç”¨npm
npm install

# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
pnpm dev

# æˆ–è€…
npm run dev

# è®¿é—®åœ°å€: http://localhost:5173
```

### 4. æ„å»ºç”Ÿäº§ç‰ˆæœ¬

```bash
# æ„å»ºç”Ÿäº§ç‰ˆæœ¬
pnpm build

# æˆ–è€…
npm run build

# é¢„è§ˆæ„å»ºç»“æœ
pnpm preview
```

## ğŸ““ Jupyterç¯å¢ƒé…ç½®

### 1. åŸºç¡€é…ç½®

```bash
# å¯åŠ¨Jupyter
jupyter lab

# æˆ–è€…
jupyter notebook
```

### 2. é…ç½®Jupyter

```bash
# ç”Ÿæˆé…ç½®æ–‡ä»¶
jupyter lab --generate-config

# è®¾ç½®å¯†ç 
jupyter lab password

# è®¾ç½®è¿œç¨‹è®¿é—® (å¯é€‰)
jupyter lab --ip=0.0.0.0 --port=8888 --no-browser
```

### 3. å®‰è£…Jupyteræ‰©å±•

```bash
# å®‰è£…å¸¸ç”¨æ‰©å±•
pip install jupyterlab-git
pip install jupyterlab-drawio
pip install @jupyter-widgets/jupyterlab-manager

# å¯ç”¨æ‰©å±•
jupyter labextension install @jupyter-widgets/jupyterlab-manager
jupyter labextension install jupyterlab-git
```

### 4. é…ç½®å†…æ ¸

```python
# åœ¨Jupyterä¸­æ³¨å†ŒPythonå†…æ ¸
import sys
print(sys.executable)

# æˆ–è€…ä½¿ç”¨å‘½ä»¤è¡Œ
python -m ipykernel install --user --name=brain_ai --display-name="Brain AI Environment"
```

## ğŸ® GPUæ”¯æŒé…ç½®

### NVIDIA GPUé…ç½®

#### 1. æ£€æŸ¥GPUæ”¯æŒ

```bash
# æ£€æŸ¥NVIDIA GPU
nvidia-smi

# æ£€æŸ¥CUDAå®‰è£…
nvcc --version
```

#### 2. å®‰è£…CUDAå·¥å…·åŒ…

```powershell
# æ–¹æ³•1: ä¸‹è½½å®‰è£…åŒ…
# è®¿é—® developer.nvidia.com/cuda-downloads
# ä¸‹è½½Windowsç‰ˆæœ¬CUDA Toolkit

# æ–¹æ³•2: ä½¿ç”¨winget
winget install Nvidia.CUDA

# æ–¹æ³•3: ä½¿ç”¨conda
conda install cudatoolkit=11.8
```

#### 3. é…ç½®PyTorch GPUæ”¯æŒ

```bash
# CPUç‰ˆæœ¬ï¼ˆå·²å®‰è£…ï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# CUDAç‰ˆæœ¬ (é€‰æ‹©å¯¹åº”çš„CUDAç‰ˆæœ¬)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118  # CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121  # CUDA 12.1
```

#### 4. éªŒè¯GPUæ”¯æŒ

```python
# åˆ›å»ºæµ‹è¯•æ–‡ä»¶ test_gpu.py
import torch

print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
    print(f"å½“å‰GPU: {torch.cuda.get_device_name(0)}")
    print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # ç®€å•GPUæµ‹è¯•
    device = torch.device('cuda')
    x = torch.rand(1000, 1000).to(device)
    y = torch.mm(x, x.t())
    print("GPUè®¡ç®—æµ‹è¯•é€šè¿‡!")
else:
    print("GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
```

```bash
python test_gpu.py
```

### AMD GPUé…ç½® (ROCm)

```bash
# AMD GPUæ”¯æŒæœ‰é™ï¼Œæ¨èä½¿ç”¨CPUç‰ˆæœ¬
# æˆ–è€…ä½¿ç”¨OpenCL
pip install pyopencl
```

## ğŸ’» CLIå·¥å…·ä½¿ç”¨æŒ‡å—

### 1. é¡¹ç›®CLIå·¥å…·

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd brain-inspired-ai

# æŸ¥çœ‹å¯ç”¨å‘½ä»¤
python cli_demo.py --help

# è¿è¡Œæ¼”ç¤ºæ¨¡å¼
python cli_demo.py --mode demo

# äº¤äº’å¼æ¨¡å¼
python cli_demo.py --mode interactive

# è‡ªå®šä¹‰å‚æ•°
python cli_demo.py --mode demo --dataset synthetic --model brain_inspired --epochs 5 --batch_size 32
```

### 2. å¸¸ç”¨CLIå‘½ä»¤

```bash
# å¿«é€Ÿæµ‹è¯•
python quick_test.py

# å®Œæ•´æµ‹è¯•å¥—ä»¶
python comprehensive_test_suite.py

# æ€§èƒ½åŸºå‡†æµ‹è¯•
python scripts/benchmark_test.py

# è¿è¡Œç‰¹å®šæ¼”ç¤º
python demos/memory_learning_demo.py
python demos/lifelong_learning_demo.py
python demos/dynamic_routing_demo.py
```

### 3. æ‰¹å¤„ç†è„šæœ¬

åˆ›å»º `run_demo.bat` æ–‡ä»¶ï¼š

```batch
@echo off
cd /d "D:\path\to\brain-inspired-ai"
call brain_ai_env\Scripts\activate
echo å¯åŠ¨Brain AIæ¼”ç¤º...
python cli_demo.py --mode demo
pause
```

### 4. PowerShellè„šæœ¬

åˆ›å»º `run_demo.ps1` æ–‡ä»¶ï¼š

```powershell
# è®¾ç½®æ‰§è¡Œç­–ç•¥
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

# åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•
Set-Location "D:\path\to\brain-inspired-ai"

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
& .\brain_ai_env\Scripts\Activate.ps1

# è¿è¡Œæ¼”ç¤º
Write-Host "å¯åŠ¨Brain AIæ¼”ç¤º..." -ForegroundColor Green
python cli_demo.py --mode demo

# ä¿æŒçª—å£æ‰“å¼€
Read-Host "æŒ‰ä»»æ„é”®é€€å‡º"
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. Pythonæ€§èƒ½ä¼˜åŒ–

```python
# åˆ›å»ºä¼˜åŒ–é…ç½®æ–‡ä»¶ optimize_config.py
import os
import torch

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['PYTHONHASHSEED'] = '0'
os.environ['PYTHONDONTWRITEBYTECODE'] = '1'

# PyTorchä¼˜åŒ–
torch.set_num_threads(8)  # è®¾ç½®çº¿ç¨‹æ•°
torch.backends.cudnn.benchmark = True  # å¯ç”¨cuDNNåŸºå‡†æµ‹è¯•
torch.backends.cudnn.deterministic = False  # ç¦ç”¨ç¡®å®šæ€§æ¨¡å¼ä»¥æé«˜æ€§èƒ½

# å¦‚æœæœ‰GPUï¼Œè®¾ç½®GPUä¼˜åŒ–
if torch.cuda.is_available():
    torch.cuda.empty_cache()  # æ¸…ç©ºGPUç¼“å­˜
    torch.backends.cuda.matmul.allow_tf32 = True  # å…è®¸TF32è®¡ç®—
    torch.backends.cudnn.allow_tf32 = True

print("æ€§èƒ½ä¼˜åŒ–é…ç½®å®Œæˆ")
```

### 2. å†…å­˜ä¼˜åŒ–

```python
# åˆ›å»ºå†…å­˜ä¼˜åŒ–å·¥å…· memory_optimizer.py
import gc
import torch
import psutil
import threading
import time

class MemoryOptimizer:
    def __init__(self, threshold=80):
        self.threshold = threshold
        self.monitor = True
        self.start_monitoring()
    
    def get_memory_usage(self):
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        memory = psutil.virtual_memory()
        return {
            'total': memory.total / 1024**3,  # GB
            'used': memory.used / 1024**3,   # GB
            'percent': memory.percent,
            'available': memory.available / 1024**3  # GB
        }
    
    def optimize_memory(self):
        """å†…å­˜ä¼˜åŒ–"""
        # Pythonåƒåœ¾å›æ”¶
        gc.collect()
        
        # GPUå†…å­˜æ¸…ç†
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()
    
    def monitor_memory(self):
        """å†…å­˜ç›‘æ§"""
        while self.monitor:
            memory_info = self.get_memory_usage()
            
            if memory_info['percent'] > self.threshold:
                print(f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ ({memory_info['percent']:.1f}%)ï¼Œæ‰§è¡Œä¼˜åŒ–...")
                self.optimize_memory()
            
            time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
    
    def start_monitoring(self):
        """å¯åŠ¨å†…å­˜ç›‘æ§"""
        thread = threading.Thread(target=self.monitor_memory, daemon=True)
        thread.start()
        print("å†…å­˜ç›‘æ§å·²å¯åŠ¨")
    
    def stop_monitoring(self):
        """åœæ­¢å†…å­˜ç›‘æ§"""
        self.monitor = False
        print("å†…å­˜ç›‘æ§å·²åœæ­¢")

# ä½¿ç”¨ç¤ºä¾‹
optimizer = MemoryOptimizer(threshold=85)
```

### 3. GPUæ€§èƒ½ä¼˜åŒ–

```python
# åˆ›å»ºGPUä¼˜åŒ–å·¥å…· gpu_optimizer.py
import torch
import time

class GPUOptimizer:
    def __init__(self):
        if torch.cuda.is_available():
            self.device = torch.device('cuda')
            self.name = torch.cuda.get_device_name(0)
            self.total_memory = torch.cuda.get_device_properties(0).total_memory
            print(f"GPUè®¾å¤‡: {self.name}")
            print(f"æ€»æ˜¾å­˜: {self.total_memory / 1024**3:.1f} GB")
        else:
            self.device = torch.device('cpu')
            self.name = "CPU"
            print("ä½¿ç”¨CPUè¿›è¡Œè®¡ç®—")
    
    def optimize_settings(self):
        """ä¼˜åŒ–GPUè®¾ç½®"""
        if torch.cuda.is_available():
            # å¯ç”¨TF32 (30%æ€§èƒ½æå‡)
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            
            # å¯ç”¨benchmarkæ¨¡å¼
            torch.backends.cudnn.benchmark = True
            
            # è®¾ç½®ä¼˜åŒ–çš„æ•°æ®ç±»å‹
            torch.set_default_dtype(torch.float32)
            
            print("GPUä¼˜åŒ–è®¾ç½®å·²åº”ç”¨")
        else:
            print("æ— å¯ç”¨GPUï¼Œè·³è¿‡ä¼˜åŒ–")
    
    def benchmark_memory_speed(self, size=1000):
        """åŸºå‡†æµ‹è¯•å†…å­˜é€Ÿåº¦"""
        if not torch.cuda.is_available():
            print("æ— å¯ç”¨GPUè¿›è¡Œå†…å­˜åŸºå‡†æµ‹è¯•")
            return
        
        # åˆ†é…æµ‹è¯•
        start_time = time.time()
        test_tensor = torch.randn(size, size, device=self.device)
        allocate_time = time.time() - start_time
        
        # å¤åˆ¶æµ‹è¯•
        start_time = time.time()
        test_tensor_copy = test_tensor.clone()
        copy_time = time.time() - start_time
        
        # è®¡ç®—æµ‹è¯•
        start_time = time.time()
        result = torch.mm(test_tensor, test_tensor)
        compute_time = time.time() - start_time
        
        print(f"GPUå†…å­˜åŸºå‡†æµ‹è¯•ç»“æœ:")
        print(f"  åˆ†é…æ—¶é—´ ({size}x{size}): {allocate_time:.4f}s")
        print(f"  å¤åˆ¶æ—¶é—´: {copy_time:.4f}s")
        print(f"  è®¡ç®—æ—¶é—´: {compute_time:.4f}s")

# ä½¿ç”¨ç¤ºä¾‹
gpu_opt = GPUOptimizer()
gpu_opt.optimize_settings()
gpu_opt.benchmark_memory_speed()
```

### 4. ç³»ç»Ÿçº§ä¼˜åŒ–

#### Windowsæ€§èƒ½è®¾ç½®

```powershell
# åˆ›å»ºä¼˜åŒ–è„šæœ¬ optimize_windows.ps1

# è®¾ç½®é«˜æ€§èƒ½ç”µæºè®¡åˆ’
powercfg /setactive 8c5e7fda-e8bf-4a96-9a85-a6e23a8c635c

# ç¦ç”¨Windowsç´¢å¼•ï¼ˆå¯é€‰ï¼‰
# Set-Service "WSearch" -StartupType Disabled

# è®¾ç½®ç¯å¢ƒå˜é‡
[Environment]::SetEnvironmentVariable("PYTORCH_CUDA_ALLOC_CONF", "max_split_size_mb:512", "Machine")
[Environment]::SetEnvironmentVariable("CUDA_CACHE_MAXSIZE", "2147483648", "Machine")

# å¯ç”¨å¼€å‘è€…æ¨¡å¼
reg add "HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\CurrentVersion\AppModelUnlock" /t REG_DWORD /f /v "AllowDevelopmentWithoutDevLicense" /d 1

Write-Host "Windowsæ€§èƒ½ä¼˜åŒ–å®Œæˆ" -ForegroundColor Green
```

#### ç£ç›˜ä¼˜åŒ–

```bash
# åˆ›å»ºç£ç›˜ä¼˜åŒ–è„šæœ¬ optimize_disk.bat

@echo off
echo æ­£åœ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶...

# æ¸…ç†Pythonç¼“å­˜
for /d /r . %%d in (__pycache__) do @if exist "%%d" rd /s /q "%%d"
del /s /q *.pyc
del /s /q *.pyo

# æ¸…ç†pipç¼“å­˜
python -m pip cache purge

# æ¸…ç†ç³»ç»Ÿä¸´æ—¶æ–‡ä»¶
del /q/f/s %TEMP%\*

echo ç£ç›˜æ¸…ç†å®Œæˆ!
pause
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. Pythonå®‰è£…é—®é¢˜

```bash
# é—®é¢˜: Pythonå‘½ä»¤ä¸å¯ç”¨
# è§£å†³æ–¹æ¡ˆ: 
# 1. æ£€æŸ¥PATHç¯å¢ƒå˜é‡
echo %PATH%
# 2. é‡æ–°å®‰è£…Pythonå¹¶å‹¾é€‰"Add to PATH"
# 3. æ‰‹åŠ¨æ·»åŠ Pythonè·¯å¾„åˆ°PATH
```

#### 2. pipå®‰è£…å¤±è´¥

```bash
# é—®é¢˜: pip installå¤±è´¥
# è§£å†³æ–¹æ¡ˆ:
pip install --upgrade pip setuptools wheel
pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org [package_name]

# æˆ–è€…ä½¿ç”¨å›½å†…é•œåƒ
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple [package_name]
```

#### 3. ä¾èµ–å†²çª

```bash
# é—®é¢˜: ä¾èµ–åŒ…ç‰ˆæœ¬å†²çª
# è§£å†³æ–¹æ¡ˆ:
pip check

# åˆ›å»ºæ–°çš„è™šæ‹Ÿç¯å¢ƒ
python -m venv new_env
new_env\Scripts\activate
pip install -r requirements.txt

# æˆ–è€…ä½¿ç”¨conda
conda create --name new_env python=3.11
conda activate new_env
conda install --file requirements.txt
```

#### 4. GPUä¸å¯ç”¨

```python
# é—®é¢˜: CUDAä¸å¯ç”¨
# è§£å†³æ–¹æ¡ˆæ£€æŸ¥:

# 1. æ£€æŸ¥CUDAå®‰è£…
import torch
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")

# 2. é‡æ–°å®‰è£…CUDAç‰ˆæœ¬PyTorch
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 3. æ£€æŸ¥NVIDIAé©±åŠ¨
# æ‰“å¼€NVIDIAæ§åˆ¶é¢æ¿ â†’ å¸®åŠ© â†’ ç³»ç»Ÿä¿¡æ¯ â†’ ç»„ä»¶ â†’ NVCUDA64.DLL
```

#### 5. Jupyteræ— æ³•å¯åŠ¨

```bash
# é—®é¢˜: Jupyter Labæ— æ³•å¯åŠ¨
# è§£å†³æ–¹æ¡ˆ:

# 1. æ£€æŸ¥ç«¯å£å ç”¨
netstat -ano | findstr :8888

# 2. æ¸…ç†Jupyteré…ç½®
jupyter lab --generate-config
jupyter lab --reset-config

# 3. é‡æ–°å®‰è£…Jupyter
pip uninstall jupyter jupyterlab
pip install jupyter jupyterlab

# 4. ä½¿ç”¨ä¸åŒç«¯å£
jupyter lab --port=9999
```

#### 6. Webç•Œé¢æ— æ³•è®¿é—®

```bash
# é—®é¢˜: Reactå¼€å‘æœåŠ¡å™¨æ— æ³•è®¿é—®
# è§£å†³æ–¹æ¡ˆ:

# 1. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
# Windowsé˜²ç«å¢™å¯èƒ½é˜»æ­¢ç«¯å£5173

# 2. é…ç½®å¼€å‘æœåŠ¡å™¨
cd ui/brain-ai-ui
npm run dev -- --host 0.0.0.0

# 3. æ£€æŸ¥ç«¯å£å ç”¨
netstat -ano | findstr :5173
```

#### 7. å†…å­˜ä¸è¶³é”™è¯¯

```python
# é—®é¢˜: OOM (Out of Memory) é”™è¯¯
# è§£å†³æ–¹æ¡ˆ:

import torch

# å‡å°‘æ‰¹æ¬¡å¤§å°
batch_size = 16  # åŸå…ˆå¯èƒ½æ˜¯64æˆ–128

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
torch.utils.checkpoint.checkpoint_sequential

# ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
from torch.cuda.amp import autocast, GradScaler
scaler = GradScaler()
with autocast():
    output = model(input_data)
    loss = criterion(output, target)

# æ¸…ç†GPUç¼“å­˜
torch.cuda.empty_cache()
```

#### 8. æ¨¡å—å¯¼å…¥é”™è¯¯

```bash
# é—®é¢˜: ModuleNotFoundError
# è§£å†³æ–¹æ¡ˆ:

# 1. æ£€æŸ¥Pythonè·¯å¾„
import sys
print(sys.path)

# 2. ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•
cd brain-inspired-ai

# 3. è®¾ç½®PYTHONPATH
set PYTHONPATH=%PYTHONPATH%;.

# 4. é‡æ–°å®‰è£…åŒ…
pip install -e .
```

### è¯Šæ–­å·¥å…·

åˆ›å»ºè¯Šæ–­è„šæœ¬ `diagnose.py`:

```python
#!/usr/bin/env python3
"""
Windows 11 Brain AI ç¯å¢ƒè¯Šæ–­å·¥å…·
"""
import sys
import subprocess
import platform
import torch
import importlib
import pkg_resources

def check_system_info():
    """æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯"""
    print("=== ç³»ç»Ÿä¿¡æ¯ ===")
    print(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"æ¶æ„: {platform.machine()}")
    print(f"å¤„ç†å™¨: {platform.processor()}")
    print()

def check_python_packages():
    """æ£€æŸ¥PythonåŒ…"""
    print("=== PythonåŒ…æ£€æŸ¥ ===")
    required_packages = [
        'torch', 'torchvision', 'numpy', 'scipy', 'pandas',
        'sklearn', 'matplotlib', 'jupyter', 'click', 'pyyaml'
    ]
    
    for package in required_packages:
        try:
            version = pkg_resources.get_distribution(package).version
            print(f"âœ… {package}: {version}")
        except pkg_resources.DistributionNotFound:
            print(f"âŒ {package}: æœªå®‰è£…")
    print()

def check_pytorch():
    """æ£€æŸ¥PyTorché…ç½®"""
    print("=== PyTorchæ£€æŸ¥ ===")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            print(f"GPU {i}: {props.name}, {props.total_memory/1024**3:.1f}GB")
    else:
        print("âš ï¸  GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPU")
    print()

def check_gpu_drivers():
    """æ£€æŸ¥GPUé©±åŠ¨"""
    print("=== GPUé©±åŠ¨æ£€æŸ¥ ===")
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIAé©±åŠ¨æ­£å¸¸")
            print(result.stdout.split('\n')[0])
        else:
            print("âŒ NVIDIAé©±åŠ¨æ£€æŸ¥å¤±è´¥")
    except FileNotFoundError:
        print("âŒ nvidia-smiå‘½ä»¤ä¸å¯ç”¨")
        print("è¯·å®‰è£…NVIDIAé©±åŠ¨ç¨‹åº")
    print()

def check_ports():
    """æ£€æŸ¥ç«¯å£å ç”¨"""
    print("=== ç«¯å£æ£€æŸ¥ ===")
    ports_to_check = [8888, 5173, 6006]
    
    for port in ports_to_check:
        result = subprocess.run(
            ['netstat', '-ano'], 
            capture_output=True, 
            text=True
        )
        if f':{port}' in result.stdout:
            print(f"âš ï¸  ç«¯å£ {port} è¢«å ç”¨")
        else:
            print(f"âœ… ç«¯å£ {port} å¯ç”¨")
    print()

def run_performance_test():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print("=== æ€§èƒ½æµ‹è¯• ===")
    
    # CPUæµ‹è¯•
    import time
    start = time.time()
    _ = sum(range(1000000))
    cpu_time = time.time() - start
    print(f"CPUè®¡ç®—æµ‹è¯•: {cpu_time:.4f}ç§’")
    
    # PyTorchæµ‹è¯•
    if torch.cuda.is_available():
        device = torch.device('cuda')
        x = torch.randn(1000, 1000, device=device)
        start = time.time()
        _ = torch.mm(x, x)
        gpu_time = time.time() - start
        print(f"GPUè®¡ç®—æµ‹è¯•: {gpu_time:.4f}ç§’")
        print(f"GPUé€Ÿåº¦æå‡: {cpu_time/gpu_time:.1f}x")
    else:
        print("è·³è¿‡GPUæµ‹è¯•ï¼ˆæ— å¯ç”¨GPUï¼‰")
    print()

def main():
    """ä¸»è¯Šæ–­å‡½æ•°"""
    print("ğŸ§  Brain AI Windows 11 ç¯å¢ƒè¯Šæ–­")
    print("=" * 50)
    
    check_system_info()
    check_python_packages()
    check_pytorch()
    check_gpu_drivers()
    check_ports()
    run_performance_test()
    
    print("=" * 50)
    print("è¯Šæ–­å®Œæˆï¼è¯·æ ¹æ®ä¸Šè¿°ä¿¡æ¯è§£å†³é—®é¢˜ã€‚")

if __name__ == "__main__":
    main()
```

```bash
# è¿è¡Œè¯Šæ–­
python diagnose.py
```

## âœ… ç¯å¢ƒéªŒè¯

### 1. å¿«é€ŸéªŒè¯è„šæœ¬

åˆ›å»º `verify_installation.py`:

```python
#!/usr/bin/env python3
"""
å¿«é€ŸéªŒè¯å®‰è£…æ˜¯å¦æˆåŠŸ
"""
import sys
import torch
import numpy as np

def test_basic_imports():
    """æµ‹è¯•åŸºç¡€å¯¼å…¥"""
    print("æµ‹è¯•åŸºç¡€åŒ…å¯¼å…¥...")
    
    try:
        import numpy as np
        import scipy
        import pandas as pd
        import sklearn
        import matplotlib.pyplot as plt
        print("âœ… åŸºç¡€ç§‘å­¦è®¡ç®—åŒ…å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ åŸºç¡€åŒ…å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    return True

def test_pytorch():
    """æµ‹è¯•PyTorch"""
    print("\næµ‹è¯•PyTorch...")
    
    try:
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
        
        # åˆ›å»ºæµ‹è¯•å¼ é‡
        x = torch.randn(100, 100)
        y = torch.randn(100, 100)
        z = torch.mm(x, y)
        print("âœ… PyTorchå¼ é‡è¿ç®—æ­£å¸¸")
        
        # GPUæµ‹è¯•
        if torch.cuda.is_available():
            x_gpu = x.to('cuda')
            y_gpu = y.to('cuda')
            z_gpu = torch.mm(x_gpu, y_gpu)
            print("âœ… GPUè®¡ç®—æ­£å¸¸")
        
        return True
    except Exception as e:
        print(f"âŒ PyTorchæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_brain_ai_modules():
    """æµ‹è¯•Brain AIæ¨¡å—"""
    print("\næµ‹è¯•Brain AIæ¨¡å—...")
    
    try:
        # æµ‹è¯•é¡¹ç›®æ¨¡å—å¯¼å…¥
        import os
        import sys
        
        # æ·»åŠ é¡¹ç›®è·¯å¾„
        project_root = os.path.dirname(os.path.abspath(__file__))
        if project_root not in sys.path:
            sys.path.insert(0, project_root)
        
        print("âœ… è·¯å¾„é…ç½®æ­£å¸¸")
        return True
    except Exception as e:
        print(f"âŒ Brain AIæ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_performance():
    """æµ‹è¯•æ€§èƒ½"""
    print("\næ€§èƒ½æµ‹è¯•...")
    
    try:
        # å†…å­˜æµ‹è¯•
        import psutil
        memory = psutil.virtual_memory()
        print(f"å†…å­˜ä½¿ç”¨ç‡: {memory.percent:.1f}%")
        
        # è®¡ç®—æ€§èƒ½æµ‹è¯•
        start = time.time()
        x = np.random.randn(1000, 1000)
        y = np.random.randn(1000, 1000)
        z = np.dot(x, y)
        numpy_time = time.time() - start
        
        print(f"NumPyçŸ©é˜µä¹˜æ³•: {numpy_time:.4f}ç§’")
        print("âœ… æ€§èƒ½æµ‹è¯•æ­£å¸¸")
        return True
    except Exception as e:
        print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»éªŒè¯å‡½æ•°"""
    print("ğŸ§  Brain AI å®‰è£…éªŒè¯")
    print("=" * 40)
    
    tests = [
        test_basic_imports,
        test_pytorch,
        test_brain_ai_modules,
        test_performance
    ]
    
    passed = 0
    for test in tests:
        if test():
            passed += 1
    
    print("\n" + "=" * 40)
    print(f"éªŒè¯ç»“æœ: {passed}/{len(tests)} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed == len(tests):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å®‰è£…æˆåŠŸï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…")

if __name__ == "__main__":
    import time
    main()
```

### 2. å®Œæ•´éªŒè¯æµç¨‹

```bash
# æŒ‰é¡ºåºè¿è¡ŒéªŒè¯
python verify_installation.py
python diagnose.py

# å¦‚æœæ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Œè¿è¡Œæ¼”ç¤º
python cli_demo.py --mode demo

# æµ‹è¯•Webç•Œé¢
cd ui/brain-ai-ui
pnpm install
pnpm dev

# æµ‹è¯•Jupyter
jupyter lab
```

## ğŸ¯ æ€»ç»“

æ­å–œï¼æ‚¨å·²ç»å®Œæˆäº†Windows 11ç¯å¢ƒä¸‹Brain AIç³»ç»Ÿçš„å®Œæ•´å®‰è£…é…ç½®ã€‚é€šè¿‡æœ¬æŒ‡å—ï¼Œæ‚¨åº”è¯¥å·²ç»ï¼š

1. âœ… å®‰è£…å¹¶é…ç½®äº†Pythonç¯å¢ƒ
2. âœ… å®‰è£…äº†æ‰€æœ‰å¿…è¦çš„ä¾èµ–åŒ…
3. âœ… é…ç½®äº†GPUæ”¯æŒï¼ˆå¦‚æœå¯ç”¨ï¼‰
4. âœ… è®¾ç½®äº†Webç•Œé¢å’ŒJupyterç¯å¢ƒ
5. âœ… ä¼˜åŒ–äº†ç³»ç»Ÿæ€§èƒ½
6. âœ… éªŒè¯äº†å®‰è£…çš„æ­£ç¡®æ€§

### ä¸‹ä¸€æ­¥æ“ä½œ

1. **å¼€å§‹ä½“éªŒ**: è¿è¡Œ `python cli_demo.py --mode demo`
2. **æ¢ç´¢åŠŸèƒ½**: æŸ¥çœ‹å„ç§æ¼”ç¤ºè„šæœ¬
3. **æ·±å…¥å¼€å‘**: ä½¿ç”¨Jupyter Labè¿›è¡Œäº¤äº’å¼å¼€å‘
4. **æ€§èƒ½è°ƒä¼˜**: æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µè°ƒæ•´é…ç½®

### è·å–å¸®åŠ©

å¦‚æœåœ¨å®‰è£…è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼š

1. æŸ¥çœ‹æ•…éšœæ’é™¤éƒ¨åˆ†
2. è¿è¡Œè¯Šæ–­è„šæœ¬
3. æ£€æŸ¥é”™è¯¯æ—¥å¿—
4. å‚è€ƒå®˜æ–¹æ–‡æ¡£

**ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼** ğŸ‰

---

*æœ¬æŒ‡å—é’ˆå¯¹Windows 11ä¼˜åŒ–ï¼Œå¦‚ä½¿ç”¨å…¶ä»–æ“ä½œç³»ç»Ÿï¼Œè¯·å‚è€ƒç›¸åº”çš„å®‰è£…æ–‡æ¡£ã€‚*