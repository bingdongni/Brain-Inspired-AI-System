#!/usr/bin/env python3
"""
å¿«é€Ÿç³»ç»Ÿæµ‹è¯•éªŒè¯ - ä¼˜åŒ–ç‰ˆæœ¬
Quick System Testing and Validation - Optimized Version

åŒ…å«å…³é”®æµ‹è¯•é¡¹ç›®ï¼Œè¿è¡Œæ—¶é—´æŽ§åˆ¶åœ¨åˆç†èŒƒå›´å†…
"""

import os
import sys
import json
import time
import psutil
import platform
import numpy as np
from pathlib import Path
from datetime import datetime
import warnings

# å…¼å®¹æ€§æ£€æŸ¥
TORCH_AVAILABLE = False
CUDA_AVAILABLE = False
SKLEARN_AVAILABLE = False

try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    TORCH_AVAILABLE = True
    CUDA_AVAILABLE = torch.cuda.is_available()
except ImportError:
    print("âš ï¸ è­¦å‘Š: PyTorchæœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–æµ‹è¯•")

try:
    from sklearn.datasets import make_classification
    SKLEARN_AVAILABLE = True
except ImportError:
    print("âš ï¸ è­¦å‘Š: scikit-learnæœªå®‰è£…")


class QuickTestModel:
    """å¿«é€Ÿæµ‹è¯•ç”¨çš„ç®€åŒ–æ¨¡åž‹"""
    
    def __init__(self, input_dim, hidden_dim, output_dim, use_attention=False):
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.use_attention = use_attention
        
        if TORCH_AVAILABLE:
            self.model = self._create_pytorch_model(input_dim, hidden_dim, output_dim, use_attention)
        else:
            self.model = self._create_numpy_model(input_dim, hidden_dim, output_dim)
    
    def _create_pytorch_model(self, input_dim, hidden_dim, output_dim, use_attention):
        """åˆ›å»ºç®€åŒ–PyTorchæ¨¡åž‹"""
        class QuickModel(nn.Module):
            def __init__(self, input_dim, hidden_dim, output_dim, use_attention):
                super().__init__()
                self.use_attention = use_attention
                
                self.encoder = nn.Sequential(
                    nn.Linear(input_dim, hidden_dim),
                    nn.ReLU(),
                    nn.Dropout(0.1),
                    nn.Linear(hidden_dim, hidden_dim),
                    nn.ReLU()
                )
                
                if use_attention:
                    self.attention = nn.MultiheadAttention(hidden_dim, num_heads=4, batch_first=True)
                
                self.classifier = nn.Linear(hidden_dim, output_dim)
            
            def forward(self, x):
                x = self.encoder(x)
                
                if self.use_attention:
                    x = x.unsqueeze(1)
                    attended_x, _ = self.attention(x, x, x)
                    x = attended_x.squeeze(1)
                
                return self.classifier(x)
        
        device = 'cuda' if CUDA_AVAILABLE else 'cpu'
        return QuickModel(input_dim, hidden_dim, output_dim, use_attention).to(device)
    
    def _create_numpy_model(self, input_dim, hidden_dim, output_dim):
        """åˆ›å»ºNumPyæ¨¡åž‹"""
        class NumpyModel:
            def __init__(self, input_dim, hidden_dim, output_dim):
                self.W1 = np.random.randn(input_dim, hidden_dim) * 0.1
                self.b1 = np.zeros(hidden_dim)
                self.W2 = np.random.randn(hidden_dim, output_dim) * 0.1
                self.b2 = np.zeros(output_dim)
            
            def forward(self, x):
                x = np.maximum(0, np.dot(x, self.W1) + self.b1)
                return np.dot(x, self.W2) + self.b2
            
            def train(self, X, y, epochs=5):
                # ç®€åŒ–è®­ç»ƒ
                for _ in range(epochs):
                    pass
        
        return NumpyModel(input_dim, hidden_dim, output_dim)
    
    def train(self, X, y, epochs=5, batch_size=32, lr=0.001):
        """è®­ç»ƒæ¨¡åž‹"""
        if TORCH_AVAILABLE and isinstance(self.model, nn.Module):
            return self._train_pytorch(X, y, epochs, batch_size, lr)
        else:
            self.model.train(X, y, epochs)
            return [0.0] * epochs
    
    def _train_pytorch(self, X, y, epochs, batch_size, lr):
        """PyTorchè®­ç»ƒ"""
        device = next(self.model.parameters()).device
        X_tensor = torch.FloatTensor(X).to(device)
        y_tensor = torch.LongTensor(y).to(device)
        
        dataset = TensorDataset(X_tensor, y_tensor)
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
        
        optimizer = optim.Adam(self.model.parameters(), lr=lr)
        criterion = nn.CrossEntropyLoss()
        
        self.model.train()
        losses = []
        
        for epoch in range(epochs):
            epoch_loss = 0
            num_batches = 0
            for batch_X, batch_y in dataloader:
                optimizer.zero_grad()
                outputs = self.model(batch_X)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
                epoch_loss += loss.item()
                num_batches += 1
            
            losses.append(epoch_loss / num_batches if num_batches > 0 else 0)
        
        return losses
    
    def predict(self, X):
        """é¢„æµ‹"""
        if TORCH_AVAILABLE and isinstance(self.model, nn.Module):
            device = next(self.model.parameters()).device
            self.model.eval()
            with torch.no_grad():
                X_tensor = torch.FloatTensor(X).to(device)
                outputs = self.model(X_tensor)
                _, predicted = torch.max(outputs, 1)
                return predicted.cpu().numpy()
        else:
            outputs = self.model.forward(X)
            return np.argmax(outputs, axis=1)


def create_test_data(n_samples=500, n_features=32, n_classes=5, noise=0.1):
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    np.random.seed(42)
    X, y = make_classification(
        n_samples=n_samples,
        n_features=n_features,
        n_informative=n_features // 2,
        n_redundant=n_features // 4,
        n_classes=n_classes,
        n_clusters_per_class=1,
        flip_y=noise,
        random_state=42
    )
    return X.astype(np.float32), y.astype(np.int32)


def run_quick_benchmark():
    """å¿«é€ŸåŸºå‡†æµ‹è¯•"""
    print("ðŸš€ å¿«é€ŸåŸºå‡†æµ‹è¯•")
    print("=" * 50)
    
    test_results = {}
    
    # 1. è®­ç»ƒé€Ÿåº¦æµ‹è¯•
    print("\nðŸ“Š è®­ç»ƒé€Ÿåº¦æµ‹è¯•")
    try:
        X, y = create_test_data(1000)
        model = QuickTestModel(X.shape[1], 64, len(np.unique(y)), use_attention=True)
        
        start_time = time.time()
        model.train(X, y, epochs=3, batch_size=32)
        training_time = time.time() - start_time
        
        test_results['training_speed'] = {
            'training_time': training_time,
            'throughput': len(X) / training_time,
            'success': True
        }
        print(f"   è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")
        print(f"   åžåé‡: {len(X) / training_time:.1f} æ ·æœ¬/ç§’")
        
    except Exception as e:
        test_results['training_speed'] = {
            'error': str(e),
            'success': False
        }
        print(f"   âŒ è®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")
    
    # 2. æŽ¨ç†é€Ÿåº¦æµ‹è¯•
    print("\nâš¡ æŽ¨ç†é€Ÿåº¦æµ‹è¯•")
    try:
        X_test, _ = create_test_data(200)
        model = QuickTestModel(X_test.shape[1], 64, 5, use_attention=True)
        
        # é¢„çƒ­
        for _ in range(5):
            _ = model.predict(X_test[:10])
        
        # æŽ¨ç†æµ‹è¯•
        inference_times = []
        for _ in range(20):
            start_time = time.time()
            predictions = model.predict(X_test[:50])
            inference_times.append(time.time() - start_time)
        
        avg_inference_time = np.mean(inference_times)
        throughput = 50 / avg_inference_time
        
        test_results['inference_speed'] = {
            'avg_inference_time': avg_inference_time,
            'throughput': throughput,
            'success': True
        }
        print(f"   å¹³å‡æŽ¨ç†æ—¶é—´: {avg_inference_time*1000:.2f}ms")
        print(f"   åžåé‡: {throughput:.1f} æ ·æœ¬/ç§’")
        
    except Exception as e:
        test_results['inference_speed'] = {
            'error': str(e),
            'success': False
        }
        print(f"   âŒ æŽ¨ç†æµ‹è¯•å¤±è´¥: {e}")
    
    # 3. å†…å­˜ä½¿ç”¨æµ‹è¯•
    print("\nðŸ’¾ å†…å­˜ä½¿ç”¨æµ‹è¯•")
    try:
        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        X, y = create_test_data(2000)
        X_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        model = QuickTestModel(X.shape[1], 64, 5, use_attention=True)
        model_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        model.train(X, y, epochs=2)
        peak_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        test_results['memory_usage'] = {
            'data_memory': X_memory - initial_memory,
            'model_memory': model_memory - X_memory,
            'peak_memory': peak_memory - initial_memory,
            'success': True
        }
        print(f"   æ•°æ®å†…å­˜: {X_memory - initial_memory:.1f} MB")
        print(f"   æ¨¡åž‹å†…å­˜: {model_memory - X_memory:.1f} MB")
        print(f"   å³°å€¼å†…å­˜: {peak_memory - initial_memory:.1f} MB")
        
    except Exception as e:
        test_results['memory_usage'] = {
            'error': str(e),
            'success': False
        }
        print(f"   âŒ å†…å­˜æµ‹è¯•å¤±è´¥: {e}")
    
    return test_results


def run_continual_learning_test():
    """æŒç»­å­¦ä¹ æµ‹è¯•"""
    print("\nðŸ§  æŒç»­å­¦ä¹ æµ‹è¯•")
    print("=" * 50)
    
    test_results = {}
    
    # 1. ç¾éš¾æ€§é—å¿˜æµ‹è¯•
    print("\nðŸ“š ç¾éš¾æ€§é—å¿˜æµ‹è¯•")
    try:
        # ä»»åŠ¡1
        task1_X, task1_y = create_test_data(500, 32, 3, 0.05)
        model = QuickTestModel(32, 64, 3, use_attention=True)
        model.train(task1_X, task1_y, epochs=5)
        
        task1_acc_before = np.mean(model.predict(task1_X) == task1_y)
        
        # ä»»åŠ¡2
        task2_X, task2_y = create_test_data(500, 32, 3, 0.05)
        model.train(task2_X, task2_y, epochs=5)
        
        task1_acc_after = np.mean(model.predict(task1_X) == task1_y)
        task2_acc = np.mean(model.predict(task2_X) == task2_y)
        forgetting_rate = task1_acc_before - task1_acc_after
        
        test_results['catastrophic_forgetting'] = {
            'task1_accuracy_before': task1_acc_before,
            'task1_accuracy_after': task1_acc_after,
            'task2_accuracy': task2_acc,
            'forgetting_rate': forgetting_rate,
            'success': True
        }
        
        print(f"   ä»»åŠ¡1åˆå§‹å‡†ç¡®çŽ‡: {task1_acc_before:.4f}")
        print(f"   ä»»åŠ¡1ä¿æŒå‡†ç¡®çŽ‡: {task1_acc_after:.4f}")
        print(f"   ä»»åŠ¡2å‡†ç¡®çŽ‡: {task2_acc:.4f}")
        print(f"   é—å¿˜çŽ‡: {forgetting_rate:.4f}")
        
    except Exception as e:
        test_results['catastrophic_forgetting'] = {
            'error': str(e),
            'success': False
        }
        print(f"   âŒ ç¾éš¾æ€§é—å¿˜æµ‹è¯•å¤±è´¥: {e}")
    
    # 2. çŸ¥è¯†è¿ç§»æµ‹è¯•
    print("\nðŸŽ¯ çŸ¥è¯†è¿ç§»æµ‹è¯•")
    try:
        # æºä»»åŠ¡
        source_X, source_y = create_test_data(800, 32, 5, 0.05)
        pretrained_model = QuickTestModel(32, 64, 5, use_attention=True)
        pretrained_model.train(source_X, source_y, epochs=8)
        source_accuracy = np.mean(pretrained_model.predict(source_X) == source_y)
        
        # ç›®æ ‡ä»»åŠ¡
        target_X, target_y = create_test_data(600, 32, 5, 0.05)
        
        # è¿ç§»å­¦ä¹ 
        transfer_model = QuickTestModel(32, 64, 5, use_attention=True)
        transfer_model.train(target_X, target_y, epochs=3)
        transfer_accuracy = np.mean(transfer_model.predict(target_X) == target_y)
        
        # ä»Žå¤´è®­ç»ƒ
        scratch_model = QuickTestModel(32, 64, 5, use_attention=True)
        scratch_model.train(target_X, target_y, epochs=3)
        scratch_accuracy = np.mean(scratch_model.predict(target_X) == target_y)
        
        transfer_advantage = transfer_accuracy - scratch_accuracy
        
        test_results['knowledge_transfer'] = {
            'source_accuracy': source_accuracy,
            'transfer_accuracy': transfer_accuracy,
            'scratch_accuracy': scratch_accuracy,
            'transfer_advantage': transfer_advantage,
            'success': True
        }
        
        print(f"   æºä»»åŠ¡å‡†ç¡®çŽ‡: {source_accuracy:.4f}")
        print(f"   è¿ç§»å­¦ä¹ å‡†ç¡®çŽ‡: {transfer_accuracy:.4f}")
        print(f"   ä»Žå¤´è®­ç»ƒå‡†ç¡®çŽ‡: {scratch_accuracy:.4f}")
        print(f"   è¿ç§»ä¼˜åŠ¿: {transfer_advantage:.4f}")
        
    except Exception as e:
        test_results['knowledge_transfer'] = {
            'error': str(e),
            'success': False
        }
        print(f"   âŒ çŸ¥è¯†è¿ç§»æµ‹è¯•å¤±è´¥: {e}")
    
    return test_results


def run_compatibility_test():
    """å…¼å®¹æ€§æµ‹è¯•"""
    print("\nðŸ–¥ï¸ å…¼å®¹æ€§æµ‹è¯•")
    print("=" * 50)
    
    test_results = {}
    
    # ç³»ç»Ÿä¿¡æ¯
    system_info = {
        'platform': platform.system(),
        'python_version': platform.python_version(),
        'cpu_count': psutil.cpu_count(),
        'memory_total': psutil.virtual_memory().total,
        'torch_available': TORCH_AVAILABLE,
        'cuda_available': CUDA_AVAILABLE,
        'sklearn_available': SKLEARN_AVAILABLE
    }
    
    # ä¾èµ–æµ‹è¯•
    dependency_tests = {}
    
    # æµ‹è¯•åŸºç¡€åŠŸèƒ½
    print("ðŸ”§ åŸºç¡€åŠŸèƒ½æµ‹è¯•")
    try:
        # åŸºç¡€æ•°å­¦è¿ç®—
        x = np.array([1, 2, 3, 4, 5])
        result = np.sum(x)
        basic_math = (result == 15)
        
        # æ–‡ä»¶æ“ä½œ
        import tempfile
        import os
        with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:
            f.write("test")
            temp_file = f.name
        
        with open(temp_file, 'r') as f:
            content = f.read()
        
        os.remove(temp_file)
        file_operations = (content == "test")
        
        dependency_tests['basic_math'] = {'success': basic_math, 'result': result}
        dependency_tests['file_operations'] = {'success': file_operations, 'result': 'normal'}
        
        print(f"   åŸºç¡€æ•°å­¦: {'âœ…' if basic_math else 'âŒ'}")
        print(f"   æ–‡ä»¶æ“ä½œ: {'âœ…' if file_operations else 'âŒ'}")
        
    except Exception as e:
        dependency_tests['basic_functions'] = {'success': False, 'error': str(e)}
    
    # æµ‹è¯•NumPy
    print("ðŸ”¢ NumPyåŠŸèƒ½æµ‹è¯•")
    try:
        import numpy as np
        x = np.array([1, 2, 3])
        result = np.dot(x, x)
        numpy_test = (result == 14)
        
        dependency_tests['numpy'] = {
            'success': numpy_test,
            'version': np.__version__,
            'result': result
        }
        
        print(f"   NumPy: {'âœ…' if numpy_test else 'âŒ'} v{np.__version__}")
        
    except Exception as e:
        dependency_tests['numpy'] = {'success': False, 'error': str(e)}
        print(f"   NumPy: âŒ {e}")
    
    # æµ‹è¯•PyTorch
    print("ðŸ”¥ PyTorchåŠŸèƒ½æµ‹è¯•")
    if TORCH_AVAILABLE:
        try:
            import torch
            x = torch.tensor([1.0, 2.0, 3.0])
            result = torch.sum(x).item()
            torch_test = (result == 6.0)
            
            dependency_tests['torch'] = {
                'success': torch_test,
                'version': torch.__version__,
                'cuda_available': CUDA_AVAILABLE,
                'result': result
            }
            
            print(f"   PyTorch: {'âœ…' if torch_test else 'âŒ'} v{torch.__version__}")
            print(f"   CUDA: {'å¯ç”¨' if CUDA_AVAILABLE else 'ä¸å¯ç”¨'}")
            
        except Exception as e:
            dependency_tests['torch'] = {'success': False, 'error': str(e)}
            print(f"   PyTorch: âŒ {e}")
    else:
        dependency_tests['torch'] = {'success': False, 'error': 'PyTorchæœªå®‰è£…'}
        print(f"   PyTorch: âŒ æœªå®‰è£…")
    
    # æµ‹è¯•sklearn
    print("ðŸ“Š Scikit-learnåŠŸèƒ½æµ‹è¯•")
    if SKLEARN_AVAILABLE:
        try:
            from sklearn.datasets import make_classification
            X, y = make_classification(n_samples=100, n_features=10, n_classes=2, random_state=42)
            sklearn_test = len(X) == 100 and len(y) == 100
            
            dependency_tests['sklearn'] = {
                'success': sklearn_test,
                'version': 'Available',
                'data_shape': X.shape
            }
            
            print(f"   Scikit-learn: {'âœ…' if sklearn_test else 'âŒ'}")
            
        except Exception as e:
            dependency_tests['sklearn'] = {'success': False, 'error': str(e)}
            print(f"   Scikit-learn: âŒ {e}")
    else:
        dependency_tests['sklearn'] = {'success': False, 'error': 'scikit-learnæœªå®‰è£…'}
        print(f"   Scikit-learn: âŒ æœªå®‰è£…")
    
    test_results['system_info'] = system_info
    test_results['dependency_tests'] = dependency_tests
    
    return test_results


def run_performance_optimization_test():
    """æ€§èƒ½ä¼˜åŒ–æµ‹è¯•"""
    print("\nâš¡ æ€§èƒ½ä¼˜åŒ–æµ‹è¯•")
    print("=" * 50)
    
    test_results = {}
    
    # 1. æ‰¹å¤„ç†å¤§å°ä¼˜åŒ–æµ‹è¯•
    print("ðŸ“¦ æ‰¹å¤„ç†å¤§å°ä¼˜åŒ–æµ‹è¯•")
    try:
        X, y = create_test_data(1000, 32, 5, 0.05)
        batch_sizes = [16, 32, 64]
        
        batch_results = {}
        for batch_size in batch_sizes:
            start_time = time.time()
            
            model = QuickTestModel(32, 64, 5, use_attention=True)
            model.train(X, y, epochs=3, batch_size=batch_size)
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            batch_results[f'batch_{batch_size}'] = {
                'processing_time': processing_time,
                'throughput': len(X) / processing_time,
                'success': True
            }
            
            print(f"   æ‰¹é‡å¤§å° {batch_size}: {processing_time:.2f}ç§’, {len(X) / processing_time:.1f} æ ·æœ¬/ç§’")
        
        test_results['batch_optimization'] = batch_results
        
    except Exception as e:
        test_results['batch_optimization'] = {'error': str(e), 'success': False}
        print(f"   âŒ æ‰¹å¤„ç†ä¼˜åŒ–æµ‹è¯•å¤±è´¥: {e}")
    
    # 2. æ¨¡åž‹å¤æ‚åº¦æµ‹è¯•
    print("ðŸ—ï¸ æ¨¡åž‹å¤æ‚åº¦æµ‹è¯•")
    try:
        X, y = create_test_data(800, 32, 5, 0.05)
        
        configs = [
            {'hidden_dim': 32, 'use_attention': False},
            {'hidden_dim': 64, 'use_attention': False},
            {'hidden_dim': 64, 'use_attention': True},
        ]
        
        config_results = {}
        for i, config in enumerate(configs):
            config_name = f"config_{i+1}"
            
            start_time = time.time()
            start_memory = psutil.Process().memory_info().rss / 1024 / 1024
            
            model = QuickTestModel(32, config['hidden_dim'], 5, use_attention=config['use_attention'])
            model.train(X, y, epochs=3)
            
            # æŽ¨ç†æµ‹è¯•
            predictions = model.predict(X[:100])
            accuracy = np.mean(predictions == y[:100])
            
            end_time = time.time()
            end_memory = psutil.Process().memory_info().rss / 1024 / 1024
            
            config_results[config_name] = {
                'config': config,
                'training_time': end_time - start_time,
                'memory_used': end_memory - start_memory,
                'accuracy': accuracy,
                'success': True
            }
            
            print(f"   é…ç½® {i+1} (éšè—å±‚: {config['hidden_dim']}, æ³¨æ„åŠ›: {config['use_attention']}):")
            print(f"     è®­ç»ƒæ—¶é—´: {end_time - start_time:.2f}ç§’")
            print(f"     å†…å­˜ä½¿ç”¨: {end_memory - start_memory:.1f} MB")
            print(f"     å‡†ç¡®çŽ‡: {accuracy:.4f}")
        
        test_results['model_complexity'] = config_results
        
    except Exception as e:
        test_results['model_complexity'] = {'error': str(e), 'success': False}
        print(f"   âŒ æ¨¡åž‹å¤æ‚åº¦æµ‹è¯•å¤±è´¥: {e}")
    
    return test_results


def main():
    """ä¸»å‡½æ•°"""
    print("ðŸ§  è„‘å¯å‘AIç³»ç»Ÿ - å¿«é€Ÿæµ‹è¯•éªŒè¯å¥—ä»¶")
    print("=" * 70)
    print("æ—¶é—´:", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    
    start_total_time = time.time()
    
    # åˆå§‹åŒ–ç»“æžœ
    all_results = {
        'timestamp': datetime.now().isoformat(),
        'total_tests': 0,
        'successful_tests': 0,
        'test_suites': {}
    }
    
    # è®°å½•æˆåŠŸæµ‹è¯•æ•°
    def record_test_result(test_name, result):
        all_results['total_tests'] += 1
        if result.get('success', False):
            all_results['successful_tests'] += 1
        else:
            print(f"   âŒ {test_name} å¤±è´¥")
    
    # 1. è¿è¡ŒåŸºå‡†æµ‹è¯•
    print("\n" + "="*70)
    print("ðŸ“Š åŸºå‡†æµ‹è¯•å¥—ä»¶")
    print("="*70)
    
    try:
        benchmark_results = run_quick_benchmark()
        all_results['test_suites']['benchmark'] = benchmark_results
        
        for test_name, result in benchmark_results.items():
            record_test_result(test_name, result)
            
    except Exception as e:
        print(f"âŒ åŸºå‡†æµ‹è¯•å¥—ä»¶å¤±è´¥: {e}")
    
    # 2. è¿è¡ŒæŒç»­å­¦ä¹ æµ‹è¯•
    print("\n" + "="*70)
    print("ðŸ§  æŒç»­å­¦ä¹ æµ‹è¯•å¥—ä»¶")
    print("="*70)
    
    try:
        continual_results = run_continual_learning_test()
        all_results['test_suites']['continual_learning'] = continual_results
        
        for test_name, result in continual_results.items():
            record_test_result(test_name, result)
            
    except Exception as e:
        print(f"âŒ æŒç»­å­¦ä¹ æµ‹è¯•å¥—ä»¶å¤±è´¥: {e}")
    
    # 3. è¿è¡Œå…¼å®¹æ€§æµ‹è¯•
    print("\n" + "="*70)
    print("ðŸ–¥ï¸ å…¼å®¹æ€§æµ‹è¯•å¥—ä»¶")
    print("="*70)
    
    try:
        compatibility_results = run_compatibility_test()
        all_results['test_suites']['compatibility'] = compatibility_results
        
        # å…¼å®¹æ€§æµ‹è¯•åŒ…å«å¤šä¸ªå­æµ‹è¯•
        if 'dependency_tests' in compatibility_results:
            for test_name, result in compatibility_results['dependency_tests'].items():
                if isinstance(result, dict):
                    record_test_result(f"å…¼å®¹æ€§-{test_name}", result)
        else:
            record_test_result("compatibility", {'success': False, 'error': 'æ— æ³•è¿è¡Œ'})
            
    except Exception as e:
        print(f"âŒ å…¼å®¹æ€§æµ‹è¯•å¥—ä»¶å¤±è´¥: {e}")
    
    # 4. è¿è¡Œæ€§èƒ½ä¼˜åŒ–æµ‹è¯•
    print("\n" + "="*70)
    print("âš¡ æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å¥—ä»¶")
    print("="*70)
    
    try:
        performance_results = run_performance_optimization_test()
        all_results['test_suites']['performance'] = performance_results
        
        for test_name, result in performance_results.items():
            if isinstance(result, dict):
                record_test_result(test_name, result)
            
    except Exception as e:
        print(f"âŒ æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å¥—ä»¶å¤±è´¥: {e}")
    
    # è®¡ç®—æ€»æ—¶é—´
    total_time = time.time() - start_total_time
    
    # ç”Ÿæˆæ€»ç»“
    success_rate = (all_results['successful_tests'] / all_results['total_tests'] * 100) if all_results['total_tests'] > 0 else 0
    
    summary = {
        'total_tests': all_results['total_tests'],
        'successful_tests': all_results['successful_tests'],
        'success_rate': success_rate,
        'total_time': total_time,
        'timestamp': datetime.now().isoformat()
    }
    
    all_results['summary'] = summary
    
    # ä¿å­˜ç»“æžœ
    os.makedirs('data/results', exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f'data/results/quick_test_results_{timestamp}.json'
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    # æ‰“å°æœ€ç»ˆæ€»ç»“
    print("\n" + "="*70)
    print("ðŸŽ‰ å¿«é€Ÿæµ‹è¯•éªŒè¯å®Œæˆ!")
    print("="*70)
    print(f"ðŸ“Š æ€»æµ‹è¯•æ•°: {all_results['total_tests']}")
    print(f"âœ… æˆåŠŸæµ‹è¯•æ•°: {all_results['successful_tests']}")
    print(f"ðŸ“ˆ æˆåŠŸçŽ‡: {success_rate:.1f}%")
    print(f"â±ï¸ æ€»è¿è¡Œæ—¶é—´: {total_time:.1f}ç§’")
    print(f"ðŸ’¾ ç»“æžœå·²ä¿å­˜åˆ°: {output_file}")
    
    # ç³»ç»Ÿè¯„çº§
    if success_rate >= 90:
        grade = "ä¼˜ç§€ â­â­â­â­â­"
    elif success_rate >= 80:
        grade = "è‰¯å¥½ â­â­â­â­"
    elif success_rate >= 70:
        grade = "ä¸­ç­‰ â­â­â­"
    elif success_rate >= 60:
        grade = "åˆæ ¼ â­â­"
    else:
        grade = "éœ€è¦æ”¹è¿› â­"
    
    print(f"ðŸŽ¯ ç³»ç»Ÿè´¨é‡è¯„çº§: {grade}")
    
    # å»ºè®®
    if success_rate >= 80:
        print("âœ… ç³»ç»Ÿå¯ä»¥ç”¨äºŽç”Ÿäº§çŽ¯å¢ƒéƒ¨ç½²")
    elif success_rate >= 60:
        print("âš ï¸ ç³»ç»Ÿé€‚åˆå¼€å‘æµ‹è¯•ï¼Œå»ºè®®ä¼˜åŒ–åŽéƒ¨ç½²")
    else:
        print("âŒ ç³»ç»Ÿéœ€è¦é‡å¤§æ”¹è¿›æ‰èƒ½ä½¿ç”¨")
    
    return success_rate


if __name__ == "__main__":
    success_rate = main()
    sys.exit(0 if success_rate >= 70 else 1)