#!/usr/bin/env python3
"""
æµ·é©¬ä½“æ¨¡æ‹Ÿå™¨ç®€åŒ–æ¼”ç¤º
å¿«é€ŸéªŒè¯æ ¸å¿ƒåŠŸèƒ½
"""

import torch
import numpy as np
import time
from hippocampus import create_hippocampus_simulator

def quick_demo():
    print("ğŸ§  æµ·é©¬ä½“æ¨¡æ‹Ÿå™¨å¿«é€ŸéªŒè¯")
    print("=" * 50)
    
    # åˆ›å»ºç®€åŒ–çš„æ¨¡æ‹Ÿå™¨
    simulator = create_hippocampus_simulator(
        input_dim=128,
        hidden_dim=64,
        vocab_size=1000
    )
    
    print(f"âœ“ ç³»ç»Ÿåˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {sum(p.numel() for p in simulator.parameters()):,}")
    
    # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
    test_input = torch.randn(2, 10, 128)
    
    # æµ‹è¯•è®°å¿†ç¼–ç 
    output, stats = simulator.forward(
        input_ids=test_input,
        mode='encoding',
        return_stats=True
    )
    
    print(f"âœ“ è®°å¿†ç¼–ç å®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"âœ“ å“åº”æ—¶é—´: {stats['response_time']:.4f}s")
    
    # æµ‹è¯•è®°å¿†æ£€ç´¢
    retrieval_output, retrieval_stats = simulator.forward(
        input_ids=test_input,
        mode='retrieval',
        memory_query=test_input.mean(dim=1),
        return_stats=True
    )
    
    print(f"âœ“ è®°å¿†æ£€ç´¢å®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {retrieval_output.shape}")
    print(f"âœ“ æ£€ç´¢æ—¶é—´: {retrieval_stats['response_time']:.4f}s")
    
    # æµ‹è¯•æ¨¡å¼åˆ†ç¦»
    sep_metrics = simulator.pattern_separator.compute_separation_metrics(
        test_input[0], test_input[1]
    )
    print(f"âœ“ æ¨¡å¼åˆ†ç¦»æµ‹è¯•: åˆ†ç¦»ç¨‹åº¦ {sep_metrics['separation_degree']:.4f}")
    
    # è·å–ç³»ç»Ÿç»Ÿè®¡
    system_stats = simulator.get_system_statistics()
    print(f"âœ“ ç³»ç»Ÿç»Ÿè®¡:")
    print(f"  - æ€»æ“ä½œæ•°: {system_stats['performance_monitor']['total_operations']}")
    print(f"  - æ¨¡å‹å¤§å°: {system_stats['system_info']['model_size_mb']:.2f} MB")
    
    print("\nğŸ‰ æµ·é©¬ä½“æ¨¡æ‹Ÿå™¨æ ¸å¿ƒåŠŸèƒ½éªŒè¯å®Œæˆï¼")
    print("åŸºäºScience 2025å¹´ç ”ç©¶æˆæœçš„ç”Ÿç‰©å¯å‘å¼è®°å¿†ç³»ç»Ÿè¿è¡Œæ­£å¸¸")

if __name__ == "__main__":
    quick_demo()