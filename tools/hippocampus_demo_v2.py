#!/usr/bin/env python3
"""
æµ·é©¬ä½“æ¨¡æ‹Ÿå™¨æ¼”ç¤ºç¨‹åº
å±•ç¤ºåŸºäºç¥ç»ç§‘å­¦åŸç†çš„ç”Ÿç‰©å¯å‘å¼è®°å¿†ç³»ç»ŸåŠŸèƒ½
"""

import torch
import torch.nn.functional as F
import numpy as np
import time
import json
from typing import Dict, Any, List

# å¯¼å…¥æµ·é©¬ä½“æ¨¡æ‹Ÿå™¨
from hippocampus import create_hippocampus_simulator, get_default_config


def print_banner():
    """æ‰“å°æ¼”ç¤ºæ¨ªå¹…"""
    print("=" * 80)
    print("ğŸ§  æµ·é©¬ä½“æ¨¡æ‹Ÿå™¨æ¼”ç¤ºç¨‹åº v2.0.0")
    print("åŸºäºScienceæœŸåˆŠ2025å¹´ç ”ç©¶æˆæœçš„ç”Ÿç‰©å¯å‘å¼è®°å¿†ç³»ç»Ÿ")
    print("=" * 80)
    print()


def demonstrate_system_initialization():
    """æ¼”ç¤ºç³»ç»Ÿåˆå§‹åŒ–"""
    print("ğŸ”§ ç³»ç»Ÿåˆå§‹åŒ–æ¼”ç¤º")
    print("-" * 40)
    
    # ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºæ¨¡æ‹Ÿå™¨
    config = get_default_config()
    print(f"âœ“ é»˜è®¤é…ç½®åŠ è½½å®Œæˆï¼ŒåŒ…å« {len(config)} ä¸ªå‚æ•°")
    
    # åˆ›å»ºæ¨¡æ‹Ÿå™¨å®ä¾‹
    simulator = create_hippocampus_simulator(
        input_dim=512,
        hidden_dim=256,
        vocab_size=10000
    )
    
    # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
    system_stats = simulator.get_system_statistics()
    total_params = system_stats['system_info']['total_parameters']
    memory_usage = system_stats['system_info']['model_size_mb']
    
    print(f"âœ“ æµ·é©¬ä½“æ¨¡æ‹Ÿå™¨åˆ›å»ºæˆåŠŸ")
    print(f"  - æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"  - æ¨¡å‹å¤§å°: {memory_usage:.2f} MB")
    print(f"  - è¾“å…¥ç»´åº¦: 512")
    print(f"  - éšè—ç»´åº¦: 256")
    print()
    
    return simulator


def demonstrate_memory_encoding(simulator: Any):
    """æ¼”ç¤ºè®°å¿†ç¼–ç åŠŸèƒ½"""
    print("ğŸ“ è®°å¿†ç¼–ç æ¼”ç¤º")
    print("-" * 40)
    
    # åˆ›å»ºæµ‹è¯•è®°å¿†å†…å®¹
    batch_size = 4
    memory_dim = 256
    
    # ç”Ÿæˆä¸åŒçš„è®°å¿†å†…å®¹
    memories = [
        "ä»Šå¤©å­¦ä¹ äº†æ·±åº¦å­¦ä¹ çš„Transformeræ¶æ„",
        "æµ·é©¬ä½“åœ¨è®°å¿†å½¢æˆä¸­èµ·å…³é”®ä½œç”¨",
        "çªè§¦å¯å¡‘æ€§æ˜¯å­¦ä¹ çš„åŸºç¡€æœºåˆ¶", 
        "æƒ…æ™¯è®°å¿†æ¶‰åŠæ—¶é—´åºåˆ—å¤„ç†"
    ]
    
    # è½¬æ¢ä¸ºå¼ é‡ï¼ˆæ¨¡æ‹Ÿç¼–ç åçš„å‘é‡ï¼‰
    memory_tensors = []
    for i, memory in enumerate(memories):
        # æ¨¡æ‹Ÿå°†æ–‡æœ¬ç¼–ç ä¸ºå‘é‡
        np.random.seed(i + 42)  # ç¡®ä¿å¯é‡ç°æ€§
        tensor = torch.randn(memory_dim)
        memory_tensors.append(tensor)
        print(f"  è®°å¿† {i+1}: {memory[:30]}...")
    
    print(f"\nâœ“ å‡†å¤‡äº† {len(memories)} ä¸ªæµ‹è¯•è®°å¿†")
    
    # ç¼–ç è®°å¿†åˆ°æµ·é©¬ä½“ç³»ç»Ÿ
    encoded_results = []
    encoding_times = []
    
    for i, memory_tensor in enumerate(memory_tensors):
        start_time = time.time()
        
        encoding_result = simulator.encode_memory(
            content=memory_tensor,
            context=None,
            metadata={'id': f'memory_{i+1}', 'type': 'episodic'}
        )
        
        encoding_time = time.time() - start_time
        encoding_times.append(encoding_time)
        encoded_results.append(encoding_result)
        
        print(f"  è®°å¿† {i+1} ç¼–ç å®Œæˆ (è€—æ—¶: {encoding_time:.4f}s)")
    
    avg_encoding_time = np.mean(encoding_times)
    print(f"\nâœ“ è®°å¿†ç¼–ç å®Œæˆï¼Œå¹³å‡è€—æ—¶: {avg_encoding_time:.4f}s")
    print()
    
    return encoded_results


def demonstrate_memory_retrieval(simulator: Any, encoded_results: List[Dict]):
    """æ¼”ç¤ºè®°å¿†æ£€ç´¢åŠŸèƒ½"""
    print("ğŸ” è®°å¿†æ£€ç´¢æ¼”ç¤º")
    print("-" * 40)
    
    # å‡†å¤‡æ£€ç´¢æŸ¥è¯¢
    query_texts = [
        "æ·±åº¦å­¦ä¹ æ¶æ„",
        "è®°å¿†æœºåˆ¶",
        "ç¥ç»ç½‘ç»œå­¦ä¹ "
    ]
    
    print("æ£€ç´¢æŸ¥è¯¢:")
    for i, query in enumerate(query_texts):
        print(f"  æŸ¥è¯¢ {i+1}: {query}")
    
    retrieval_results = []
    retrieval_times = []
    
    for i, query_text in enumerate(query_texts):
        # åˆ›å»ºæŸ¥è¯¢å‘é‡ï¼ˆæ¨¡æ‹Ÿæ–‡æœ¬ç¼–ç ï¼‰
        np.random.seed(i + 100)
        query_tensor = torch.randn(256)
        
        start_time = time.time()
        
        # æ‰§è¡Œæ£€ç´¢
        retrieval_result = simulator.retrieve_memory(
            query=query_tensor,
            retrieval_type='hybrid',
            num_results=3
        )
        
        retrieval_time = time.time() - start_time
        retrieval_times.append(retrieval_time)
        retrieval_results.append(retrieval_result)
        
        similarity = retrieval_result['similarity_score']
        print(f"  æŸ¥è¯¢ {i+1} æ£€ç´¢å®Œæˆ (ç›¸ä¼¼åº¦: {similarity:.4f}, è€—æ—¶: {retrieval_time:.4f}s)")
    
    avg_retrieval_time = np.mean(retrieval_times)
    print(f"\nâœ“ è®°å¿†æ£€ç´¢å®Œæˆï¼Œå¹³å‡è€—æ—¶: {avg_retrieval_time:.4f}s")
    print()
    
    return retrieval_results


def demonstrate_pattern_separation(simulator: Any):
    """æ¼”ç¤ºæ¨¡å¼åˆ†ç¦»åŠŸèƒ½"""
    print("ğŸ¯ æ¨¡å¼åˆ†ç¦»æ¼”ç¤º")
    print("-" * 40)
    
    # åˆ›å»ºç›¸ä¼¼å’Œä¸åŒçš„è¾“å…¥å¯¹
    base_input = torch.randn(256)
    
    # ç›¸ä¼¼è¾“å…¥ï¼ˆåœ¨åŸºç¡€è¾“å…¥ä¸Šæ·»åŠ å°æ‰°åŠ¨ï¼‰
    similar_input = base_input + 0.1 * torch.randn(256)
    
    # ä¸åŒè¾“å…¥ï¼ˆå®Œå…¨ä¸åŒçš„å‘é‡ï¼‰
    different_input = torch.randn(256)
    
    inputs = {
        'ç›¸ä¼¼è¾“å…¥': (base_input, similar_input),
        'ä¸åŒè¾“å…¥': (base_input, different_input)
    }
    
    print("æµ‹è¯•æ¨¡å¼åˆ†ç¦»æ•ˆæœ:")
    
    for test_name, (input1, input2) in inputs.items():
        # è®¡ç®—åˆ†ç¦»æŒ‡æ ‡
        metrics = simulator.pattern_separator.compute_separation_metrics(input1, input2)
        
        print(f"\n  {test_name}:")
        print(f"    åŸå§‹ç›¸ä¼¼åº¦: {metrics['cosine_similarity']:.4f}")
        print(f"    åˆ†ç¦»åç›¸ä¼¼åº¦: {metrics['separated_cosine']:.4f}")
        print(f"    åˆ†ç¦»æ”¹å–„: {metrics['separation_improvement']:.4f}")
        print(f"    æ¬§æ°è·ç¦»å˜åŒ–: {metrics['euclidean_distance']:.4f} -> {metrics['separated_euclidean']:.4f}")
    
    print("\nâœ“ æ¨¡å¼åˆ†ç¦»æ¼”ç¤ºå®Œæˆ")
    print()


def demonstrate_fast_learning(simulator: Any):
    """æ¼”ç¤ºå¿«é€Ÿå­¦ä¹ åŠŸèƒ½"""
    print("âš¡ å¿«é€Ÿå­¦ä¹ æ¼”ç¤º")
    print("-" * 40)
    
    # åˆ›å»ºfew-shotå­¦ä¹ ä»»åŠ¡
    num_way = 3  # 3ç±»
    num_shot = 2  # æ¯ç±»2ä¸ªæ ·æœ¬
    num_query = 4  # 4ä¸ªæŸ¥è¯¢æ ·æœ¬
    
    # ç”Ÿæˆæ”¯æŒé›†å’ŒæŸ¥è¯¢é›†
    support_size = num_way * num_shot
    query_size = num_query
    
    support_x = torch.randn(support_size, 256)
    query_x = torch.randn(query_size, 256)
    
    # æ¨¡æ‹Ÿæ”¯æŒé›†æ ‡ç­¾
    support_y = torch.cat([
        torch.full((num_shot,), i, dtype=torch.long) 
        for i in range(num_way)
    ])
    
    print(f"Few-shotå­¦ä¹ ä»»åŠ¡:")
    print(f"  - ç±»åˆ«æ•°: {num_way}")
    print(f"  - æ¯ç±»æ ·æœ¬æ•°: {num_shot}")
    print(f"  - æŸ¥è¯¢æ ·æœ¬æ•°: {query_size}")
    
    # æ‰§è¡Œfew-shotå­¦ä¹ 
    start_time = time.time()
    
    predictions, learning_stats = simulator.one_shot_learner.few_shot_learning(
        support_x=support_x,
        support_y=support_y,
        query_x=query_x,
        adaptation_steps=5
    )
    
    learning_time = time.time() - start_time
    
    print(f"\nå­¦ä¹ ç»“æœ:")
    print(f"  - é¢„æµ‹å½¢çŠ¶: {predictions.shape}")
    print(f"  - å­¦ä¹ è€—æ—¶: {learning_time:.4f}s")
    print(f"  - æ”¯æŒé›†ç¼–ç èŒƒæ•°: {learning_stats['support_encoded_norm']:.4f}")
    print(f"  - æŸ¥è¯¢é›†ç¼–ç èŒƒæ•°: {learning_stats['query_encoded_norm']:.4f}")
    print(f"  - é€‚åº”ç­–ç•¥: {learning_stats['adaptation_strategy'].mean():.4f}")
    
    print("\nâœ“ å¿«é€Ÿå­¦ä¹ æ¼”ç¤ºå®Œæˆ")
    print()


def demonstrate_episodic_memory(simulator: Any):
    """æ¼”ç¤ºæƒ…æ™¯è®°å¿†åŠŸèƒ½"""
    print("ğŸ“š æƒ…æ™¯è®°å¿†æ¼”ç¤º")
    print("-" * 40)
    
    # åˆ›å»ºæ—¶é—´åºåˆ—è®°å¿†
    base_time = time.time()
    episodes = []
    
    for i in range(5):
        timestamp = base_time + i * 3600  # æ¯å°æ—¶ä¸€ä¸ªäº‹ä»¶
        
        # åˆ›å»ºæƒ…æ™¯å†…å®¹
        content = torch.randn(256)
        context = torch.randn(256)
        
        episode_id = f"episode_{i+1}"
        
        # å­˜å‚¨æƒ…æ™¯è®°å¿†
        result = simulator.episodic_memory.store_episode(
            content=content,
            timestamp=timestamp,
            context=context,
            episode_id=episode_id
        )
        
        episodes.append({
            'id': episode_id,
            'timestamp': timestamp,
            'content_norm': torch.norm(content).item()
        })
        
        print(f"  å­˜å‚¨æƒ…æ™¯ {i+1}: {episode_id} (æ—¶é—´: {time.ctime(timestamp)})")
    
    print(f"\nâœ“ å­˜å‚¨äº† {len(episodes)} ä¸ªæƒ…æ™¯è®°å¿†")
    
    # æ£€ç´¢æƒ…æ™¯è®°å¿†
    query_content = torch.randn(256)
    query_time = base_time + 7200  # æŸ¥è¯¢ç¬¬3å°æ—¶çš„äº‹ä»¶
    
    start_time = time.time()
    
    retrieved, stats = simulator.episodic_memory.retrieve_episodes(
        query_content=query_content,
        query_context=torch.randn(256),
        query_timestamp=query_time,
        time_window=(base_time, base_time + 4 * 3600),  # å‰4å°æ—¶
        retrieval_type='temporal'
    )
    
    retrieval_time = time.time() - start_time
    
    print(f"\næƒ…æ™¯è®°å¿†æ£€ç´¢:")
    print(f"  - æ£€ç´¢è€—æ—¶: {retrieval_time:.4f}s")
    print(f"  - æ£€ç´¢ç±»å‹: {stats['retrieval_type']}")
    print(f"  - æœç´¢ç»†èƒæ•°: {stats['num_cells_searched']}")
    print(f"  - å¹³å‡æ£€ç´¢åˆ†æ•°: {stats['avg_retrieval_score']:.4f}")
    
    print("\nâœ“ æƒ…æ™¯è®°å¿†æ¼”ç¤ºå®Œæˆ")
    print()


def demonstrate_memory_consolidation(simulator: Any):
    """æ¼”ç¤ºè®°å¿†å·©å›ºåŠŸèƒ½"""
    print("ğŸ”„ è®°å¿†å·©å›ºæ¼”ç¤º")
    print("-" * 40)
    
    # æ‰§è¡Œè®°å¿†å·©å›º
    consolidation_result = simulator.consolidate_memories()
    
    print("è®°å¿†å·©å›ºç»“æœ:")
    print(f"  - å·©å›ºè€—æ—¶: {consolidation_result['consolidation_time']:.4f}s")
    print(f"  - æ—¶é—´æˆ³: {time.ctime(consolidation_result['timestamp'])}")
    
    episodic_update = consolidation_result['episodic_update']
    print(f"  - æ›´æ–°çš„è®°å¿†ç»†èƒ: {episodic_update['cells_updated']}")
    print(f"  - å·©å›ºçš„è®°å¿†æ•°: {episodic_update['memories_consolidated']}")
    print(f"  - é—å¿˜çš„è®°å¿†æ•°: {episodic_update['memories_forgotten']}")
    
    dict_compression = consolidation_result['dictionary_compression']
    print(f"  - ç¥ç»å­—å…¸å‹ç¼©:")
    for cell, count in dict_compression.items():
        print(f"    {cell}: {count} ä¸ªè®°å¿†è¢«é—å¿˜")
    
    print("\nâœ“ è®°å¿†å·©å›ºæ¼”ç¤ºå®Œæˆ")
    print()


def demonstrate_system_performance(simulator: Any):
    """æ¼”ç¤ºç³»ç»Ÿæ€§èƒ½ç›‘æ§"""
    print("ğŸ“Š ç³»ç»Ÿæ€§èƒ½ç›‘æ§")
    print("-" * 40)
    
    # è·å–å®Œæ•´ç³»ç»Ÿç»Ÿè®¡
    system_stats = simulator.get_system_statistics()
    
    print("ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡:")
    print(f"  - æ€»æ“ä½œæ•°: {system_stats['performance_monitor']['total_operations']}")
    print(f"  - å¹³å‡å“åº”æ—¶é—´: {system_stats['performance_monitor']['avg_response_time']:.4f}s")
    print(f"  - æ¨¡å‹å¤§å°: {system_stats['system_info']['model_size_mb']:.2f} MB")
    
    print("\næ¨¡å—ä½¿ç”¨ç»Ÿè®¡:")
    module_usage = system_stats['performance_monitor']['module_usage']
    for module, count in module_usage.items():
        print(f"  - {module}: {count} æ¬¡è°ƒç”¨")
    
    print("\nè¯¦ç»†æ¨¡å—ç»Ÿè®¡:")
    
    # ç¥ç»å­—å…¸ç»Ÿè®¡
    dict_stats = system_stats['modules']['neural_dictionary']
    print(f"  ç¥ç»å­—å…¸:")
    print(f"    - å½“å‰å¤§å°: {dict_stats['total_current_size']}")
    print(f"    - å¹³å‡åˆ©ç”¨ç‡: {dict_stats['average_utilization']:.4f}")
    print(f"    - æ€»å†™å…¥æ¬¡æ•°: {dict_stats['global_memory_stats']['total_writes']}")
    print(f"    - æ€»æ£€ç´¢æ¬¡æ•°: {dict_stats['global_memory_stats']['total_retrievals']}")
    
    # æ¨¡å¼åˆ†ç¦»å™¨ç»Ÿè®¡
    sep_stats = system_stats['modules']['pattern_separator']
    print(f"  æ¨¡å¼åˆ†ç¦»å™¨:")
    print(f"    - é¢—ç²’ç»†èƒæ•°: {sep_stats['granule_layer']['num_granule_cells']}")
    print(f"    - å½“å‰ç¨€ç–æ€§: {sep_stats['granule_layer']['current_sparsity']:.4f}")
    print(f"    - CA3ç»†èƒæ•°: {sep_stats['ca3_network']['num_ca3_cells']}")
    
    # æƒ…æ™¯è®°å¿†ç»Ÿè®¡
    epi_stats = system_stats['modules']['episodic_memory']
    print(f"  æƒ…æ™¯è®°å¿†:")
    print(f"    - è®°å¿†ç»†èƒæ•°: {epi_stats['num_memory_cells']}")
    print(f"    - æ€»å®¹é‡: {epi_stats['total_capacity']}")
    print(f"    - å½“å‰ä½¿ç”¨: {epi_stats['total_current_size']}")
    print(f"    - çŸ­æœŸç¼“å†²: {epi_stats['short_term_buffer_size']}")
    
    print("\nâœ“ ç³»ç»Ÿæ€§èƒ½ç›‘æ§å®Œæˆ")
    print()


def demonstrate_memory_export(simulator: Any):
    """æ¼”ç¤ºè®°å¿†çŠ¶æ€å¯¼å‡º"""
    print("ğŸ’¾ è®°å¿†çŠ¶æ€å¯¼å‡ºæ¼”ç¤º")
    print("-" * 40)
    
    export_path = "/workspace/hippocampus_memory_state.json"
    
    # å¯¼å‡ºè®°å¿†çŠ¶æ€
    simulator.export_memory_state(export_path)
    
    print(f"âœ“ è®°å¿†çŠ¶æ€å·²å¯¼å‡ºåˆ°: {export_path}")
    
    # æ£€æŸ¥å¯¼å‡ºæ–‡ä»¶
    try:
        with open(export_path, 'r', encoding='utf-8') as f:
            export_data = json.load(f)
        
        print(f"  å¯¼å‡ºæ–‡ä»¶å¤§å°: {len(json.dumps(export_data))} å­—ç¬¦")
        print(f"  åŒ…å«ç³»ç»Ÿç»Ÿè®¡: {'system_statistics' in export_data}")
        print(f"  åŒ…å«ç¥ç»å­—å…¸çŠ¶æ€: {'neural_dictionary_state' in export_data}")
        print(f"  åŒ…å«æƒ…æ™¯è®°å¿†ç¼“å†²: {'episodic_memory_buffer' in export_data}")
        print(f"  å¯¼å‡ºæ—¶é—´æˆ³: {export_data['timestamp']}")
        
    except Exception as e:
        print(f"  å¯¼å‡ºæ–‡ä»¶è¯»å–å¤±è´¥: {e}")
    
    print("\nâœ“ è®°å¿†çŠ¶æ€å¯¼å‡ºæ¼”ç¤ºå®Œæˆ")
    print()


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print_banner()
    
    try:
        # 1. ç³»ç»Ÿåˆå§‹åŒ–
        simulator = demonstrate_system_initialization()
        
        # 2. è®°å¿†ç¼–ç æ¼”ç¤º
        encoded_results = demonstrate_memory_encoding(simulator)
        
        # 3. è®°å¿†æ£€ç´¢æ¼”ç¤º
        retrieval_results = demonstrate_memory_retrieval(simulator, encoded_results)
        
        # 4. æ¨¡å¼åˆ†ç¦»æ¼”ç¤º
        demonstrate_pattern_separation(simulator)
        
        # 5. å¿«é€Ÿå­¦ä¹ æ¼”ç¤º
        demonstrate_fast_learning(simulator)
        
        # 6. æƒ…æ™¯è®°å¿†æ¼”ç¤º
        demonstrate_episodic_memory(simulator)
        
        # 7. è®°å¿†å·©å›ºæ¼”ç¤º
        demonstrate_memory_consolidation(simulator)
        
        # 8. ç³»ç»Ÿæ€§èƒ½ç›‘æ§
        demonstrate_system_performance(simulator)
        
        # 9. è®°å¿†çŠ¶æ€å¯¼å‡º
        demonstrate_memory_export(simulator)
        
        # å®Œæˆæ€»ç»“
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆæ€»ç»“")
        print("=" * 40)
        print("âœ“ æ‰€æœ‰åŠŸèƒ½æ¨¡å—æµ‹è¯•é€šè¿‡")
        print("âœ“ æµ·é©¬ä½“è®°å¿†ç³»ç»Ÿè¿è¡Œæ­£å¸¸")
        print("âœ“ åŸºäºç¥ç»ç§‘å­¦çš„ç”Ÿç‰©å¯å‘å¼å®ç°éªŒè¯æˆåŠŸ")
        print("\nğŸ“ ä¸»è¦ç‰¹æ€§éªŒè¯:")
        print("  â€¢ Transformer-basedè®°å¿†ç¼–ç ")
        print("  â€¢ å¯å¾®åˆ†ç¥ç»å­—å…¸å­˜å‚¨æ£€ç´¢")
        print("  â€¢ æ¨¡å¼åˆ†ç¦»æœºåˆ¶")
        print("  â€¢ å¿«é€Ÿä¸€æ¬¡æ€§å­¦ä¹ ")
        print("  â€¢ æƒ…æ™¯è®°å¿†æ—¶é—´åºåˆ—å¤„ç†")
        print("  â€¢ è®°å¿†å·©å›ºå’Œè¡°å‡")
        print("  â€¢ æ€§èƒ½ç›‘æ§å’ŒçŠ¶æ€å¯¼å‡º")
        print("\nğŸ§  æµ·é©¬ä½“æ¨¡æ‹Ÿå™¨v2.0.0éƒ¨ç½²æˆåŠŸï¼")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()