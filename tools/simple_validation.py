#!/usr/bin/env python3
"""
æç®€ç³»ç»ŸéªŒè¯æµ‹è¯• - éªŒè¯æ ¸å¿ƒåŠŸèƒ½
"""

import numpy as np
import time
import platform
import psutil
from datetime import datetime

# æ£€æŸ¥ä¾èµ–
TORCH_AVAILABLE = False
SKLEARN_AVAILABLE = False

try:
    import torch
    TORCH_AVAILABLE = True
    print("âœ… PyTorchå¯ç”¨")
except ImportError:
    print("âŒ PyTorchä¸å¯ç”¨")

try:
    from sklearn.datasets import make_classification
    SKLEARN_AVAILABLE = True
    print("âœ… scikit-learnå¯ç”¨")
except ImportError:
    print("âŒ scikit-learnä¸å¯ç”¨")

print("="*60)
print("ğŸ§  è„‘å¯å‘AIç³»ç»Ÿ - æç®€åŠŸèƒ½éªŒè¯")
print("="*60)
print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# 1. åŸºç¡€æ•°å­¦è¿ç®—æµ‹è¯•
print("\nğŸ”¢ åŸºç¡€æ•°å­¦è¿ç®—æµ‹è¯•")
try:
    x = np.array([1, 2, 3, 4, 5])
    result = np.sum(x)
    assert result == 15
    print(f"   âœ… NumPyæ•°ç»„æ“ä½œ: {result}")
    
    # çŸ©é˜µè¿ç®—
    A = np.random.randn(10, 10)
    B = np.random.randn(10, 10)
    C = np.dot(A, B)
    assert C.shape == (10, 10)
    print(f"   âœ… çŸ©é˜µä¹˜æ³•: {C.shape}")
    
    print("   âœ… åŸºç¡€æ•°å­¦è¿ç®—æ­£å¸¸")
except Exception as e:
    print(f"   âŒ åŸºç¡€æ•°å­¦è¿ç®—å¤±è´¥: {e}")

# 2. æ•°æ®ç”Ÿæˆæµ‹è¯•
print("\nğŸ“Š æ•°æ®ç”Ÿæˆæµ‹è¯•")
try:
    if SKLEARN_AVAILABLE:
        X, y = make_classification(
            n_samples=100,
            n_features=20,
            n_classes=3,
            random_state=42
        )
        print(f"   âœ… æ•°æ®ç”Ÿæˆ: {X.shape}, {len(np.unique(y))} ç±»åˆ«")
        print(f"   æ•°æ®ç±»å‹: {X.dtype}, æ ‡ç­¾ç±»å‹: {y.dtype}")
    else:
        # ä½¿ç”¨éšæœºæ•°æ®ä»£æ›¿
        np.random.seed(42)
        X = np.random.randn(100, 20).astype(np.float32)
        y = np.random.randint(0, 3, 100).astype(np.int32)
        print(f"   âœ… éšæœºæ•°æ®ç”Ÿæˆ: {X.shape}, {len(np.unique(y))} ç±»åˆ«")
        print(f"   æ•°æ®ç±»å‹: {X.dtype}, æ ‡ç­¾ç±»å‹: {y.dtype}")
except Exception as e:
    print(f"   âŒ æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")

# 3. æ¨¡å‹æ¶æ„æµ‹è¯•
print("\nğŸ—ï¸ æ¨¡å‹æ¶æ„æµ‹è¯•")
try:
    if TORCH_AVAILABLE:
        import torch
        import torch.nn as nn
        
        # åˆ›å»ºç®€å•æ¨¡å‹
        class SimpleModel(nn.Module):
            def __init__(self, input_dim, hidden_dim, output_dim):
                super().__init__()
                self.encoder = nn.Sequential(
                    nn.Linear(input_dim, hidden_dim),
                    nn.ReLU(),
                    nn.Linear(hidden_dim, hidden_dim),
                    nn.ReLU()
                )
                self.classifier = nn.Linear(hidden_dim, output_dim)
            
            def forward(self, x):
                x = self.encoder(x)
                return self.classifier(x)
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = SimpleModel(20, 64, 3)
        
        # å‰å‘ä¼ æ’­æµ‹è¯•
        test_input = torch.randn(10, 20)
        output = model(test_input)
        
        assert output.shape == (10, 3)
        
        # ç»Ÿè®¡å‚æ•°
        total_params = sum(p.numel() for p in model.parameters())
        print(f"   âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"   âœ… å‰å‘ä¼ æ’­æ­£å¸¸: {output.shape}")
        print(f"   ğŸ“Š æ€»å‚æ•°æ•°: {total_params:,}")
        
    else:
        # NumPyç‰ˆæœ¬
        input_dim, hidden_dim, output_dim = 20, 64, 3
        
        # ç®€å•çš„å‰å‘ä¼ æ’­æµ‹è¯•
        weights1 = np.random.randn(input_dim, hidden_dim) * 0.1
        bias1 = np.zeros(hidden_dim)
        weights2 = np.random.randn(hidden_dim, output_dim) * 0.1
        bias2 = np.zeros(output_dim)
        
        test_input = np.random.randn(10, input_dim).astype(np.float32)
        
        # å‰å‘ä¼ æ’­
        hidden = np.maximum(0, np.dot(test_input, weights1) + bias1)
        output = np.dot(hidden, weights2) + bias2
        
        assert output.shape == (10, output_dim)
        
        print(f"   âœ… NumPyæ¨¡å‹æ¶æ„æ­£å¸¸")
        print(f"   âœ… å‰å‘ä¼ æ’­æ­£å¸¸: {output.shape}")
        
except Exception as e:
    print(f"   âŒ æ¨¡å‹æ¶æ„æµ‹è¯•å¤±è´¥: {e}")

# 4. è®­ç»ƒæµ‹è¯•ï¼ˆç®€åŒ–ç‰ˆï¼‰
print("\nğŸ¯ è®­ç»ƒæµ‹è¯•ï¼ˆç®€åŒ–ç‰ˆï¼‰")
try:
    if TORCH_AVAILABLE and SKLEARN_AVAILABLE:
        import torch
        import torch.nn as nn
        import torch.optim as optim
        
        # å‡†å¤‡æ•°æ®
        X_tensor = torch.FloatTensor(X)
        y_tensor = torch.LongTensor(y)
        
        # åˆ›å»ºæ¨¡å‹
        model = SimpleModel(20, 64, 3)
        optimizer = optim.Adam(model.parameters(), lr=0.01)
        criterion = nn.CrossEntropyLoss()
        
        # ç®€å•è®­ç»ƒå¾ªç¯
        model.train()
        initial_loss = None
        final_loss = None
        
        for epoch in range(3):
            optimizer.zero_grad()
            outputs = model(X_tensor)
            loss = criterion(outputs, y_tensor)
            loss.backward()
            optimizer.step()
            
            if epoch == 0:
                initial_loss = loss.item()
            final_loss = loss.item()
        
        print(f"   âœ… è®­ç»ƒå¾ªç¯æ­£å¸¸")
        print(f"   ğŸ“‰ æŸå¤±: {initial_loss:.4f} -> {final_loss:.4f}")
        
        # æ¨ç†æµ‹è¯•
        model.eval()
        with torch.no_grad():
            test_outputs = model(X_tensor[:10])
            _, predicted = torch.max(test_outputs, 1)
            accuracy = (predicted == y_tensor[:10]).float().mean().item()
        
        print(f"   âœ… æ¨ç†æµ‹è¯•æ­£å¸¸")
        print(f"   ğŸ¯ æ ·æœ¬å‡†ç¡®ç‡: {accuracy:.4f}")
        
    else:
        # ç®€åŒ–è®­ç»ƒæµ‹è¯•
        print("   âš ï¸ è·³è¿‡è¯¦ç»†è®­ç»ƒæµ‹è¯•ï¼ˆç¼ºå°‘ä¾èµ–ï¼‰")
        print("   âœ… åŸºç¡€æ¶æ„æ­£å¸¸")
        
except Exception as e:
    print(f"   âŒ è®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")

# 5. å†…å­˜å’Œæ€§èƒ½æµ‹è¯•
print("\nğŸ’¾ å†…å­˜å’Œæ€§èƒ½æµ‹è¯•")
try:
    # è·å–ç³»ç»Ÿä¿¡æ¯
    memory_info = psutil.virtual_memory()
    print(f"   ğŸ’½ æ€»å†…å­˜: {memory_info.total / 1024**3:.1f} GB")
    print(f"   ğŸ“Š å¯ç”¨å†…å­˜: {memory_info.available / 1024**3:.1f} GB")
    print(f"   ğŸ–¥ï¸ CPUæ ¸å¿ƒæ•°: {psutil.cpu_count()}")
    print(f"   ğŸ–±ï¸ å¹³å°: {platform.system()} {platform.release()}")
    
    # ç®€å•æ€§èƒ½æµ‹è¯•
    start_time = time.time()
    test_array = np.random.randn(1000, 100).astype(np.float32)
    result = np.sum(test_array, axis=0)
    end_time = time.time()
    
    print(f"   âš¡ æ€§èƒ½æµ‹è¯•: {(end_time - start_time)*1000:.2f}ms")
    print(f"   âœ… å†…å­˜å’Œæ€§èƒ½æ­£å¸¸")
    
except Exception as e:
    print(f"   âŒ å†…å­˜å’Œæ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")

# 6. æŒç»­å­¦ä¹ åŸºæœ¬æµ‹è¯•
print("\nğŸ§  æŒç»­å­¦ä¹ åŸºæœ¬æµ‹è¯•")
try:
    # ä»»åŠ¡1æ•°æ®
    task1_data = np.random.randn(50, 20).astype(np.float32)
    task1_labels = np.random.randint(0, 3, 50).astype(np.int32)
    
    # ä»»åŠ¡2æ•°æ®
    task2_data = np.random.randn(50, 20).astype(np.float32)
    task2_labels = np.random.randint(0, 3, 50).astype(np.int32)
    
    print(f"   âœ… ä»»åŠ¡1æ•°æ®: {task1_data.shape}")
    print(f"   âœ… ä»»åŠ¡2æ•°æ®: {task2_data.shape}")
    
    # æ£€æŸ¥æ•°æ®åˆ†å¸ƒ
    print(f"   ğŸ“Š ä»»åŠ¡1æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(task1_labels)}")
    print(f"   ğŸ“Š ä»»åŠ¡2æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(task2_labels)}")
    
    print("   âœ… æŒç»­å­¦ä¹ æ•°æ®å‡†å¤‡æ­£å¸¸")
    
except Exception as e:
    print(f"   âŒ æŒç»­å­¦ä¹ æµ‹è¯•å¤±è´¥: {e}")

# ç”Ÿæˆæ€»ç»“
print("\n" + "="*60)
print("ğŸ‰ æç®€åŠŸèƒ½éªŒè¯å®Œæˆ!")
print("="*60)

# æ£€æŸ¥ä¾èµ–çŠ¶æ€
dependencies_status = {
    'PyTorch': TORCH_AVAILABLE,
    'scikit-learn': SKLEARN_AVAILABLE,
    'NumPy': True,
    'Platform': True
}

available_deps = sum(dependencies_status.values())
total_deps = len(dependencies_status)

print(f"ğŸ“¦ ä¾èµ–æ£€æŸ¥:")
for dep, available in dependencies_status.items():
    status = "âœ…" if available else "âŒ"
    print(f"   {status} {dep}")

availability_rate = available_deps / total_deps * 100

print(f"\nğŸ“Š ç³»ç»ŸçŠ¶æ€:")
print(f"   ä¾èµ–å¯ç”¨ç‡: {availability_rate:.1f}% ({available_deps}/{total_deps})")
print(f"   ç³»ç»Ÿå¹³å°: {platform.system()}")
print(f"   Pythonç‰ˆæœ¬: {platform.python_version()}")

# è¯„çº§
if availability_rate >= 80:
    grade = "ä¼˜ç§€ â­â­â­â­â­"
    recommendation = "ç³»ç»Ÿæ ¸å¿ƒåŠŸèƒ½å®Œæ•´ï¼Œå¯ä»¥è¿›è¡Œå®Œæ•´æµ‹è¯•"
elif availability_rate >= 60:
    grade = "è‰¯å¥½ â­â­â­â­"
    recommendation = "ç³»ç»ŸåŸºæœ¬åŠŸèƒ½å¯ç”¨ï¼Œå»ºè®®å®Œå–„ä¾èµ–"
elif availability_rate >= 40:
    grade = "ä¸­ç­‰ â­â­â­"
    recommendation = "ç³»ç»Ÿéƒ¨åˆ†åŠŸèƒ½å¯ç”¨ï¼Œéœ€è¦è¡¥å……å…³é”®ä¾èµ–"
else:
    grade = "éœ€è¦æ”¹è¿› â­â­"
    recommendation = "ç³»ç»ŸåŠŸèƒ½å—é™ï¼Œå»ºè®®å®‰è£…å¿…è¦ä¾èµ–"

print(f"\nğŸ¯ ç³»ç»Ÿè¯„çº§: {grade}")
print(f"ğŸ’¡ å»ºè®®: {recommendation}")

print(f"\nâ±ï¸ éªŒè¯å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# ä¿å­˜ç®€åŒ–çš„éªŒè¯ç»“æœ
import json
import os

os.makedirs('data/results', exist_ok=True)
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
simple_result = {
    'timestamp': datetime.now().isoformat(),
    'dependencies': dependencies_status,
    'availability_rate': availability_rate,
    'grade': grade,
    'recommendation': recommendation,
    'system_info': {
        'platform': platform.system(),
        'python_version': platform.python_version(),
        'cpu_count': psutil.cpu_count(),
        'memory_total_gb': psutil.virtual_memory().total / 1024**3
    }
}

output_file = f'data/results/simple_validation_{timestamp}.json'
with open(output_file, 'w', encoding='utf-8') as f:
    json.dump(simple_result, f, indent=2, ensure_ascii=False)

print(f"ğŸ’¾ éªŒè¯ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

# è¿”å›æˆåŠŸçŠ¶æ€
success = availability_rate >= 60
print(f"\n{'âœ… ç³»ç»ŸéªŒè¯é€šè¿‡' if success else 'âŒ ç³»ç»Ÿéœ€è¦æ”¹è¿›'}")
