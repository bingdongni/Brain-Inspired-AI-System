#!/usr/bin/env python3
"""
æµ·é©¬ä½“æ¨¡æ‹Ÿå™¨æ ¸å¿ƒæ¨¡å—å®Œæ•´æ€§éªŒè¯
ç®€åŒ–çš„éªŒè¯è„šæœ¬ï¼Œé¿å…å¤æ‚çš„ç»´åº¦åŒ¹é…é—®é¢˜
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import time
from typing import Dict, Any, Tuple, Optional, List

# å¯¼å…¥æ‰€æœ‰æ ¸å¿ƒæ¨¡å—
from hippocampus.encoders.transformer_encoder import TransformerMemoryEncoder
from memory_cell.neural_dictionary import DifferentiableNeuralDictionary
from pattern_separation.pattern_separator import PatternSeparationNetwork
from hippocampus.fast_learning import OneShotLearner
from hippocampus.episodic_memory import EpisodicMemorySystem


class CoreModulesValidator:
    """æ ¸å¿ƒæ¨¡å—éªŒè¯å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–éªŒè¯å™¨"""
        print("ğŸ”§ åˆå§‹åŒ–æµ·é©¬ä½“æ¨¡æ‹Ÿå™¨æ ¸å¿ƒæ¨¡å—...")
        
        # é…ç½®å‚æ•°
        self.config = {
            'input_dim': 512,
            'hidden_dim': 256,
            'vocab_size': 1000,
            'transformer_layers': 4,
            'num_heads': 8,
            'dict_cells': 4,
            'dict_capacity': 200,
            'granule_cells': 400,
            'ca3_cells': 100,
            'sparsity': 0.02,
            'episodic_cells': 4,
            'episodic_capacity': 50,
            'temporal_dim': 32
        }
        
        self.setup_modules()
        print(f"âœ… æ ¸å¿ƒæ¨¡å—åˆå§‹åŒ–å®Œæˆ")
        print(f"   - æ€»å‚æ•°: {self.get_total_parameters():,}")
        
    def setup_modules(self):
        """è®¾ç½®æ‰€æœ‰æ ¸å¿ƒæ¨¡å—"""
        
        # 1. Transformerè®°å¿†ç¼–ç å™¨
        self.transformer_encoder = TransformerMemoryEncoder(
            vocab_size=self.config['vocab_size'],
            hidden_dim=self.config['hidden_dim'],
            num_layers=self.config['transformer_layers'],
            num_heads=self.config['num_heads'],
            max_seq_len=64,
            msb_enhancement=True,
            pattern_completion=False,  # æš‚æ—¶ç¦ç”¨æ¨¡å¼å®Œæˆé¿å…å¤æ‚ä¾èµ–
            temporal_alignment=True
        )
        
        # 2. å¯å¾®åˆ†ç¥ç»å­—å…¸
        self.neural_dictionary = DifferentiableNeuralDictionary(
            key_dim=self.config['hidden_dim'],
            value_dim=self.config['hidden_dim'],
            num_cells=self.config['dict_cells'],
            capacity_per_cell=self.config['dict_capacity'],
            temperature=1.0
        )
        
        # 3. æ¨¡å¼åˆ†ç¦»ç½‘ç»œ
        self.pattern_separator = PatternSeparationNetwork(
            input_dim=self.config['hidden_dim'],
            hidden_dim=self.config['hidden_dim'],
            num_granule_cells=self.config['granule_cells'],
            num_ca3_cells=self.config['ca3_cells'],
            sparsity=self.config['sparsity']
        )
        
        # 4. å¿«é€Ÿå­¦ä¹ å™¨
        self.one_shot_learner = OneShotLearner(
            input_dim=self.config['hidden_dim'],
            hidden_dim=self.config['hidden_dim'],
            num_way=3,
            num_shot=1
        )
        
        # 5. æƒ…æ™¯è®°å¿†ç³»ç»Ÿ
        self.episodic_memory = EpisodicMemorySystem(
            content_dim=self.config['hidden_dim'],
            temporal_dim=self.config['temporal_dim'],
            context_dim=self.config['hidden_dim'],
            num_cells=self.config['episodic_cells'],
            capacity_per_cell=self.config['episodic_capacity']
        )
        
    def get_total_parameters(self) -> int:
        """è·å–æ€»å‚æ•°æ•°é‡"""
        total = 0
        for module in [self.transformer_encoder, self.neural_dictionary, 
                      self.pattern_separator, self.one_shot_learner, self.episodic_memory]:
            total += sum(p.numel() for p in module.parameters())
        return total
    
    def validate_transformer_encoder(self) -> Dict[str, Any]:
        """éªŒè¯Transformerè®°å¿†ç¼–ç å™¨"""
        print("\nğŸ“ éªŒè¯Transformerè®°å¿†ç¼–ç å™¨...")
        
        try:
            # åˆ›å»ºæµ‹è¯•è¾“å…¥
            batch_size, seq_len = 2, 8
            test_input = torch.randint(0, self.config['vocab_size'], (batch_size, seq_len))
            
            # å‰å‘ä¼ æ’­
            with torch.no_grad():
                output, stats = self.transformer_encoder(
                    input_ids=test_input,
                    return_stats=True
                )
            
            print(f"   âœ… è¾“å…¥å½¢çŠ¶: {test_input.shape}")
            print(f"   âœ… è¾“å‡ºå½¢çŠ¶: {output.shape}")
            print(f"   âœ… ç»Ÿè®¡ä¿¡æ¯: {len(stats)} é¡¹")
            
            return {
                'success': True,
                'input_shape': list(test_input.shape),
                'output_shape': list(output.shape),
                'statistics_keys': list(stats.keys()) if stats else []
            }
            
        except Exception as e:
            print(f"   âŒ éªŒè¯å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def validate_neural_dictionary(self) -> Dict[str, Any]:
        """éªŒè¯å¯å¾®åˆ†ç¥ç»å­—å…¸"""
        print("\nğŸ” éªŒè¯å¯å¾®åˆ†ç¥ç»å­—å…¸...")
        
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            batch_size = 3
            test_keys = torch.randn(batch_size, self.config['hidden_dim'])
            test_values = torch.randn(batch_size, self.config['hidden_dim'])
            test_query = torch.randn(1, self.config['hidden_dim'])
            
            # å†™å…¥è®°å¿†
            with torch.no_grad():
                write_result = self.neural_dictionary.write_memory(test_keys, test_values)
            
            # æ£€ç´¢è®°å¿†
            with torch.no_grad():
                retrieved, retrieval_stats = self.neural_dictionary.retrieve_memory(
                    test_query, top_k=2
                )
            
            print(f"   âœ… å†™å…¥è®°å¿†: {write_result['total_writes']} é¡¹")
            print(f"   âœ… æ£€ç´¢ç»“æœ: {retrieved.shape}")
            print(f"   âœ… ç»Ÿè®¡ä¿¡æ¯: {len(retrieval_stats['cell_stats'])} ä¸ªç»†èƒ")
            
            return {
                'success': True,
                'write_operations': write_result['total_writes'],
                'retrieval_shape': list(retrieved.shape),
                'cells_searched': len(retrieval_stats['cell_stats'])
            }
            
        except Exception as e:
            print(f"   âŒ éªŒè¯å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def validate_pattern_separator(self) -> Dict[str, Any]:
        """éªŒè¯æ¨¡å¼åˆ†ç¦»ç½‘ç»œ"""
        print("\nğŸ¯ éªŒè¯æ¨¡å¼åˆ†ç¦»ç½‘ç»œ...")
        
        try:
            # åˆ›å»ºæµ‹è¯•è¾“å…¥å¯¹
            test_input1 = torch.randn(1, self.config['hidden_dim'])
            test_input2 = torch.randn(1, self.config['hidden_dim'])
            
            # æ¨¡å¼åˆ†ç¦»
            with torch.no_grad():
                sep1, sep2, stats = self.pattern_separator(test_input1, test_input2)
            
            print(f"   âœ… è¾“å…¥1å½¢çŠ¶: {test_input1.shape}")
            print(f"   âœ… è¾“å…¥2å½¢çŠ¶: {test_input2.shape}")
            print(f"   âœ… åˆ†ç¦»è¾“å‡º1: {sep1.shape}")
            print(f"   âœ… åˆ†ç¦»è¾“å‡º2: {sep2.shape}")
            print(f"   âœ… åˆ†ç¦»åº¦: {stats.get('separation_degree', 0.0):.3f}")
            
            return {
                'success': True,
                'input_shape': list(test_input1.shape),
                'output1_shape': list(sep1.shape),
                'output2_shape': list(sep2.shape),
                'separation_degree': stats.get('separation_degree', 0.0)
            }
            
        except Exception as e:
            print(f"   âŒ éªŒè¯å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def validate_one_shot_learner(self) -> Dict[str, Any]:
        """éªŒè¯å¿«é€Ÿå­¦ä¹ å™¨"""
        print("\nâš¡ éªŒè¯å¿«é€Ÿå­¦ä¹ å™¨...")
        
        try:
            # åˆ›å»ºfew-shotå­¦ä¹ æ•°æ®
            support_size, query_size = 3, 2
            support_x = torch.randn(support_size, self.config['hidden_dim'])
            query_x = torch.randn(query_size, self.config['hidden_dim'])
            support_y = torch.randint(0, 3, (support_size,))
            
            # Few-shotå­¦ä¹ 
            with torch.no_grad():
                predictions, learning_stats = self.one_shot_learner.few_shot_learning(
                    support_x=support_x,
                    support_y=support_y,
                    query_x=query_x
                )
            
            print(f"   âœ… æ”¯æŒé›†: {support_x.shape}")
            print(f"   âœ… æŸ¥è¯¢é›†: {query_x.shape}")
            print(f"   âœ… é¢„æµ‹ç»“æœ: {predictions.shape}")
            print(f"   âœ… å­¦ä¹ ç»Ÿè®¡: {len(learning_stats)} é¡¹")
            
            return {
                'success': True,
                'support_shape': list(support_x.shape),
                'query_shape': list(query_x.shape),
                'prediction_shape': list(predictions.shape),
                'stats_keys': list(learning_stats.keys())
            }
            
        except Exception as e:
            print(f"   âŒ éªŒè¯å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def validate_episodic_memory(self) -> Dict[str, Any]:
        """éªŒè¯æƒ…æ™¯è®°å¿†ç³»ç»Ÿ"""
        print("\nğŸ“š éªŒè¯æƒ…æ™¯è®°å¿†ç³»ç»Ÿ...")
        
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®
            test_content = torch.randn(1, self.config['hidden_dim'])
            test_context = torch.randn(1, self.config['hidden_dim'])
            timestamp = time.time()
            
            # å­˜å‚¨æƒ…æ™¯è®°å¿†
            with torch.no_grad():
                storage_result = self.episodic_memory.store_episode(
                    content=test_content,
                    timestamp=timestamp,
                    context=test_context,
                    episode_id="test_episode"
                )
            
            # æ£€ç´¢æƒ…æ™¯è®°å¿†
            with torch.no_grad():
                retrieval_result, retrieval_stats = self.episodic_memory.retrieve_episodes(
                    query_content=test_content,
                    query_context=test_context,
                    retrieval_type='content'
                )
            
            print(f"   âœ… å­˜å‚¨ç»“æœ: {storage_result['global_episode_id']}")
            print(f"   âœ… æ£€ç´¢å½¢çŠ¶: {retrieval_result.shape}")
            print(f"   âœ… æ£€ç´¢ç»Ÿè®¡: {len(retrieval_stats)} é¡¹")
            
            return {
                'success': True,
                'storage_episode_id': storage_result['global_episode_id'],
                'retrieval_shape': list(retrieval_result.shape),
                'retrieval_stats_keys': list(retrieval_stats.keys())
            }
            
        except Exception as e:
            print(f"   âŒ éªŒè¯å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def validate_integration(self) -> Dict[str, Any]:
        """éªŒè¯æ¨¡å—é›†æˆ"""
        print("\nğŸ”— éªŒè¯æ¨¡å—é›†æˆ...")
        
        try:
            # åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„è®°å¿†å¤„ç†æµç¨‹
            with torch.no_grad():
                # 1. ç¼–ç 
                input_tokens = torch.randint(0, self.config['vocab_size'], (1, 4))
                encoded_output, _ = self.transformer_encoder(input_ids=input_tokens, return_stats=False)
                
                # 2. æå–ç‰¹å¾å‘é‡
                features = encoded_output.mean(dim=1)  # [1, hidden_dim]
                
                # 3. æ¨¡å¼åˆ†ç¦»
                sep1, sep2, _ = self.pattern_separator(features, features + 0.1 * torch.randn_like(features))
                
                # 4. å­˜å‚¨åˆ°ç¥ç»å­—å…¸
                dict_result = self.neural_dictionary.write_memory(
                    key=features,
                    value=features
                )
                
                # 5. å­˜å‚¨æƒ…æ™¯è®°å¿†
                storage_result = self.episodic_memory.store_episode(
                    content=features,
                    timestamp=time.time(),
                    context=torch.zeros_like(features),
                    episode_id="integration_test"
                )
                
                # 6. æ£€ç´¢
                retrieval_result, retrieval_stats = self.episodic_memory.retrieve_episodes(
                    query_content=features,
                    query_context=torch.zeros_like(features)
                )
            
            print(f"   âœ… ç¼–ç å®Œæˆ: {encoded_output.shape}")
            print(f"   âœ… ç‰¹å¾æå–: {features.shape}")
            print(f"   âœ… æ¨¡å¼åˆ†ç¦»: {sep1.shape}")
            print(f"   âœ… å­—å…¸å­˜å‚¨: {dict_result['total_writes']} é¡¹")
            print(f"   âœ… æƒ…æ™¯å­˜å‚¨: {storage_result['global_episode_id']}")
            print(f"   âœ… è®°å¿†æ£€ç´¢: {retrieval_result.shape}")
            
            return {
                'success': True,
                'encoded_shape': list(encoded_output.shape),
                'features_shape': list(features.shape),
                'dict_writes': dict_result['total_writes'],
                'storage_episode': storage_result['global_episode_id'],
                'retrieval_shape': list(retrieval_result.shape)
            }
            
        except Exception as e:
            print(f"   âŒ é›†æˆéªŒè¯å¤±è´¥: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def get_system_statistics(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        print("\nğŸ“Š ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯")
        print("-" * 40)
        
        stats = {
            'total_parameters': self.get_total_parameters(),
            'model_size_mb': sum(p.numel() * p.element_size() 
                               for module in [self.transformer_encoder, self.neural_dictionary, 
                                            self.pattern_separator, self.one_shot_learner, 
                                            self.episodic_memory]
                               for p in module.parameters()) / (1024**2),
            'configuration': self.config,
            'modules': {
                'transformer_encoder': self.transformer_encoder.get_memory_statistics(),
                'neural_dictionary': self.neural_dictionary.get_global_statistics(),
                'pattern_separator': self.pattern_separator.get_network_statistics(),
                'one_shot_learner': self.one_shot_learner.get_learning_statistics(),
                'episodic_memory': self.episodic_memory.get_system_statistics()
            }
        }
        
        print(f"   ğŸ“‹ æ€»å‚æ•°: {stats['total_parameters']:,}")
        print(f"   ğŸ’¾ æ¨¡å‹å¤§å°: {stats['model_size_mb']:.2f} MB")
        print(f"   ğŸ”§ é…ç½®é¡¹: {len(self.config)} ä¸ª")
        
        return stats
    
    def run_complete_validation(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„éªŒè¯"""
        print("=" * 60)
        print("ğŸ§  æµ·é©¬ä½“æ¨¡æ‹Ÿå™¨æ ¸å¿ƒæ¨¡å—å®Œæ•´æ€§éªŒè¯")
        print("åŸºäºScienceæœŸåˆŠ2025å¹´ç ”ç©¶æˆæœ")
        print("=" * 60)
        
        validation_results = {}
        
        # éªŒè¯å„ä¸ªæ¨¡å—
        validation_results['transformer_encoder'] = self.validate_transformer_encoder()
        validation_results['neural_dictionary'] = self.validate_neural_dictionary()
        validation_results['pattern_separator'] = self.validate_pattern_separator()
        validation_results['one_shot_learner'] = self.validate_one_shot_learner()
        validation_results['episodic_memory'] = self.validate_episodic_memory()
        validation_results['integration'] = self.validate_integration()
        
        # è·å–ç³»ç»Ÿç»Ÿè®¡
        validation_results['system_statistics'] = self.get_system_statistics()
        
        # æ€»ç»“ç»“æœ
        successful_modules = sum(1 for result in validation_results.values() 
                               if isinstance(result, dict) and result.get('success', False))
        total_modules = len([k for k in validation_results.keys() if k != 'system_statistics'])
        
        print("\n" + "=" * 60)
        print("ğŸ‰ éªŒè¯ç»“æœæ€»ç»“")
        print("=" * 60)
        print(f"âœ… æˆåŠŸæ¨¡å—: {successful_modules}/{total_modules}")
        print(f"âŒ å¤±è´¥æ¨¡å—: {total_modules - successful_modules}/{total_modules}")
        
        if successful_modules == total_modules:
            print("ğŸŠ æ‰€æœ‰æ ¸å¿ƒæ¨¡å—éªŒè¯é€šè¿‡ï¼")
            print("\nğŸ“‹ å·²å®ç°çš„æ¨¡å—:")
            print("   âœ“ Transformer-basedè®°å¿†ç¼–ç å™¨")
            print("   âœ“ å¯å¾®åˆ†ç¥ç»å­—å…¸")
            print("   âœ“ æ¨¡å¼åˆ†ç¦»æœºåˆ¶")
            print("   âœ“ å¿«é€Ÿä¸€æ¬¡æ€§å­¦ä¹ åŠŸèƒ½")
            print("   âœ“ æƒ…æ™¯è®°å¿†å­˜å‚¨å’Œæ£€ç´¢ç³»ç»Ÿ")
            print("   âœ“ æ¨¡å—é›†æˆéªŒè¯")
        else:
            print("âš ï¸  éƒ¨åˆ†æ¨¡å—éœ€è¦ä¿®å¤")
            for module, result in validation_results.items():
                if isinstance(result, dict) and not result.get('success', False):
                    print(f"   âŒ {module}: {result.get('error', 'Unknown error')}")
        
        print("=" * 60)
        
        return validation_results


def main():
    """ä¸»éªŒè¯å‡½æ•°"""
    validator = CoreModulesValidator()
    results = validator.run_complete_validation()
    return results


if __name__ == "__main__":
    results = main()